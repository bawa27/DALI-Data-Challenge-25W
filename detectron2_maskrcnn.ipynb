{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-28T22:56:48.341313Z",
     "start_time": "2025-01-28T22:56:41.330247Z"
    }
   },
   "source": [
    "import torch\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import warnings\n",
    "# These warnings are not impactful on the output\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\".*incompatible shapes.*\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T22:56:48.350445Z",
     "start_time": "2025-01-28T22:56:48.341313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # this block is used when changing the registered dataset\n",
    "#\n",
    "# from detectron2.data import MetadataCatalog\n",
    "# # remove metadata of dataset from registry\n",
    "# MetadataCatalog.remove(\"barnacle_train\")"
   ],
   "id": "3c224e1a0f1dc78d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T22:56:48.437878Z",
     "start_time": "2025-01-28T22:56:48.434329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Register dataset\n",
    "register_coco_instances(\n",
    "    \"barnacle_train\",\n",
    "    {},\n",
    "    \"barnacle_dataset/annotations/train.json\",  # COCO-style annotations (see below)\n",
    "    \"barnacle_dataset/train/images\"  # Path to image directory\n",
    ")"
   ],
   "id": "6be6f8dfdc2f5efc",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T22:56:48.456655Z",
     "start_time": "2025-01-28T22:56:48.444672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create config\n",
    "cfg = get_cfg()\n",
    "\n",
    "# load base from model zoo\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "\n",
    "# dataset config\n",
    "cfg.DATASETS.TRAIN = (\"barnacle_train\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "\n",
    "# model config\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1 # Only barnacle class\n",
    "# cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
    "\n",
    "# memory optimization\n",
    "cfg.TEST.DETECTIONS_PER_IMAGE = 2000  # Increased to handle dense clusters\n",
    "cfg.SOLVER.AMP.ENABLED = True  # Automatic Mixed Precision\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "# Training Configuration\n",
    "cfg.SOLVER.IMS_PER_BATCH = 1\n",
    "cfg.SOLVER.BASE_LR = 0.00001\n",
    "cfg.SOLVER.MAX_ITER = 2000\n",
    "cfg.SOLVER.STEPS = [400, 900, 1400]\n",
    "cfg.SOLVER.GAMMA = 0.1\n",
    "\n",
    "# Warmup Configuration\n",
    "cfg.SOLVER.WARMUP_FACTOR = 1.0 / 1000\n",
    "cfg.SOLVER.WARMUP_ITERS = 200\n",
    "cfg.SOLVER.WARMUP_METHOD = \"linear\"\n",
    "\n",
    "# Gradient Clipping\n",
    "cfg.SOLVER.CLIP_GRADIENTS.ENABLED = True\n",
    "cfg.SOLVER.CLIP_GRADIENTS.CLIP_TYPE = \"norm\"\n",
    "cfg.SOLVER.CLIP_GRADIENTS.CLIP_VALUE = 1.0"
   ],
   "id": "6168ad10b0a56de",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T22:41:25.253109Z",
     "start_time": "2025-01-28T21:52:30.183997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Start training\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ],
   "id": "fac15c05f4505017",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[01/28 23:52:31 d2.engine.defaults]: \u001B[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001B[32m[01/28 23:52:32 d2.data.datasets.coco]: \u001B[0mLoaded 100 images in COCO format from barnacle_dataset/annotations/train.json\n",
      "\u001B[5m\u001B[31mWARNING\u001B[0m \u001B[32m[01/28 23:52:32 d2.data.datasets.coco]: \u001B[0mFiltered out 4914 instances without valid segmentation. There might be issues in your dataset generation process.  Please check https://detectron2.readthedocs.io/en/latest/tutorials/datasets.html carefully\n",
      "\u001B[32m[01/28 23:52:32 d2.data.build]: \u001B[0mRemoved 0 images with no usable annotations. 100 images left.\n",
      "\u001B[32m[01/28 23:52:32 d2.data.build]: \u001B[0mDistribution of instances among all 1 categories:\n",
      "\u001B[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|  barnacle  | 71627        |\n",
      "|            |              |\u001B[0m\n",
      "\u001B[32m[01/28 23:52:32 d2.data.dataset_mapper]: \u001B[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001B[32m[01/28 23:52:32 d2.data.build]: \u001B[0mUsing training sampler TrainingSampler\n",
      "\u001B[32m[01/28 23:52:32 d2.data.common]: \u001B[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001B[32m[01/28 23:52:32 d2.data.common]: \u001B[0mSerializing 100 elements to byte tensors and concatenating them all ...\n",
      "\u001B[32m[01/28 23:52:32 d2.data.common]: \u001B[0mSerialized dataset takes 21.49 MiB\n",
      "\u001B[32m[01/28 23:52:32 d2.data.build]: \u001B[0mMaking batched data loader with batch_size=1\n",
      "\u001B[5m\u001B[31mWARNING\u001B[0m \u001B[32m[01/28 23:52:32 d2.solver.build]: \u001B[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
      "\u001B[32m[01/28 23:52:32 d2.checkpoint.detection_checkpoint]: \u001B[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001B[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001B[0m\n",
      "\u001B[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001B[0m\n",
      "\u001B[34mroi_heads.mask_head.predictor.{bias, weight}\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[01/28 23:52:33 d2.engine.train_loop]: \u001B[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aryan Bawa\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torch\\functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3596.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "C:\\Users\\Aryan Bawa\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[01/28 23:52:57 d2.utils.events]: \u001B[0m eta: 0:14:15  iter: 19  total_loss: 6.086  loss_cls: 0.6366  loss_box_reg: 0.2568  loss_mask: 0.687  loss_rpn_cls: 4.12  loss_rpn_loc: 0.44    time: 1.1160  last_time: 1.7131  data_time: 0.1396  last_data_time: 0.0032   lr: 2.8771e-06  max_mem: 6169M\n",
      "\u001B[32m[01/28 23:53:27 d2.utils.events]: \u001B[0m eta: 0:25:08  iter: 39  total_loss: 6.228  loss_cls: 0.6348  loss_box_reg: 0.2079  loss_mask: 0.6859  loss_rpn_cls: 4.214  loss_rpn_loc: 0.4758    time: 1.2969  last_time: 1.2914  data_time: 0.0021  last_data_time: 0.0015   lr: 5.8741e-06  max_mem: 7188M\n",
      "\u001B[32m[01/28 23:54:04 d2.utils.events]: \u001B[0m eta: 0:40:01  iter: 59  total_loss: 5.645  loss_cls: 0.63  loss_box_reg: 0.2002  loss_mask: 0.6835  loss_rpn_cls: 3.643  loss_rpn_loc: 0.5324    time: 1.4859  last_time: 2.0383  data_time: 0.0021  last_data_time: 0.0031   lr: 8.8712e-06  max_mem: 7188M\n",
      "\u001B[32m[01/28 23:54:31 d2.utils.events]: \u001B[0m eta: 0:39:36  iter: 79  total_loss: 4.614  loss_cls: 0.6178  loss_box_reg: 0.2622  loss_mask: 0.679  loss_rpn_cls: 2.621  loss_rpn_loc: 0.4284    time: 1.4560  last_time: 2.3973  data_time: 0.0021  last_data_time: 0.0034   lr: 1.1868e-05  max_mem: 7362M\n",
      "\u001B[32m[01/28 23:54:53 d2.utils.events]: \u001B[0m eta: 0:38:47  iter: 99  total_loss: 3.903  loss_cls: 0.6034  loss_box_reg: 0.2877  loss_mask: 0.6742  loss_rpn_cls: 1.834  loss_rpn_loc: 0.4274    time: 1.3812  last_time: 1.6112  data_time: 0.0016  last_data_time: 0.0032   lr: 1.4865e-05  max_mem: 7362M\n",
      "\u001B[32m[01/28 23:55:22 d2.utils.events]: \u001B[0m eta: 0:38:47  iter: 119  total_loss: 3.379  loss_cls: 0.5932  loss_box_reg: 0.124  loss_mask: 0.6686  loss_rpn_cls: 1.443  loss_rpn_loc: 0.568    time: 1.3977  last_time: 3.0036  data_time: 0.0023  last_data_time: 0.0032   lr: 1.7862e-05  max_mem: 7362M\n",
      "\u001B[32m[01/28 23:55:50 d2.utils.events]: \u001B[0m eta: 0:37:58  iter: 139  total_loss: 2.737  loss_cls: 0.5859  loss_box_reg: 0.2807  loss_mask: 0.6608  loss_rpn_cls: 0.7471  loss_rpn_loc: 0.4145    time: 1.3942  last_time: 0.8111  data_time: 0.0021  last_data_time: 0.0014   lr: 2.0859e-05  max_mem: 7362M\n",
      "\u001B[32m[01/28 23:56:12 d2.utils.events]: \u001B[0m eta: 0:36:47  iter: 159  total_loss: 2.475  loss_cls: 0.5705  loss_box_reg: 0.3317  loss_mask: 0.6529  loss_rpn_cls: 0.5506  loss_rpn_loc: 0.3674    time: 1.3561  last_time: 1.1445  data_time: 0.0016  last_data_time: 0.0013   lr: 2.3856e-05  max_mem: 7362M\n",
      "\u001B[32m[01/28 23:56:37 d2.utils.events]: \u001B[0m eta: 0:36:08  iter: 179  total_loss: 2.268  loss_cls: 0.553  loss_box_reg: 0.2903  loss_mask: 0.6442  loss_rpn_cls: 0.4163  loss_rpn_loc: 0.3236    time: 1.3466  last_time: 1.1974  data_time: 0.0018  last_data_time: 0.0015   lr: 2.6853e-05  max_mem: 7362M\n",
      "\u001B[32m[01/28 23:57:03 d2.utils.events]: \u001B[0m eta: 0:35:44  iter: 199  total_loss: 2.173  loss_cls: 0.5346  loss_box_reg: 0.3019  loss_mask: 0.6289  loss_rpn_cls: 0.3953  loss_rpn_loc: 0.3452    time: 1.3431  last_time: 1.4129  data_time: 0.0019  last_data_time: 0.0013   lr: 2.985e-05  max_mem: 7362M\n",
      "\u001B[32m[01/28 23:57:29 d2.utils.events]: \u001B[0m eta: 0:34:47  iter: 219  total_loss: 2.193  loss_cls: 0.5191  loss_box_reg: 0.3359  loss_mask: 0.6186  loss_rpn_cls: 0.4053  loss_rpn_loc: 0.3037    time: 1.3374  last_time: 0.8584  data_time: 0.0018  last_data_time: 0.0011   lr: 3e-05  max_mem: 7362M\n",
      "\u001B[32m[01/28 23:58:04 d2.utils.events]: \u001B[0m eta: 0:34:46  iter: 239  total_loss: 2.084  loss_cls: 0.5086  loss_box_reg: 0.2485  loss_mask: 0.6055  loss_rpn_cls: 0.3869  loss_rpn_loc: 0.3653    time: 1.3697  last_time: 1.1829  data_time: 0.0023  last_data_time: 0.0011   lr: 3e-05  max_mem: 7362M\n",
      "\u001B[32m[01/28 23:58:35 d2.utils.events]: \u001B[0m eta: 0:34:32  iter: 259  total_loss: 2.048  loss_cls: 0.491  loss_box_reg: 0.2582  loss_mask: 0.5931  loss_rpn_cls: 0.3576  loss_rpn_loc: 0.3504    time: 1.3867  last_time: 1.2790  data_time: 0.0021  last_data_time: 0.0014   lr: 3e-05  max_mem: 7362M\n",
      "\u001B[32m[01/28 23:58:58 d2.utils.events]: \u001B[0m eta: 0:33:54  iter: 279  total_loss: 2.029  loss_cls: 0.4847  loss_box_reg: 0.3386  loss_mask: 0.582  loss_rpn_cls: 0.3445  loss_rpn_loc: 0.3213    time: 1.3670  last_time: 1.0853  data_time: 0.0019  last_data_time: 0.0011   lr: 3e-05  max_mem: 7362M\n",
      "\u001B[32m[01/28 23:59:21 d2.utils.events]: \u001B[0m eta: 0:33:13  iter: 299  total_loss: 2.038  loss_cls: 0.4769  loss_box_reg: 0.3281  loss_mask: 0.5741  loss_rpn_cls: 0.3187  loss_rpn_loc: 0.2753    time: 1.3533  last_time: 0.3621  data_time: 0.0018  last_data_time: 0.0009   lr: 3e-05  max_mem: 7362M\n",
      "\u001B[32m[01/28 23:59:48 d2.utils.events]: \u001B[0m eta: 0:32:31  iter: 319  total_loss: 1.996  loss_cls: 0.4775  loss_box_reg: 0.3117  loss_mask: 0.56  loss_rpn_cls: 0.3556  loss_rpn_loc: 0.3253    time: 1.3521  last_time: 0.3304  data_time: 0.0021  last_data_time: 0.0007   lr: 3e-05  max_mem: 7362M\n",
      "\u001B[32m[01/29 00:00:12 d2.utils.events]: \u001B[0m eta: 0:32:14  iter: 339  total_loss: 1.958  loss_cls: 0.4602  loss_box_reg: 0.3055  loss_mask: 0.5561  loss_rpn_cls: 0.3239  loss_rpn_loc: 0.3365    time: 1.3444  last_time: 1.3857  data_time: 0.0020  last_data_time: 0.0030   lr: 3e-05  max_mem: 7362M\n",
      "\u001B[32m[01/29 00:00:41 d2.utils.events]: \u001B[0m eta: 0:32:07  iter: 359  total_loss: 1.92  loss_cls: 0.4516  loss_box_reg: 0.2921  loss_mask: 0.5334  loss_rpn_cls: 0.3478  loss_rpn_loc: 0.3154    time: 1.3497  last_time: 2.3514  data_time: 0.0019  last_data_time: 0.0031   lr: 3e-05  max_mem: 7362M\n",
      "\u001B[32m[01/29 00:01:04 d2.utils.events]: \u001B[0m eta: 0:31:35  iter: 379  total_loss: 1.939  loss_cls: 0.4441  loss_box_reg: 0.297  loss_mask: 0.5507  loss_rpn_cls: 0.3353  loss_rpn_loc: 0.3206    time: 1.3408  last_time: 0.2922  data_time: 0.0016  last_data_time: 0.0007   lr: 3e-05  max_mem: 7362M\n",
      "\u001B[32m[01/29 00:01:31 d2.utils.events]: \u001B[0m eta: 0:31:04  iter: 399  total_loss: 1.957  loss_cls: 0.4479  loss_box_reg: 0.3073  loss_mask: 0.5321  loss_rpn_cls: 0.347  loss_rpn_loc: 0.3109    time: 1.3411  last_time: 0.7544  data_time: 0.0020  last_data_time: 0.0014   lr: 3e-05  max_mem: 7362M\n",
      "\u001B[32m[01/29 00:01:58 d2.utils.events]: \u001B[0m eta: 0:30:48  iter: 419  total_loss: 1.892  loss_cls: 0.4408  loss_box_reg: 0.2704  loss_mask: 0.5422  loss_rpn_cls: 0.3306  loss_rpn_loc: 0.3279    time: 1.3399  last_time: 1.3879  data_time: 0.0020  last_data_time: 0.0012   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:02:24 d2.utils.events]: \u001B[0m eta: 0:30:25  iter: 439  total_loss: 1.973  loss_cls: 0.4382  loss_box_reg: 0.2895  loss_mask: 0.5397  loss_rpn_cls: 0.3166  loss_rpn_loc: 0.3112    time: 1.3387  last_time: 0.3292  data_time: 0.0015  last_data_time: 0.0007   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:02:50 d2.utils.events]: \u001B[0m eta: 0:29:54  iter: 459  total_loss: 1.919  loss_cls: 0.4462  loss_box_reg: 0.3098  loss_mask: 0.5425  loss_rpn_cls: 0.3167  loss_rpn_loc: 0.3091    time: 1.3370  last_time: 0.2720  data_time: 0.0019  last_data_time: 0.0009   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:03:19 d2.utils.events]: \u001B[0m eta: 0:29:30  iter: 479  total_loss: 1.923  loss_cls: 0.4346  loss_box_reg: 0.2654  loss_mask: 0.5331  loss_rpn_cls: 0.3131  loss_rpn_loc: 0.3156    time: 1.3422  last_time: 2.4151  data_time: 0.0018  last_data_time: 0.0029   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:03:49 d2.utils.events]: \u001B[0m eta: 0:29:06  iter: 499  total_loss: 1.869  loss_cls: 0.4386  loss_box_reg: 0.3278  loss_mask: 0.5222  loss_rpn_cls: 0.3296  loss_rpn_loc: 0.2776    time: 1.3479  last_time: 1.8911  data_time: 0.0030  last_data_time: 0.0075   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:04:24 d2.utils.events]: \u001B[0m eta: 0:28:51  iter: 519  total_loss: 1.892  loss_cls: 0.4301  loss_box_reg: 0.2755  loss_mask: 0.5312  loss_rpn_cls: 0.3481  loss_rpn_loc: 0.3243    time: 1.3640  last_time: 0.8766  data_time: 0.0031  last_data_time: 0.0026   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:04:55 d2.utils.events]: \u001B[0m eta: 0:28:28  iter: 539  total_loss: 1.988  loss_cls: 0.4386  loss_box_reg: 0.3427  loss_mask: 0.5227  loss_rpn_cls: 0.3536  loss_rpn_loc: 0.3036    time: 1.3713  last_time: 3.5128  data_time: 0.0027  last_data_time: 0.0098   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:05:23 d2.utils.events]: \u001B[0m eta: 0:27:59  iter: 559  total_loss: 1.886  loss_cls: 0.4274  loss_box_reg: 0.3426  loss_mask: 0.5242  loss_rpn_cls: 0.3312  loss_rpn_loc: 0.312    time: 1.3714  last_time: 2.5933  data_time: 0.0030  last_data_time: 0.0065   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:05:50 d2.utils.events]: \u001B[0m eta: 0:27:36  iter: 579  total_loss: 1.941  loss_cls: 0.4336  loss_box_reg: 0.2917  loss_mask: 0.5194  loss_rpn_cls: 0.3319  loss_rpn_loc: 0.3145    time: 1.3713  last_time: 1.5317  data_time: 0.0038  last_data_time: 0.0016   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:06:26 d2.utils.events]: \u001B[0m eta: 0:27:22  iter: 599  total_loss: 1.859  loss_cls: 0.4337  loss_box_reg: 0.2244  loss_mask: 0.5291  loss_rpn_cls: 0.3009  loss_rpn_loc: 0.3484    time: 1.3843  last_time: 3.4667  data_time: 0.0027  last_data_time: 0.0055   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:06:56 d2.utils.events]: \u001B[0m eta: 0:26:59  iter: 619  total_loss: 1.839  loss_cls: 0.4187  loss_box_reg: 0.2837  loss_mask: 0.5247  loss_rpn_cls: 0.3068  loss_rpn_loc: 0.3025    time: 1.3885  last_time: 1.0481  data_time: 0.0019  last_data_time: 0.0013   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:07:28 d2.utils.events]: \u001B[0m eta: 0:26:39  iter: 639  total_loss: 1.913  loss_cls: 0.428  loss_box_reg: 0.3261  loss_mask: 0.5192  loss_rpn_cls: 0.3263  loss_rpn_loc: 0.294    time: 1.3957  last_time: 0.3078  data_time: 0.0020  last_data_time: 0.0010   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:08:05 d2.utils.events]: \u001B[0m eta: 0:26:33  iter: 659  total_loss: 1.864  loss_cls: 0.4358  loss_box_reg: 0.2649  loss_mask: 0.5428  loss_rpn_cls: 0.3167  loss_rpn_loc: 0.3506    time: 1.4098  last_time: 1.2116  data_time: 0.0025  last_data_time: 0.0013   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:08:31 d2.utils.events]: \u001B[0m eta: 0:26:05  iter: 679  total_loss: 1.904  loss_cls: 0.4326  loss_box_reg: 0.3157  loss_mask: 0.5272  loss_rpn_cls: 0.2919  loss_rpn_loc: 0.2946    time: 1.4064  last_time: 0.2741  data_time: 0.0020  last_data_time: 0.0015   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:09:04 d2.utils.events]: \u001B[0m eta: 0:25:48  iter: 699  total_loss: 1.87  loss_cls: 0.4347  loss_box_reg: 0.2663  loss_mask: 0.5358  loss_rpn_cls: 0.2923  loss_rpn_loc: 0.3315    time: 1.4135  last_time: 0.4491  data_time: 0.0024  last_data_time: 0.0011   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:09:34 d2.utils.events]: \u001B[0m eta: 0:25:22  iter: 719  total_loss: 1.886  loss_cls: 0.4098  loss_box_reg: 0.281  loss_mask: 0.5352  loss_rpn_cls: 0.3168  loss_rpn_loc: 0.3344    time: 1.4146  last_time: 0.3639  data_time: 0.0022  last_data_time: 0.0010   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:10:07 d2.utils.events]: \u001B[0m eta: 0:25:01  iter: 739  total_loss: 1.894  loss_cls: 0.4199  loss_box_reg: 0.2463  loss_mask: 0.5337  loss_rpn_cls: 0.3037  loss_rpn_loc: 0.3478    time: 1.4218  last_time: 3.2014  data_time: 0.0030  last_data_time: 0.0059   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:10:39 d2.utils.events]: \u001B[0m eta: 0:24:37  iter: 759  total_loss: 1.881  loss_cls: 0.4217  loss_box_reg: 0.3179  loss_mask: 0.5095  loss_rpn_cls: 0.3111  loss_rpn_loc: 0.2767    time: 1.4257  last_time: 0.5332  data_time: 0.0023  last_data_time: 0.0008   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:11:06 d2.utils.events]: \u001B[0m eta: 0:24:13  iter: 779  total_loss: 1.872  loss_cls: 0.4154  loss_box_reg: 0.3376  loss_mask: 0.5153  loss_rpn_cls: 0.2946  loss_rpn_loc: 0.2699    time: 1.4245  last_time: 0.8361  data_time: 0.0022  last_data_time: 0.0014   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:11:38 d2.utils.events]: \u001B[0m eta: 0:23:51  iter: 799  total_loss: 1.88  loss_cls: 0.4446  loss_box_reg: 0.2595  loss_mask: 0.5259  loss_rpn_cls: 0.3375  loss_rpn_loc: 0.3305    time: 1.4287  last_time: 2.9293  data_time: 0.0029  last_data_time: 0.0043   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:12:05 d2.utils.events]: \u001B[0m eta: 0:23:27  iter: 819  total_loss: 1.883  loss_cls: 0.4173  loss_box_reg: 0.2876  loss_mask: 0.5155  loss_rpn_cls: 0.3332  loss_rpn_loc: 0.2836    time: 1.4270  last_time: 1.0342  data_time: 0.0025  last_data_time: 0.0016   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:12:41 d2.utils.events]: \u001B[0m eta: 0:23:08  iter: 839  total_loss: 1.855  loss_cls: 0.4266  loss_box_reg: 0.2793  loss_mask: 0.5146  loss_rpn_cls: 0.3418  loss_rpn_loc: 0.3314    time: 1.4354  last_time: 3.1019  data_time: 0.0027  last_data_time: 0.0033   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:13:04 d2.utils.events]: \u001B[0m eta: 0:22:46  iter: 859  total_loss: 1.927  loss_cls: 0.4236  loss_box_reg: 0.3051  loss_mask: 0.5371  loss_rpn_cls: 0.3121  loss_rpn_loc: 0.3499    time: 1.4291  last_time: 1.3101  data_time: 0.0021  last_data_time: 0.0011   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:13:38 d2.utils.events]: \u001B[0m eta: 0:22:24  iter: 879  total_loss: 1.875  loss_cls: 0.4422  loss_box_reg: 0.2294  loss_mask: 0.5112  loss_rpn_cls: 0.338  loss_rpn_loc: 0.3424    time: 1.4357  last_time: 1.2187  data_time: 0.0026  last_data_time: 0.0013   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:14:06 d2.utils.events]: \u001B[0m eta: 0:22:02  iter: 899  total_loss: 1.866  loss_cls: 0.4185  loss_box_reg: 0.2893  loss_mask: 0.5288  loss_rpn_cls: 0.3308  loss_rpn_loc: 0.2733    time: 1.4342  last_time: 3.0067  data_time: 0.0019  last_data_time: 0.0035   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:14:38 d2.utils.events]: \u001B[0m eta: 0:21:40  iter: 919  total_loss: 1.884  loss_cls: 0.4284  loss_box_reg: 0.2268  loss_mask: 0.539  loss_rpn_cls: 0.324  loss_rpn_loc: 0.3442    time: 1.4384  last_time: 0.8429  data_time: 0.0029  last_data_time: 0.0016   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:15:05 d2.utils.events]: \u001B[0m eta: 0:21:16  iter: 939  total_loss: 1.863  loss_cls: 0.4101  loss_box_reg: 0.3403  loss_mask: 0.5281  loss_rpn_cls: 0.3059  loss_rpn_loc: 0.2901    time: 1.4366  last_time: 4.2643  data_time: 0.0020  last_data_time: 0.0044   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:15:39 d2.utils.events]: \u001B[0m eta: 0:20:52  iter: 959  total_loss: 1.909  loss_cls: 0.4307  loss_box_reg: 0.2733  loss_mask: 0.5141  loss_rpn_cls: 0.3288  loss_rpn_loc: 0.3154    time: 1.4417  last_time: 0.3585  data_time: 0.0045  last_data_time: 0.0025   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:16:01 d2.utils.events]: \u001B[0m eta: 0:20:24  iter: 979  total_loss: 1.88  loss_cls: 0.4138  loss_box_reg: 0.3224  loss_mask: 0.5236  loss_rpn_cls: 0.3323  loss_rpn_loc: 0.3323    time: 1.4349  last_time: 0.3765  data_time: 0.0022  last_data_time: 0.0010   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:16:27 d2.utils.events]: \u001B[0m eta: 0:19:57  iter: 999  total_loss: 1.922  loss_cls: 0.4119  loss_box_reg: 0.3332  loss_mask: 0.5187  loss_rpn_cls: 0.3334  loss_rpn_loc: 0.2886    time: 1.4322  last_time: 2.8991  data_time: 0.0023  last_data_time: 0.0055   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:16:54 d2.utils.events]: \u001B[0m eta: 0:19:32  iter: 1019  total_loss: 1.838  loss_cls: 0.4078  loss_box_reg: 0.3425  loss_mask: 0.5118  loss_rpn_cls: 0.2955  loss_rpn_loc: 0.2811    time: 1.4306  last_time: 3.7550  data_time: 0.0024  last_data_time: 0.0058   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:17:24 d2.utils.events]: \u001B[0m eta: 0:19:12  iter: 1039  total_loss: 1.892  loss_cls: 0.4025  loss_box_reg: 0.28  loss_mask: 0.5194  loss_rpn_cls: 0.2681  loss_rpn_loc: 0.3133    time: 1.4312  last_time: 1.9586  data_time: 0.0023  last_data_time: 0.0026   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:18:03 d2.utils.events]: \u001B[0m eta: 0:18:45  iter: 1059  total_loss: 1.872  loss_cls: 0.4329  loss_box_reg: 0.1655  loss_mask: 0.5258  loss_rpn_cls: 0.3176  loss_rpn_loc: 0.3504    time: 1.4412  last_time: 0.5444  data_time: 0.0039  last_data_time: 0.0025   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:18:34 d2.utils.events]: \u001B[0m eta: 0:18:21  iter: 1079  total_loss: 1.856  loss_cls: 0.4169  loss_box_reg: 0.2795  loss_mask: 0.5145  loss_rpn_cls: 0.313  loss_rpn_loc: 0.2989    time: 1.4431  last_time: 0.4565  data_time: 0.0028  last_data_time: 0.0011   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:19:03 d2.utils.events]: \u001B[0m eta: 0:18:03  iter: 1099  total_loss: 1.881  loss_cls: 0.409  loss_box_reg: 0.2984  loss_mask: 0.5261  loss_rpn_cls: 0.3515  loss_rpn_loc: 0.3241    time: 1.4437  last_time: 1.1917  data_time: 0.0025  last_data_time: 0.0019   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:19:27 d2.utils.events]: \u001B[0m eta: 0:17:36  iter: 1119  total_loss: 1.891  loss_cls: 0.4101  loss_box_reg: 0.3128  loss_mask: 0.5206  loss_rpn_cls: 0.3209  loss_rpn_loc: 0.2957    time: 1.4395  last_time: 1.8035  data_time: 0.0099  last_data_time: 0.0054   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:20:00 d2.utils.events]: \u001B[0m eta: 0:17:15  iter: 1139  total_loss: 1.837  loss_cls: 0.4203  loss_box_reg: 0.2881  loss_mask: 0.5112  loss_rpn_cls: 0.3409  loss_rpn_loc: 0.2967    time: 1.4429  last_time: 0.8848  data_time: 0.0035  last_data_time: 0.0016   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:20:35 d2.utils.events]: \u001B[0m eta: 0:16:55  iter: 1159  total_loss: 1.831  loss_cls: 0.426  loss_box_reg: 0.2522  loss_mask: 0.5071  loss_rpn_cls: 0.3244  loss_rpn_loc: 0.34    time: 1.4480  last_time: 1.3518  data_time: 0.0031  last_data_time: 0.0019   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:21:01 d2.utils.events]: \u001B[0m eta: 0:16:33  iter: 1179  total_loss: 1.906  loss_cls: 0.4209  loss_box_reg: 0.2729  loss_mask: 0.525  loss_rpn_cls: 0.3311  loss_rpn_loc: 0.3436    time: 1.4456  last_time: 1.4047  data_time: 0.0027  last_data_time: 0.0018   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:21:29 d2.utils.events]: \u001B[0m eta: 0:16:11  iter: 1199  total_loss: 1.887  loss_cls: 0.4053  loss_box_reg: 0.2788  loss_mask: 0.5277  loss_rpn_cls: 0.3191  loss_rpn_loc: 0.3323    time: 1.4445  last_time: 3.1006  data_time: 0.0026  last_data_time: 0.0056   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:22:04 d2.utils.events]: \u001B[0m eta: 0:15:56  iter: 1219  total_loss: 1.821  loss_cls: 0.4343  loss_box_reg: 0.2868  loss_mask: 0.5039  loss_rpn_cls: 0.3149  loss_rpn_loc: 0.317    time: 1.4496  last_time: 3.1419  data_time: 0.0027  last_data_time: 0.0036   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:22:33 d2.utils.events]: \u001B[0m eta: 0:15:31  iter: 1239  total_loss: 1.854  loss_cls: 0.3827  loss_box_reg: 0.2946  loss_mask: 0.5255  loss_rpn_cls: 0.3272  loss_rpn_loc: 0.3278    time: 1.4496  last_time: 1.0185  data_time: 0.0018  last_data_time: 0.0013   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:23:01 d2.utils.events]: \u001B[0m eta: 0:15:01  iter: 1259  total_loss: 1.858  loss_cls: 0.419  loss_box_reg: 0.2434  loss_mask: 0.5146  loss_rpn_cls: 0.3126  loss_rpn_loc: 0.3437    time: 1.4490  last_time: 0.8360  data_time: 0.0022  last_data_time: 0.0015   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:23:32 d2.utils.events]: \u001B[0m eta: 0:14:42  iter: 1279  total_loss: 1.84  loss_cls: 0.4098  loss_box_reg: 0.2794  loss_mask: 0.5114  loss_rpn_cls: 0.3254  loss_rpn_loc: 0.2956    time: 1.4504  last_time: 1.2765  data_time: 0.0021  last_data_time: 0.0013   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:24:03 d2.utils.events]: \u001B[0m eta: 0:14:30  iter: 1299  total_loss: 1.819  loss_cls: 0.3989  loss_box_reg: 0.255  loss_mask: 0.5171  loss_rpn_cls: 0.3012  loss_rpn_loc: 0.3221    time: 1.4519  last_time: 2.6307  data_time: 0.0020  last_data_time: 0.0029   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:24:34 d2.utils.events]: \u001B[0m eta: 0:14:10  iter: 1319  total_loss: 1.798  loss_cls: 0.4007  loss_box_reg: 0.3164  loss_mask: 0.5006  loss_rpn_cls: 0.2979  loss_rpn_loc: 0.2656    time: 1.4538  last_time: 0.7968  data_time: 0.0021  last_data_time: 0.0013   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:25:07 d2.utils.events]: \u001B[0m eta: 0:13:46  iter: 1339  total_loss: 1.867  loss_cls: 0.4087  loss_box_reg: 0.2804  loss_mask: 0.5134  loss_rpn_cls: 0.3343  loss_rpn_loc: 0.3474    time: 1.4564  last_time: 1.4668  data_time: 0.0026  last_data_time: 0.0015   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:25:33 d2.utils.events]: \u001B[0m eta: 0:13:18  iter: 1359  total_loss: 1.888  loss_cls: 0.402  loss_box_reg: 0.308  loss_mask: 0.5231  loss_rpn_cls: 0.3183  loss_rpn_loc: 0.3193    time: 1.4539  last_time: 1.5282  data_time: 0.0023  last_data_time: 0.0047   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:26:08 d2.utils.events]: \u001B[0m eta: 0:12:58  iter: 1379  total_loss: 1.851  loss_cls: 0.4113  loss_box_reg: 0.2702  loss_mask: 0.5207  loss_rpn_cls: 0.3253  loss_rpn_loc: 0.3432    time: 1.4582  last_time: 2.9590  data_time: 0.0036  last_data_time: 0.0073   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:26:33 d2.utils.events]: \u001B[0m eta: 0:12:38  iter: 1399  total_loss: 1.874  loss_cls: 0.3941  loss_box_reg: 0.3015  loss_mask: 0.5235  loss_rpn_cls: 0.3071  loss_rpn_loc: 0.3256    time: 1.4558  last_time: 0.5229  data_time: 0.0027  last_data_time: 0.0011   lr: 3e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:27:13 d2.utils.events]: \u001B[0m eta: 0:12:23  iter: 1419  total_loss: 1.816  loss_cls: 0.4174  loss_box_reg: 0.2292  loss_mask: 0.5222  loss_rpn_cls: 0.3044  loss_rpn_loc: 0.3274    time: 1.4630  last_time: 2.6617  data_time: 0.0031  last_data_time: 0.0055   lr: 3e-07  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:27:36 d2.utils.events]: \u001B[0m eta: 0:11:57  iter: 1439  total_loss: 1.825  loss_cls: 0.3888  loss_box_reg: 0.3149  loss_mask: 0.5073  loss_rpn_cls: 0.3017  loss_rpn_loc: 0.2696    time: 1.4591  last_time: 1.3642  data_time: 0.0023  last_data_time: 0.0019   lr: 3e-07  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:28:03 d2.utils.events]: \u001B[0m eta: 0:11:31  iter: 1459  total_loss: 1.87  loss_cls: 0.3969  loss_box_reg: 0.3179  loss_mask: 0.5085  loss_rpn_cls: 0.3164  loss_rpn_loc: 0.291    time: 1.4576  last_time: 1.0122  data_time: 0.0024  last_data_time: 0.0016   lr: 3e-07  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:28:31 d2.utils.events]: \u001B[0m eta: 0:11:06  iter: 1479  total_loss: 1.873  loss_cls: 0.4081  loss_box_reg: 0.3341  loss_mask: 0.5189  loss_rpn_cls: 0.3029  loss_rpn_loc: 0.3285    time: 1.4565  last_time: 0.6031  data_time: 0.0029  last_data_time: 0.0012   lr: 3e-07  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:29:00 d2.utils.events]: \u001B[0m eta: 0:10:42  iter: 1499  total_loss: 1.887  loss_cls: 0.4155  loss_box_reg: 0.272  loss_mask: 0.513  loss_rpn_cls: 0.3392  loss_rpn_loc: 0.3412    time: 1.4566  last_time: 1.3492  data_time: 0.0034  last_data_time: 0.0022   lr: 3e-07  max_mem: 7366M\n",
      "\u001B[32m[01/29 00:29:29 d2.utils.events]: \u001B[0m eta: 0:10:15  iter: 1519  total_loss: 1.814  loss_cls: 0.4087  loss_box_reg: 0.3105  loss_mask: 0.5235  loss_rpn_cls: 0.2946  loss_rpn_loc: 0.2883    time: 1.4561  last_time: 1.5925  data_time: 0.0019  last_data_time: 0.0014   lr: 3e-07  max_mem: 7368M\n",
      "\u001B[32m[01/29 00:29:52 d2.utils.events]: \u001B[0m eta: 0:09:49  iter: 1539  total_loss: 1.806  loss_cls: 0.3875  loss_box_reg: 0.2918  loss_mask: 0.5036  loss_rpn_cls: 0.2941  loss_rpn_loc: 0.2611    time: 1.4522  last_time: 1.7608  data_time: 0.0018  last_data_time: 0.0013   lr: 3e-07  max_mem: 7368M\n",
      "\u001B[32m[01/29 00:30:14 d2.utils.events]: \u001B[0m eta: 0:09:23  iter: 1559  total_loss: 1.866  loss_cls: 0.393  loss_box_reg: 0.3254  loss_mask: 0.5141  loss_rpn_cls: 0.3008  loss_rpn_loc: 0.3072    time: 1.4478  last_time: 1.8375  data_time: 0.0017  last_data_time: 0.0036   lr: 3e-07  max_mem: 7368M\n",
      "\u001B[32m[01/29 00:30:48 d2.utils.events]: \u001B[0m eta: 0:09:00  iter: 1579  total_loss: 1.813  loss_cls: 0.399  loss_box_reg: 0.3029  loss_mask: 0.5034  loss_rpn_cls: 0.3194  loss_rpn_loc: 0.3117    time: 1.4512  last_time: 3.8052  data_time: 0.0025  last_data_time: 0.0052   lr: 3e-07  max_mem: 7368M\n",
      "\u001B[32m[01/29 00:31:26 d2.utils.events]: \u001B[0m eta: 0:08:40  iter: 1599  total_loss: 1.89  loss_cls: 0.4284  loss_box_reg: 0.1632  loss_mask: 0.5266  loss_rpn_cls: 0.3565  loss_rpn_loc: 0.3672    time: 1.4565  last_time: 1.7682  data_time: 0.0029  last_data_time: 0.0029   lr: 3e-07  max_mem: 7368M\n",
      "\u001B[32m[01/29 00:31:53 d2.utils.events]: \u001B[0m eta: 0:08:08  iter: 1619  total_loss: 1.854  loss_cls: 0.3906  loss_box_reg: 0.2921  loss_mask: 0.5087  loss_rpn_cls: 0.3445  loss_rpn_loc: 0.3302    time: 1.4554  last_time: 0.4662  data_time: 0.0020  last_data_time: 0.0009   lr: 3e-07  max_mem: 7368M\n",
      "\u001B[32m[01/29 00:32:19 d2.utils.events]: \u001B[0m eta: 0:07:42  iter: 1639  total_loss: 1.811  loss_cls: 0.4047  loss_box_reg: 0.3144  loss_mask: 0.5151  loss_rpn_cls: 0.2734  loss_rpn_loc: 0.271    time: 1.4535  last_time: 0.3603  data_time: 0.0021  last_data_time: 0.0008   lr: 3e-07  max_mem: 7368M\n",
      "\u001B[32m[01/29 00:32:43 d2.utils.events]: \u001B[0m eta: 0:07:13  iter: 1659  total_loss: 1.906  loss_cls: 0.4121  loss_box_reg: 0.3668  loss_mask: 0.5035  loss_rpn_cls: 0.3158  loss_rpn_loc: 0.2932    time: 1.4503  last_time: 0.7500  data_time: 0.0025  last_data_time: 0.0015   lr: 3e-07  max_mem: 7368M\n",
      "\u001B[32m[01/29 00:33:21 d2.utils.events]: \u001B[0m eta: 0:06:50  iter: 1679  total_loss: 1.811  loss_cls: 0.4122  loss_box_reg: 0.2267  loss_mask: 0.518  loss_rpn_cls: 0.3166  loss_rpn_loc: 0.3455    time: 1.4559  last_time: 4.1556  data_time: 0.0029  last_data_time: 0.0039   lr: 3e-07  max_mem: 7368M\n",
      "\u001B[32m[01/29 00:33:52 d2.utils.events]: \u001B[0m eta: 0:06:23  iter: 1699  total_loss: 1.833  loss_cls: 0.3946  loss_box_reg: 0.271  loss_mask: 0.5048  loss_rpn_cls: 0.3011  loss_rpn_loc: 0.3124    time: 1.4570  last_time: 1.1886  data_time: 0.0025  last_data_time: 0.0015   lr: 3e-07  max_mem: 7368M\n",
      "\u001B[32m[01/29 00:34:18 d2.utils.events]: \u001B[0m eta: 0:05:58  iter: 1719  total_loss: 1.875  loss_cls: 0.4078  loss_box_reg: 0.3039  loss_mask: 0.5171  loss_rpn_cls: 0.3237  loss_rpn_loc: 0.3254    time: 1.4550  last_time: 0.4393  data_time: 0.0028  last_data_time: 0.0009   lr: 3e-07  max_mem: 7368M\n",
      "\u001B[32m[01/29 00:34:49 d2.utils.events]: \u001B[0m eta: 0:05:31  iter: 1739  total_loss: 1.818  loss_cls: 0.3987  loss_box_reg: 0.2779  loss_mask: 0.5013  loss_rpn_cls: 0.2964  loss_rpn_loc: 0.2806    time: 1.4562  last_time: 2.5939  data_time: 0.0026  last_data_time: 0.0063   lr: 3e-07  max_mem: 7368M\n",
      "\u001B[32m[01/29 00:35:25 d2.utils.events]: \u001B[0m eta: 0:05:07  iter: 1759  total_loss: 1.826  loss_cls: 0.4085  loss_box_reg: 0.27  loss_mask: 0.5191  loss_rpn_cls: 0.3071  loss_rpn_loc: 0.3105    time: 1.4601  last_time: 1.3024  data_time: 0.0027  last_data_time: 0.0015   lr: 3e-07  max_mem: 7368M\n",
      "\u001B[32m[01/29 00:35:54 d2.utils.events]: \u001B[0m eta: 0:04:41  iter: 1779  total_loss: 1.841  loss_cls: 0.3978  loss_box_reg: 0.2523  loss_mask: 0.5159  loss_rpn_cls: 0.3543  loss_rpn_loc: 0.3476    time: 1.4598  last_time: 1.7598  data_time: 0.0050  last_data_time: 0.0051   lr: 3e-07  max_mem: 7368M\n",
      "\u001B[32m[01/29 00:36:25 d2.utils.events]: \u001B[0m eta: 0:04:14  iter: 1799  total_loss: 1.799  loss_cls: 0.3972  loss_box_reg: 0.2628  loss_mask: 0.5074  loss_rpn_cls: 0.2654  loss_rpn_loc: 0.2804    time: 1.4606  last_time: 0.3015  data_time: 0.0028  last_data_time: 0.0013   lr: 3e-07  max_mem: 7368M\n",
      "\u001B[32m[01/29 00:36:47 d2.utils.events]: \u001B[0m eta: 0:03:49  iter: 1819  total_loss: 1.912  loss_cls: 0.4063  loss_box_reg: 0.4222  loss_mask: 0.5103  loss_rpn_cls: 0.3182  loss_rpn_loc: 0.3063    time: 1.4569  last_time: 1.5832  data_time: 0.0023  last_data_time: 0.0020   lr: 3e-07  max_mem: 7368M\n",
      "\u001B[32m[01/29 00:37:27 d2.utils.events]: \u001B[0m eta: 0:03:25  iter: 1839  total_loss: 1.829  loss_cls: 0.4207  loss_box_reg: 0.1849  loss_mask: 0.5062  loss_rpn_cls: 0.3577  loss_rpn_loc: 0.3629    time: 1.4627  last_time: 1.8065  data_time: 0.0039  last_data_time: 0.0016   lr: 3e-07  max_mem: 7368M\n",
      "\u001B[32m[01/29 00:37:56 d2.utils.events]: \u001B[0m eta: 0:02:59  iter: 1859  total_loss: 1.823  loss_cls: 0.3881  loss_box_reg: 0.2845  loss_mask: 0.5061  loss_rpn_cls: 0.3222  loss_rpn_loc: 0.3131    time: 1.4625  last_time: 0.4991  data_time: 0.0024  last_data_time: 0.0030   lr: 3e-07  max_mem: 7368M\n",
      "\u001B[32m[01/29 00:38:24 d2.utils.events]: \u001B[0m eta: 0:02:33  iter: 1879  total_loss: 1.823  loss_cls: 0.4097  loss_box_reg: 0.2748  loss_mask: 0.5103  loss_rpn_cls: 0.3127  loss_rpn_loc: 0.3094    time: 1.4618  last_time: 0.3526  data_time: 0.0026  last_data_time: 0.0009   lr: 3e-07  max_mem: 7368M\n",
      "\u001B[32m[01/29 00:38:51 d2.utils.events]: \u001B[0m eta: 0:02:07  iter: 1899  total_loss: 1.816  loss_cls: 0.4038  loss_box_reg: 0.3138  loss_mask: 0.4968  loss_rpn_cls: 0.3039  loss_rpn_loc: 0.2723    time: 1.4608  last_time: 1.0496  data_time: 0.0023  last_data_time: 0.0012   lr: 3e-07  max_mem: 7368M\n",
      "\u001B[32m[01/29 00:39:26 d2.utils.events]: \u001B[0m eta: 0:01:42  iter: 1919  total_loss: 1.806  loss_cls: 0.3894  loss_box_reg: 0.2657  loss_mask: 0.4883  loss_rpn_cls: 0.3148  loss_rpn_loc: 0.323    time: 1.4637  last_time: 0.3540  data_time: 0.0022  last_data_time: 0.0008   lr: 3e-07  max_mem: 7368M\n",
      "\u001B[32m[01/29 00:39:59 d2.utils.events]: \u001B[0m eta: 0:01:17  iter: 1939  total_loss: 1.793  loss_cls: 0.4031  loss_box_reg: 0.2737  loss_mask: 0.5073  loss_rpn_cls: 0.3103  loss_rpn_loc: 0.3039    time: 1.4655  last_time: 0.5290  data_time: 0.0019  last_data_time: 0.0009   lr: 3e-07  max_mem: 7368M\n",
      "\u001B[32m[01/29 00:40:23 d2.utils.events]: \u001B[0m eta: 0:00:51  iter: 1959  total_loss: 1.861  loss_cls: 0.3852  loss_box_reg: 0.2999  loss_mask: 0.5183  loss_rpn_cls: 0.317  loss_rpn_loc: 0.3014    time: 1.4628  last_time: 1.2379  data_time: 0.0022  last_data_time: 0.0016   lr: 3e-07  max_mem: 7368M\n",
      "\u001B[32m[01/29 00:40:48 d2.utils.events]: \u001B[0m eta: 0:00:25  iter: 1979  total_loss: 1.829  loss_cls: 0.4072  loss_box_reg: 0.3321  loss_mask: 0.5092  loss_rpn_cls: 0.288  loss_rpn_loc: 0.2853    time: 1.4608  last_time: 0.3180  data_time: 0.0022  last_data_time: 0.0010   lr: 3e-07  max_mem: 7368M\n",
      "\u001B[32m[01/29 00:41:25 d2.utils.events]: \u001B[0m eta: 0:00:00  iter: 1999  total_loss: 1.865  loss_cls: 0.4093  loss_box_reg: 0.2897  loss_mask: 0.5101  loss_rpn_cls: 0.3443  loss_rpn_loc: 0.3305    time: 1.4643  last_time: 0.5342  data_time: 0.0030  last_data_time: 0.0009   lr: 3e-07  max_mem: 7368M\n",
      "\u001B[32m[01/29 00:41:25 d2.engine.hooks]: \u001B[0mOverall training speed: 1998 iterations in 0:48:45 (1.4643 s / it)\n",
      "\u001B[32m[01/29 00:41:25 d2.engine.hooks]: \u001B[0mTotal training time: 0:48:47 (0:00:01 on hooks)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T22:52:41.382829Z",
     "start_time": "2025-01-28T22:52:41.187942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# plot the training loss\n",
    "metrics_df = pd.read_json(\"./output/metrics.json\", orient=\"records\", lines=True)\n",
    "mdf = metrics_df.sort_values(\"iteration\")\n",
    "mdf.head(10).T\n",
    "fig, ax = plt.subplots()\n",
    "mdf1 = mdf[~mdf[\"total_loss\"].isna()]\n",
    "ax.plot(mdf1[\"iteration\"], mdf1[\"total_loss\"], c=\"C0\", label=\"train\")\n",
    "# ax.set_ylim([0, 3])\n",
    "ax.legend()\n",
    "ax.set_title(\"Loss curve\")\n",
    "\n",
    "#Save the plot as an image file\n",
    "plt.savefig(\"loss_curve.png\")\n",
    "\n",
    "plt.show()"
   ],
   "id": "b58cff662d835e01",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T23:01:00.449413Z",
     "start_time": "2025-01-28T22:56:48.470067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load trained model\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.WEIGHTS = \"output/model_final.pth\"\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # Only barnacle class\n",
    "cfg.TEST.DETECTIONS_PER_IMAGE = 5000\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TEST = 5000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 5000\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.4  # Set the testing threshold for this model\n",
    "cfg.INPUT.MIN_SIZE_TEST = 0\n",
    "cfg.INPUT.MAX_SIZE_TEST = 9999\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# Predict on a new ROI\n",
    "roi = cv2.imread(\"barnacle_dataset/test/roi_unseen_img1.png\")\n",
    "if roi is None:\n",
    "    raise FileNotFoundError(\"The image 'barnacle_dataset/test/roi_unseen_img1.png' was not found or could not be read.\")\n",
    "\n",
    "# Resize the image\n",
    "new_width = 1800  # Set the desired width\n",
    "new_height = 1800  # Set the desired height\n",
    "roi = cv2.resize(roi, (new_width, new_height))\n",
    "\n",
    "outputs = predictor(roi)\n",
    "\n",
    "# Visualize results\n",
    "v = Visualizer(roi[:, :, ::-1], scale=0.5)\n",
    "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "\n",
    "# Save the output image\n",
    "output_image = out.get_image()[:, :, ::-1]\n",
    "cv2.imwrite(\"output/images/result.png\", output_image)\n",
    "\n",
    "# Optionally, display the image\n",
    "cv2.imshow(\"Result\", output_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# count barnacles\n",
    "num_barnacles = len(outputs[\"instances\"])\n",
    "print(f\"Number of barnacles detected: {num_barnacles}\")"
   ],
   "id": "8d7d8d50ce89d6de",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aryan Bawa\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torch\\functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3596.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of barnacles detected: 962\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "58005e27a1125de5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
