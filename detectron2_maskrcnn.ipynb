{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-28T23:07:51.636850Z",
     "start_time": "2025-01-28T23:07:47.720379Z"
    }
   },
   "source": [
    "import torch\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import warnings\n",
    "# These warnings are not impactful on the output\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\".*incompatible shapes.*\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T23:07:51.644438Z",
     "start_time": "2025-01-28T23:07:51.641856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # this block is used when changing the registered dataset\n",
    "#\n",
    "# from detectron2.data import MetadataCatalog\n",
    "# # remove metadata of dataset from registry\n",
    "# MetadataCatalog.remove(\"barnacle_train\")"
   ],
   "id": "3c224e1a0f1dc78d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T23:07:51.710037Z",
     "start_time": "2025-01-28T23:07:51.707306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Register dataset\n",
    "register_coco_instances(\n",
    "    \"barnacle_train\",\n",
    "    {},\n",
    "    \"barnacle_dataset/annotations/train.json\",  # COCO-style annotations (see below)\n",
    "    \"barnacle_dataset/train/images\"  # Path to image directory\n",
    ")"
   ],
   "id": "6be6f8dfdc2f5efc",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T23:09:06.494725Z",
     "start_time": "2025-01-28T23:09:06.483330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define configuration\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"barnacle_train\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Pre-trained weights\n",
    "cfg.SOLVER.IMS_PER_BATCH = 1\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "cfg.SOLVER.MAX_ITER = 2000    # Keep training short for small dataset\n",
    "cfg.SOLVER.AMP.ENABLED = True  # Enable automatic mixed precision\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # Only barnacle class\n",
    "\n",
    "# free up gpu memory\n",
    "torch.cuda.empty_cache()"
   ],
   "id": "6168ad10b0a56de",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T23:49:19.227346Z",
     "start_time": "2025-01-28T23:09:09.291540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Start training\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ],
   "id": "fac15c05f4505017",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[01/29 01:09:10 d2.engine.defaults]: \u001B[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001B[32m[01/29 01:09:11 d2.data.datasets.coco]: \u001B[0mLoaded 100 images in COCO format from barnacle_dataset/annotations/train.json\n",
      "\u001B[5m\u001B[31mWARNING\u001B[0m \u001B[32m[01/29 01:09:12 d2.data.datasets.coco]: \u001B[0mFiltered out 4914 instances without valid segmentation. There might be issues in your dataset generation process.  Please check https://detectron2.readthedocs.io/en/latest/tutorials/datasets.html carefully\n",
      "\u001B[32m[01/29 01:09:12 d2.data.build]: \u001B[0mRemoved 0 images with no usable annotations. 100 images left.\n",
      "\u001B[32m[01/29 01:09:12 d2.data.build]: \u001B[0mDistribution of instances among all 1 categories:\n",
      "\u001B[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|  barnacle  | 71627        |\n",
      "|            |              |\u001B[0m\n",
      "\u001B[32m[01/29 01:09:12 d2.data.dataset_mapper]: \u001B[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001B[32m[01/29 01:09:12 d2.data.build]: \u001B[0mUsing training sampler TrainingSampler\n",
      "\u001B[32m[01/29 01:09:12 d2.data.common]: \u001B[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001B[32m[01/29 01:09:12 d2.data.common]: \u001B[0mSerializing 100 elements to byte tensors and concatenating them all ...\n",
      "\u001B[32m[01/29 01:09:12 d2.data.common]: \u001B[0mSerialized dataset takes 21.49 MiB\n",
      "\u001B[32m[01/29 01:09:12 d2.data.build]: \u001B[0mMaking batched data loader with batch_size=1\n",
      "\u001B[5m\u001B[31mWARNING\u001B[0m \u001B[32m[01/29 01:09:12 d2.solver.build]: \u001B[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
      "\u001B[32m[01/29 01:09:12 d2.checkpoint.detection_checkpoint]: \u001B[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001B[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001B[0m\n",
      "\u001B[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001B[0m\n",
      "\u001B[34mroi_heads.mask_head.predictor.{bias, weight}\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[01/29 01:09:12 d2.engine.train_loop]: \u001B[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aryan Bawa\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torch\\functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3596.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "C:\\Users\\Aryan Bawa\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[01/29 01:09:47 d2.utils.events]: \u001B[0m eta: 0:25:19  iter: 19  total_loss: 5.916  loss_cls: 0.7163  loss_box_reg: 0.1938  loss_mask: 0.691  loss_rpn_cls: 3.866  loss_rpn_loc: 0.4605    time: 1.6359  last_time: 4.7041  data_time: 0.1548  last_data_time: 0.0039   lr: 4.9953e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 01:10:13 d2.utils.events]: \u001B[0m eta: 0:29:45  iter: 39  total_loss: 3.111  loss_cls: 0.6868  loss_box_reg: 0.2857  loss_mask: 0.6859  loss_rpn_cls: 1.028  loss_rpn_loc: 0.4451    time: 1.4664  last_time: 0.9469  data_time: 0.0030  last_data_time: 0.0032   lr: 9.9902e-06  max_mem: 7366M\n",
      "\u001B[32m[01/29 01:10:39 d2.utils.events]: \u001B[0m eta: 0:31:38  iter: 59  total_loss: 2.515  loss_cls: 0.655  loss_box_reg: 0.2692  loss_mask: 0.6781  loss_rpn_cls: 0.4895  loss_rpn_loc: 0.4625    time: 1.4000  last_time: 2.1464  data_time: 0.0038  last_data_time: 0.0061   lr: 1.4985e-05  max_mem: 7366M\n",
      "\u001B[32m[01/29 01:11:04 d2.utils.events]: \u001B[0m eta: 0:32:46  iter: 79  total_loss: 2.351  loss_cls: 0.613  loss_box_reg: 0.2926  loss_mask: 0.664  loss_rpn_cls: 0.4293  loss_rpn_loc: 0.4008    time: 1.3598  last_time: 2.8878  data_time: 0.0047  last_data_time: 0.0107   lr: 1.998e-05  max_mem: 7366M\n",
      "\u001B[32m[01/29 01:11:24 d2.utils.events]: \u001B[0m eta: 0:31:18  iter: 99  total_loss: 2.342  loss_cls: 0.5598  loss_box_reg: 0.3513  loss_mask: 0.6442  loss_rpn_cls: 0.4162  loss_rpn_loc: 0.3412    time: 1.2846  last_time: 2.6221  data_time: 0.0032  last_data_time: 0.0082   lr: 2.4975e-05  max_mem: 7366M\n",
      "\u001B[32m[01/29 01:11:58 d2.utils.events]: \u001B[0m eta: 0:33:31  iter: 119  total_loss: 2.128  loss_cls: 0.5281  loss_box_reg: 0.1679  loss_mask: 0.6273  loss_rpn_cls: 0.377  loss_rpn_loc: 0.3702    time: 1.3544  last_time: 2.8466  data_time: 0.0066  last_data_time: 0.0324   lr: 2.997e-05  max_mem: 7366M\n",
      "\u001B[32m[01/29 01:12:21 d2.utils.events]: \u001B[0m eta: 0:33:10  iter: 139  total_loss: 2.116  loss_cls: 0.5091  loss_box_reg: 0.2987  loss_mask: 0.6054  loss_rpn_cls: 0.3541  loss_rpn_loc: 0.3079    time: 1.3246  last_time: 1.2442  data_time: 0.0042  last_data_time: 0.0008   lr: 3.4965e-05  max_mem: 7366M\n",
      "\u001B[32m[01/29 01:12:40 d2.utils.events]: \u001B[0m eta: 0:30:58  iter: 159  total_loss: 2.111  loss_cls: 0.5006  loss_box_reg: 0.3181  loss_mask: 0.5878  loss_rpn_cls: 0.3682  loss_rpn_loc: 0.319    time: 1.2813  last_time: 0.9065  data_time: 0.0025  last_data_time: 0.0004   lr: 3.996e-05  max_mem: 7366M\n",
      "\u001B[32m[01/29 01:13:04 d2.utils.events]: \u001B[0m eta: 0:31:02  iter: 179  total_loss: 2.043  loss_cls: 0.4877  loss_box_reg: 0.3021  loss_mask: 0.571  loss_rpn_cls: 0.3488  loss_rpn_loc: 0.2736    time: 1.2703  last_time: 0.9972  data_time: 0.0047  last_data_time: 0.0029   lr: 4.4955e-05  max_mem: 7366M\n",
      "\u001B[32m[01/29 01:13:43 d2.utils.events]: \u001B[0m eta: 0:32:06  iter: 199  total_loss: 1.959  loss_cls: 0.4741  loss_box_reg: 0.2838  loss_mask: 0.5586  loss_rpn_cls: 0.3216  loss_rpn_loc: 0.3277    time: 1.3370  last_time: 1.7959  data_time: 0.0285  last_data_time: 0.0089   lr: 4.995e-05  max_mem: 7366M\n",
      "\u001B[32m[01/29 01:14:06 d2.utils.events]: \u001B[0m eta: 0:31:44  iter: 219  total_loss: 1.936  loss_cls: 0.4668  loss_box_reg: 0.3009  loss_mask: 0.5369  loss_rpn_cls: 0.3154  loss_rpn_loc: 0.2793    time: 1.3224  last_time: 0.8199  data_time: 0.0053  last_data_time: 0.0021   lr: 5.4945e-05  max_mem: 7366M\n",
      "\u001B[32m[01/29 01:14:36 d2.utils.events]: \u001B[0m eta: 0:31:31  iter: 239  total_loss: 1.888  loss_cls: 0.4559  loss_box_reg: 0.2589  loss_mask: 0.5314  loss_rpn_cls: 0.3303  loss_rpn_loc: 0.3472    time: 1.3356  last_time: 0.6979  data_time: 0.0033  last_data_time: 0.0011   lr: 5.994e-05  max_mem: 7366M\n",
      "\u001B[32m[01/29 01:15:02 d2.utils.events]: \u001B[0m eta: 0:31:17  iter: 259  total_loss: 1.855  loss_cls: 0.4367  loss_box_reg: 0.2509  loss_mask: 0.5388  loss_rpn_cls: 0.3109  loss_rpn_loc: 0.3434    time: 1.3331  last_time: 0.9287  data_time: 0.0022  last_data_time: 0.0015   lr: 6.4935e-05  max_mem: 7366M\n",
      "\u001B[32m[01/29 01:15:21 d2.utils.events]: \u001B[0m eta: 0:30:37  iter: 279  total_loss: 1.874  loss_cls: 0.4237  loss_box_reg: 0.305  loss_mask: 0.5236  loss_rpn_cls: 0.2653  loss_rpn_loc: 0.3006    time: 1.3060  last_time: 1.0128  data_time: 0.0017  last_data_time: 0.0014   lr: 6.993e-05  max_mem: 7366M\n",
      "\u001B[32m[01/29 01:15:44 d2.utils.events]: \u001B[0m eta: 0:29:45  iter: 299  total_loss: 1.811  loss_cls: 0.39  loss_box_reg: 0.2934  loss_mask: 0.507  loss_rpn_cls: 0.3036  loss_rpn_loc: 0.2632    time: 1.2964  last_time: 0.2114  data_time: 0.0019  last_data_time: 0.0008   lr: 7.4925e-05  max_mem: 7366M\n",
      "\u001B[32m[01/29 01:16:07 d2.utils.events]: \u001B[0m eta: 0:29:09  iter: 319  total_loss: 1.771  loss_cls: 0.4194  loss_box_reg: 0.3111  loss_mask: 0.4823  loss_rpn_cls: 0.2887  loss_rpn_loc: 0.3109    time: 1.2851  last_time: 0.1883  data_time: 0.0023  last_data_time: 0.0016   lr: 7.992e-05  max_mem: 7366M\n",
      "\u001B[32m[01/29 01:16:29 d2.utils.events]: \u001B[0m eta: 0:28:22  iter: 339  total_loss: 1.729  loss_cls: 0.371  loss_box_reg: 0.2617  loss_mask: 0.479  loss_rpn_cls: 0.2891  loss_rpn_loc: 0.3316    time: 1.2753  last_time: 2.0861  data_time: 0.0021  last_data_time: 0.0030   lr: 8.4915e-05  max_mem: 7366M\n",
      "\u001B[32m[01/29 01:16:53 d2.utils.events]: \u001B[0m eta: 0:27:58  iter: 359  total_loss: 1.695  loss_cls: 0.3511  loss_box_reg: 0.2811  loss_mask: 0.4492  loss_rpn_cls: 0.3083  loss_rpn_loc: 0.3052    time: 1.2698  last_time: 2.1293  data_time: 0.0021  last_data_time: 0.0029   lr: 8.991e-05  max_mem: 7366M\n",
      "\u001B[32m[01/29 01:17:13 d2.utils.events]: \u001B[0m eta: 0:27:40  iter: 379  total_loss: 1.694  loss_cls: 0.3585  loss_box_reg: 0.261  loss_mask: 0.446  loss_rpn_cls: 0.3031  loss_rpn_loc: 0.3185    time: 1.2576  last_time: 0.2870  data_time: 0.0019  last_data_time: 0.0008   lr: 9.4905e-05  max_mem: 7366M\n",
      "\u001B[32m[01/29 01:17:37 d2.utils.events]: \u001B[0m eta: 0:27:12  iter: 399  total_loss: 1.663  loss_cls: 0.3415  loss_box_reg: 0.2774  loss_mask: 0.4272  loss_rpn_cls: 0.2865  loss_rpn_loc: 0.2702    time: 1.2529  last_time: 0.7742  data_time: 0.0026  last_data_time: 0.0025   lr: 9.99e-05  max_mem: 7366M\n",
      "\u001B[32m[01/29 01:18:03 d2.utils.events]: \u001B[0m eta: 0:26:56  iter: 419  total_loss: 1.603  loss_cls: 0.3302  loss_box_reg: 0.2771  loss_mask: 0.4118  loss_rpn_cls: 0.29  loss_rpn_loc: 0.3087    time: 1.2562  last_time: 1.6408  data_time: 0.0024  last_data_time: 0.0018   lr: 0.0001049  max_mem: 7366M\n",
      "\u001B[32m[01/29 01:18:25 d2.utils.events]: \u001B[0m eta: 0:26:31  iter: 439  total_loss: 1.688  loss_cls: 0.3293  loss_box_reg: 0.2933  loss_mask: 0.4064  loss_rpn_cls: 0.2603  loss_rpn_loc: 0.3133    time: 1.2494  last_time: 0.1924  data_time: 0.0020  last_data_time: 0.0007   lr: 0.00010989  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:18:49 d2.utils.events]: \u001B[0m eta: 0:26:10  iter: 459  total_loss: 1.538  loss_cls: 0.3068  loss_box_reg: 0.3065  loss_mask: 0.3954  loss_rpn_cls: 0.2522  loss_rpn_loc: 0.286    time: 1.2468  last_time: 0.2265  data_time: 0.0028  last_data_time: 0.0009   lr: 0.00011489  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:19:12 d2.utils.events]: \u001B[0m eta: 0:25:55  iter: 479  total_loss: 1.576  loss_cls: 0.287  loss_box_reg: 0.2963  loss_mask: 0.4019  loss_rpn_cls: 0.2872  loss_rpn_loc: 0.3087    time: 1.2423  last_time: 2.5498  data_time: 0.0023  last_data_time: 0.0039   lr: 0.00011988  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:19:39 d2.utils.events]: \u001B[0m eta: 0:25:30  iter: 499  total_loss: 1.509  loss_cls: 0.3017  loss_box_reg: 0.2808  loss_mask: 0.3815  loss_rpn_cls: 0.2665  loss_rpn_loc: 0.2662    time: 1.2465  last_time: 2.4262  data_time: 0.0026  last_data_time: 0.0042   lr: 0.00012488  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:20:06 d2.utils.events]: \u001B[0m eta: 0:25:14  iter: 519  total_loss: 1.511  loss_cls: 0.2785  loss_box_reg: 0.294  loss_mask: 0.3813  loss_rpn_cls: 0.2622  loss_rpn_loc: 0.2915    time: 1.2517  last_time: 1.0098  data_time: 0.0024  last_data_time: 0.0018   lr: 0.00012987  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:20:29 d2.utils.events]: \u001B[0m eta: 0:24:42  iter: 539  total_loss: 1.568  loss_cls: 0.289  loss_box_reg: 0.2954  loss_mask: 0.3862  loss_rpn_cls: 0.2671  loss_rpn_loc: 0.281    time: 1.2461  last_time: 2.2093  data_time: 0.0023  last_data_time: 0.0038   lr: 0.00013487  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:20:49 d2.utils.events]: \u001B[0m eta: 0:24:22  iter: 559  total_loss: 1.504  loss_cls: 0.2824  loss_box_reg: 0.3125  loss_mask: 0.3834  loss_rpn_cls: 0.2265  loss_rpn_loc: 0.2934    time: 1.2384  last_time: 2.1271  data_time: 0.0025  last_data_time: 0.0060   lr: 0.00013986  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:21:13 d2.utils.events]: \u001B[0m eta: 0:23:56  iter: 579  total_loss: 1.521  loss_cls: 0.2703  loss_box_reg: 0.3106  loss_mask: 0.3737  loss_rpn_cls: 0.2584  loss_rpn_loc: 0.2888    time: 1.2363  last_time: 1.6024  data_time: 0.0027  last_data_time: 0.0017   lr: 0.00014486  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:21:40 d2.utils.events]: \u001B[0m eta: 0:23:45  iter: 599  total_loss: 1.485  loss_cls: 0.269  loss_box_reg: 0.2755  loss_mask: 0.3835  loss_rpn_cls: 0.2602  loss_rpn_loc: 0.32    time: 1.2398  last_time: 2.2801  data_time: 0.0028  last_data_time: 0.0047   lr: 0.00014985  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:22:03 d2.utils.events]: \u001B[0m eta: 0:23:25  iter: 619  total_loss: 1.416  loss_cls: 0.2383  loss_box_reg: 0.3011  loss_mask: 0.3652  loss_rpn_cls: 0.2531  loss_rpn_loc: 0.2916    time: 1.2373  last_time: 0.9344  data_time: 0.0024  last_data_time: 0.0014   lr: 0.00015485  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:22:26 d2.utils.events]: \u001B[0m eta: 0:22:55  iter: 639  total_loss: 1.456  loss_cls: 0.2497  loss_box_reg: 0.321  loss_mask: 0.373  loss_rpn_cls: 0.2398  loss_rpn_loc: 0.2627    time: 1.2341  last_time: 0.3322  data_time: 0.0026  last_data_time: 0.0013   lr: 0.00015984  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:22:53 d2.utils.events]: \u001B[0m eta: 0:22:44  iter: 659  total_loss: 1.417  loss_cls: 0.2479  loss_box_reg: 0.2649  loss_mask: 0.3852  loss_rpn_cls: 0.2603  loss_rpn_loc: 0.3068    time: 1.2391  last_time: 1.4988  data_time: 0.0031  last_data_time: 0.0024   lr: 0.00016484  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:23:16 d2.utils.events]: \u001B[0m eta: 0:22:28  iter: 679  total_loss: 1.396  loss_cls: 0.2315  loss_box_reg: 0.3435  loss_mask: 0.3747  loss_rpn_cls: 0.215  loss_rpn_loc: 0.2614    time: 1.2359  last_time: 0.2438  data_time: 0.0022  last_data_time: 0.0013   lr: 0.00016983  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:23:40 d2.utils.events]: \u001B[0m eta: 0:22:08  iter: 699  total_loss: 1.409  loss_cls: 0.2349  loss_box_reg: 0.2617  loss_mask: 0.3821  loss_rpn_cls: 0.2128  loss_rpn_loc: 0.3044    time: 1.2348  last_time: 0.2429  data_time: 0.0028  last_data_time: 0.0013   lr: 0.00017483  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:24:02 d2.utils.events]: \u001B[0m eta: 0:21:48  iter: 719  total_loss: 1.38  loss_cls: 0.2231  loss_box_reg: 0.3018  loss_mask: 0.3808  loss_rpn_cls: 0.2329  loss_rpn_loc: 0.3036    time: 1.2310  last_time: 0.2004  data_time: 0.0026  last_data_time: 0.0012   lr: 0.00017982  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:24:27 d2.utils.events]: \u001B[0m eta: 0:21:29  iter: 739  total_loss: 1.376  loss_cls: 0.2102  loss_box_reg: 0.2506  loss_mask: 0.3821  loss_rpn_cls: 0.2205  loss_rpn_loc: 0.3163    time: 1.2321  last_time: 2.0644  data_time: 0.0033  last_data_time: 0.0048   lr: 0.00018482  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:24:51 d2.utils.events]: \u001B[0m eta: 0:21:08  iter: 759  total_loss: 1.359  loss_cls: 0.1978  loss_box_reg: 0.3001  loss_mask: 0.3561  loss_rpn_cls: 0.2181  loss_rpn_loc: 0.2427    time: 1.2300  last_time: 0.2267  data_time: 0.0025  last_data_time: 0.0012   lr: 0.00018981  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:25:10 d2.utils.events]: \u001B[0m eta: 0:20:44  iter: 779  total_loss: 1.405  loss_cls: 0.2061  loss_box_reg: 0.3122  loss_mask: 0.3671  loss_rpn_cls: 0.2239  loss_rpn_loc: 0.25    time: 1.2238  last_time: 0.7763  data_time: 0.0022  last_data_time: 0.0019   lr: 0.00019481  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:25:36 d2.utils.events]: \u001B[0m eta: 0:20:23  iter: 799  total_loss: 1.38  loss_cls: 0.2368  loss_box_reg: 0.272  loss_mask: 0.3765  loss_rpn_cls: 0.2612  loss_rpn_loc: 0.2874    time: 1.2249  last_time: 2.1596  data_time: 0.0032  last_data_time: 0.0049   lr: 0.0001998  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:25:59 d2.utils.events]: \u001B[0m eta: 0:20:05  iter: 819  total_loss: 1.33  loss_cls: 0.2214  loss_box_reg: 0.2946  loss_mask: 0.3549  loss_rpn_cls: 0.2289  loss_rpn_loc: 0.259    time: 1.2239  last_time: 1.0261  data_time: 0.0027  last_data_time: 0.0019   lr: 0.0002048  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:26:25 d2.utils.events]: \u001B[0m eta: 0:19:46  iter: 839  total_loss: 1.308  loss_cls: 0.1913  loss_box_reg: 0.26  loss_mask: 0.3583  loss_rpn_cls: 0.2315  loss_rpn_loc: 0.2608    time: 1.2251  last_time: 2.1489  data_time: 0.0029  last_data_time: 0.0048   lr: 0.00020979  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:26:44 d2.utils.events]: \u001B[0m eta: 0:19:24  iter: 859  total_loss: 1.414  loss_cls: 0.2145  loss_box_reg: 0.3197  loss_mask: 0.3586  loss_rpn_cls: 0.2022  loss_rpn_loc: 0.3021    time: 1.2192  last_time: 0.8780  data_time: 0.0025  last_data_time: 0.0017   lr: 0.00021479  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:27:12 d2.utils.events]: \u001B[0m eta: 0:19:04  iter: 879  total_loss: 1.329  loss_cls: 0.2027  loss_box_reg: 0.2112  loss_mask: 0.3679  loss_rpn_cls: 0.2299  loss_rpn_loc: 0.2993    time: 1.2235  last_time: 1.0189  data_time: 0.0035  last_data_time: 0.0019   lr: 0.00021978  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:27:34 d2.utils.events]: \u001B[0m eta: 0:18:44  iter: 899  total_loss: 1.331  loss_cls: 0.1894  loss_box_reg: 0.2774  loss_mask: 0.366  loss_rpn_cls: 0.231  loss_rpn_loc: 0.2645    time: 1.2200  last_time: 1.9969  data_time: 0.0026  last_data_time: 0.0048   lr: 0.00022478  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:28:03 d2.utils.events]: \u001B[0m eta: 0:18:27  iter: 919  total_loss: 1.297  loss_cls: 0.1935  loss_box_reg: 0.2367  loss_mask: 0.3709  loss_rpn_cls: 0.2431  loss_rpn_loc: 0.3062    time: 1.2248  last_time: 0.9361  data_time: 0.0033  last_data_time: 0.0016   lr: 0.00022977  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:28:23 d2.utils.events]: \u001B[0m eta: 0:18:05  iter: 939  total_loss: 1.283  loss_cls: 0.1843  loss_box_reg: 0.3019  loss_mask: 0.3531  loss_rpn_cls: 0.1905  loss_rpn_loc: 0.2512    time: 1.2206  last_time: 2.0712  data_time: 0.0023  last_data_time: 0.0054   lr: 0.00023477  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:28:50 d2.utils.events]: \u001B[0m eta: 0:17:45  iter: 959  total_loss: 1.286  loss_cls: 0.1953  loss_box_reg: 0.2628  loss_mask: 0.3556  loss_rpn_cls: 0.1847  loss_rpn_loc: 0.2667    time: 1.2228  last_time: 0.2267  data_time: 0.0029  last_data_time: 0.0014   lr: 0.00023976  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:29:10 d2.utils.events]: \u001B[0m eta: 0:17:23  iter: 979  total_loss: 1.312  loss_cls: 0.1833  loss_box_reg: 0.3212  loss_mask: 0.3588  loss_rpn_cls: 0.2244  loss_rpn_loc: 0.2884    time: 1.2186  last_time: 0.1921  data_time: 0.0025  last_data_time: 0.0014   lr: 0.00024476  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:29:32 d2.utils.events]: \u001B[0m eta: 0:17:01  iter: 999  total_loss: 1.33  loss_cls: 0.1787  loss_box_reg: 0.338  loss_mask: 0.3598  loss_rpn_cls: 0.212  loss_rpn_loc: 0.2744    time: 1.2165  last_time: 2.7207  data_time: 0.0024  last_data_time: 0.0046   lr: 0.00024975  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:29:52 d2.utils.events]: \u001B[0m eta: 0:16:39  iter: 1019  total_loss: 1.318  loss_cls: 0.1767  loss_box_reg: 0.3393  loss_mask: 0.3509  loss_rpn_cls: 0.2081  loss_rpn_loc: 0.2538    time: 1.2122  last_time: 2.5747  data_time: 0.0025  last_data_time: 0.0042   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:30:15 d2.utils.events]: \u001B[0m eta: 0:16:20  iter: 1039  total_loss: 1.302  loss_cls: 0.1926  loss_box_reg: 0.2807  loss_mask: 0.3583  loss_rpn_cls: 0.2221  loss_rpn_loc: 0.2634    time: 1.2102  last_time: 1.2504  data_time: 0.0029  last_data_time: 0.0022   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:30:46 d2.utils.events]: \u001B[0m eta: 0:16:00  iter: 1059  total_loss: 1.289  loss_cls: 0.1905  loss_box_reg: 0.1915  loss_mask: 0.3655  loss_rpn_cls: 0.2465  loss_rpn_loc: 0.313    time: 1.2172  last_time: 0.2063  data_time: 0.0040  last_data_time: 0.0014   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:31:10 d2.utils.events]: \u001B[0m eta: 0:15:39  iter: 1079  total_loss: 1.254  loss_cls: 0.191  loss_box_reg: 0.2923  loss_mask: 0.3561  loss_rpn_cls: 0.1986  loss_rpn_loc: 0.2594    time: 1.2169  last_time: 0.2355  data_time: 0.0027  last_data_time: 0.0011   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:31:34 d2.utils.events]: \u001B[0m eta: 0:15:21  iter: 1099  total_loss: 1.333  loss_cls: 0.2008  loss_box_reg: 0.2875  loss_mask: 0.351  loss_rpn_cls: 0.2305  loss_rpn_loc: 0.2828    time: 1.2160  last_time: 1.0718  data_time: 0.0027  last_data_time: 0.0031   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:31:54 d2.utils.events]: \u001B[0m eta: 0:14:50  iter: 1119  total_loss: 1.276  loss_cls: 0.1682  loss_box_reg: 0.3128  loss_mask: 0.3539  loss_rpn_cls: 0.1992  loss_rpn_loc: 0.2846    time: 1.2123  last_time: 2.1295  data_time: 0.0024  last_data_time: 0.0047   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:32:18 d2.utils.events]: \u001B[0m eta: 0:14:28  iter: 1139  total_loss: 1.281  loss_cls: 0.1888  loss_box_reg: 0.267  loss_mask: 0.3607  loss_rpn_cls: 0.2325  loss_rpn_loc: 0.2667    time: 1.2121  last_time: 0.7705  data_time: 0.0029  last_data_time: 0.0018   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:32:45 d2.utils.events]: \u001B[0m eta: 0:14:16  iter: 1159  total_loss: 1.225  loss_cls: 0.1773  loss_box_reg: 0.2759  loss_mask: 0.3509  loss_rpn_cls: 0.1994  loss_rpn_loc: 0.2924    time: 1.2151  last_time: 1.4944  data_time: 0.0031  last_data_time: 0.0020   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:33:08 d2.utils.events]: \u001B[0m eta: 0:13:54  iter: 1179  total_loss: 1.275  loss_cls: 0.1809  loss_box_reg: 0.2912  loss_mask: 0.3606  loss_rpn_cls: 0.1926  loss_rpn_loc: 0.2834    time: 1.2132  last_time: 0.9671  data_time: 0.0028  last_data_time: 0.0024   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:33:32 d2.utils.events]: \u001B[0m eta: 0:13:32  iter: 1199  total_loss: 1.252  loss_cls: 0.1669  loss_box_reg: 0.2634  loss_mask: 0.3462  loss_rpn_cls: 0.2117  loss_rpn_loc: 0.2762    time: 1.2132  last_time: 2.4767  data_time: 0.0027  last_data_time: 0.0052   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:33:58 d2.utils.events]: \u001B[0m eta: 0:13:11  iter: 1219  total_loss: 1.203  loss_cls: 0.1695  loss_box_reg: 0.2653  loss_mask: 0.3505  loss_rpn_cls: 0.1806  loss_rpn_loc: 0.261    time: 1.2145  last_time: 1.8981  data_time: 0.0036  last_data_time: 0.0044   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:34:19 d2.utils.events]: \u001B[0m eta: 0:12:49  iter: 1239  total_loss: 1.217  loss_cls: 0.1508  loss_box_reg: 0.2815  loss_mask: 0.3462  loss_rpn_cls: 0.2125  loss_rpn_loc: 0.2586    time: 1.2121  last_time: 1.5054  data_time: 0.0022  last_data_time: 0.0017   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:34:44 d2.utils.events]: \u001B[0m eta: 0:12:27  iter: 1259  total_loss: 1.282  loss_cls: 0.1711  loss_box_reg: 0.2494  loss_mask: 0.3492  loss_rpn_cls: 0.212  loss_rpn_loc: 0.2887    time: 1.2126  last_time: 1.0045  data_time: 0.0028  last_data_time: 0.0020   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:35:07 d2.utils.events]: \u001B[0m eta: 0:12:07  iter: 1279  total_loss: 1.208  loss_cls: 0.1607  loss_box_reg: 0.2656  loss_mask: 0.3453  loss_rpn_cls: 0.2024  loss_rpn_loc: 0.2487    time: 1.2115  last_time: 1.0222  data_time: 0.0028  last_data_time: 0.0014   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:35:31 d2.utils.events]: \u001B[0m eta: 0:11:50  iter: 1299  total_loss: 1.219  loss_cls: 0.1652  loss_box_reg: 0.2767  loss_mask: 0.3512  loss_rpn_cls: 0.1731  loss_rpn_loc: 0.2879    time: 1.2117  last_time: 2.3695  data_time: 0.0028  last_data_time: 0.0051   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:35:53 d2.utils.events]: \u001B[0m eta: 0:11:27  iter: 1319  total_loss: 1.156  loss_cls: 0.1472  loss_box_reg: 0.2785  loss_mask: 0.3373  loss_rpn_cls: 0.1855  loss_rpn_loc: 0.226    time: 1.2100  last_time: 0.9971  data_time: 0.0026  last_data_time: 0.0015   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:36:17 d2.utils.events]: \u001B[0m eta: 0:11:11  iter: 1339  total_loss: 1.252  loss_cls: 0.1696  loss_box_reg: 0.2612  loss_mask: 0.3483  loss_rpn_cls: 0.1803  loss_rpn_loc: 0.2791    time: 1.2097  last_time: 1.0440  data_time: 0.0030  last_data_time: 0.0030   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:36:39 d2.utils.events]: \u001B[0m eta: 0:10:49  iter: 1359  total_loss: 1.285  loss_cls: 0.1707  loss_box_reg: 0.296  loss_mask: 0.3586  loss_rpn_cls: 0.2355  loss_rpn_loc: 0.2703    time: 1.2082  last_time: 2.3983  data_time: 0.0024  last_data_time: 0.0036   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:37:06 d2.utils.events]: \u001B[0m eta: 0:10:31  iter: 1379  total_loss: 1.196  loss_cls: 0.17  loss_box_reg: 0.1994  loss_mask: 0.3437  loss_rpn_cls: 0.2009  loss_rpn_loc: 0.2874    time: 1.2100  last_time: 2.0750  data_time: 0.0032  last_data_time: 0.0059   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:37:27 d2.utils.events]: \u001B[0m eta: 0:10:10  iter: 1399  total_loss: 1.315  loss_cls: 0.1783  loss_box_reg: 0.2652  loss_mask: 0.3489  loss_rpn_cls: 0.1927  loss_rpn_loc: 0.2709    time: 1.2074  last_time: 0.1997  data_time: 0.0024  last_data_time: 0.0014   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:37:56 d2.utils.events]: \u001B[0m eta: 0:09:50  iter: 1419  total_loss: 1.209  loss_cls: 0.1738  loss_box_reg: 0.2152  loss_mask: 0.354  loss_rpn_cls: 0.1995  loss_rpn_loc: 0.2789    time: 1.2110  last_time: 2.7140  data_time: 0.0032  last_data_time: 0.0052   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:38:14 d2.utils.events]: \u001B[0m eta: 0:09:29  iter: 1439  total_loss: 1.186  loss_cls: 0.1512  loss_box_reg: 0.2884  loss_mask: 0.3494  loss_rpn_cls: 0.1857  loss_rpn_loc: 0.2359    time: 1.2068  last_time: 1.2054  data_time: 0.0024  last_data_time: 0.0020   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:38:36 d2.utils.events]: \u001B[0m eta: 0:09:08  iter: 1459  total_loss: 1.219  loss_cls: 0.172  loss_box_reg: 0.2719  loss_mask: 0.3472  loss_rpn_cls: 0.1917  loss_rpn_loc: 0.2463    time: 1.2055  last_time: 1.0007  data_time: 0.0023  last_data_time: 0.0014   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:38:58 d2.utils.events]: \u001B[0m eta: 0:08:45  iter: 1479  total_loss: 1.22  loss_cls: 0.1781  loss_box_reg: 0.3194  loss_mask: 0.3424  loss_rpn_cls: 0.1873  loss_rpn_loc: 0.2707    time: 1.2038  last_time: 0.2434  data_time: 0.0027  last_data_time: 0.0013   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:39:26 d2.utils.events]: \u001B[0m eta: 0:08:28  iter: 1499  total_loss: 1.227  loss_cls: 0.1678  loss_box_reg: 0.238  loss_mask: 0.3355  loss_rpn_cls: 0.1839  loss_rpn_loc: 0.2913    time: 1.2063  last_time: 1.2633  data_time: 0.0029  last_data_time: 0.0022   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:39:48 d2.utils.events]: \u001B[0m eta: 0:08:05  iter: 1519  total_loss: 1.235  loss_cls: 0.1764  loss_box_reg: 0.3258  loss_mask: 0.3542  loss_rpn_cls: 0.2101  loss_rpn_loc: 0.2606    time: 1.2048  last_time: 1.1974  data_time: 0.0026  last_data_time: 0.0021   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:40:09 d2.utils.events]: \u001B[0m eta: 0:07:44  iter: 1539  total_loss: 1.168  loss_cls: 0.1379  loss_box_reg: 0.2842  loss_mask: 0.3273  loss_rpn_cls: 0.1787  loss_rpn_loc: 0.2376    time: 1.2027  last_time: 0.8484  data_time: 0.0024  last_data_time: 0.0015   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:40:28 d2.utils.events]: \u001B[0m eta: 0:07:23  iter: 1559  total_loss: 1.227  loss_cls: 0.1556  loss_box_reg: 0.3001  loss_mask: 0.3408  loss_rpn_cls: 0.1914  loss_rpn_loc: 0.2518    time: 1.2000  last_time: 2.5303  data_time: 0.0022  last_data_time: 0.0055   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:40:54 d2.utils.events]: \u001B[0m eta: 0:07:04  iter: 1579  total_loss: 1.163  loss_cls: 0.1403  loss_box_reg: 0.2646  loss_mask: 0.3367  loss_rpn_cls: 0.1907  loss_rpn_loc: 0.2418    time: 1.2011  last_time: 1.8373  data_time: 0.0028  last_data_time: 0.0055   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:41:26 d2.utils.events]: \u001B[0m eta: 0:06:45  iter: 1599  total_loss: 1.215  loss_cls: 0.1696  loss_box_reg: 0.1877  loss_mask: 0.3573  loss_rpn_cls: 0.1777  loss_rpn_loc: 0.3113    time: 1.2062  last_time: 2.6192  data_time: 0.0047  last_data_time: 0.0193   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:41:50 d2.utils.events]: \u001B[0m eta: 0:06:25  iter: 1619  total_loss: 1.157  loss_cls: 0.135  loss_box_reg: 0.2806  loss_mask: 0.3325  loss_rpn_cls: 0.1813  loss_rpn_loc: 0.2702    time: 1.2058  last_time: 0.2424  data_time: 0.0053  last_data_time: 0.0010   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:42:12 d2.utils.events]: \u001B[0m eta: 0:06:06  iter: 1639  total_loss: 1.202  loss_cls: 0.168  loss_box_reg: 0.27  loss_mask: 0.3535  loss_rpn_cls: 0.1801  loss_rpn_loc: 0.2518    time: 1.2047  last_time: 0.2038  data_time: 0.0038  last_data_time: 0.0010   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:42:34 d2.utils.events]: \u001B[0m eta: 0:05:42  iter: 1659  total_loss: 1.217  loss_cls: 0.1571  loss_box_reg: 0.3093  loss_mask: 0.3513  loss_rpn_cls: 0.1861  loss_rpn_loc: 0.2424    time: 1.2034  last_time: 0.7882  data_time: 0.0026  last_data_time: 0.0016   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:43:03 d2.utils.events]: \u001B[0m eta: 0:05:22  iter: 1679  total_loss: 1.201  loss_cls: 0.1773  loss_box_reg: 0.2517  loss_mask: 0.3467  loss_rpn_cls: 0.206  loss_rpn_loc: 0.2791    time: 1.2063  last_time: 2.1130  data_time: 0.0038  last_data_time: 0.0069   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:43:24 d2.utils.events]: \u001B[0m eta: 0:05:01  iter: 1699  total_loss: 1.216  loss_cls: 0.1634  loss_box_reg: 0.261  loss_mask: 0.3465  loss_rpn_cls: 0.1781  loss_rpn_loc: 0.283    time: 1.2047  last_time: 0.9369  data_time: 0.0027  last_data_time: 0.0018   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:43:48 d2.utils.events]: \u001B[0m eta: 0:04:41  iter: 1719  total_loss: 1.233  loss_cls: 0.1725  loss_box_reg: 0.2679  loss_mask: 0.3516  loss_rpn_cls: 0.1858  loss_rpn_loc: 0.2606    time: 1.2042  last_time: 0.2066  data_time: 0.0029  last_data_time: 0.0014   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:44:09 d2.utils.events]: \u001B[0m eta: 0:04:20  iter: 1739  total_loss: 1.174  loss_cls: 0.1485  loss_box_reg: 0.2741  loss_mask: 0.3424  loss_rpn_cls: 0.1803  loss_rpn_loc: 0.2482    time: 1.2029  last_time: 2.2956  data_time: 0.0025  last_data_time: 0.0051   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:44:36 d2.utils.events]: \u001B[0m eta: 0:04:02  iter: 1759  total_loss: 1.132  loss_cls: 0.1438  loss_box_reg: 0.2511  loss_mask: 0.3498  loss_rpn_cls: 0.1787  loss_rpn_loc: 0.2793    time: 1.2040  last_time: 1.3225  data_time: 0.0032  last_data_time: 0.0019   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:44:59 d2.utils.events]: \u001B[0m eta: 0:03:44  iter: 1779  total_loss: 1.168  loss_cls: 0.1724  loss_box_reg: 0.2259  loss_mask: 0.3525  loss_rpn_cls: 0.1599  loss_rpn_loc: 0.282    time: 1.2038  last_time: 2.1170  data_time: 0.0031  last_data_time: 0.0063   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:45:21 d2.utils.events]: \u001B[0m eta: 0:03:23  iter: 1799  total_loss: 1.2  loss_cls: 0.1616  loss_box_reg: 0.3075  loss_mask: 0.3397  loss_rpn_cls: 0.1699  loss_rpn_loc: 0.2334    time: 1.2023  last_time: 0.2034  data_time: 0.0028  last_data_time: 0.0011   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:45:36 d2.utils.events]: \u001B[0m eta: 0:03:01  iter: 1819  total_loss: 1.146  loss_cls: 0.1598  loss_box_reg: 0.2973  loss_mask: 0.3341  loss_rpn_cls: 0.1125  loss_rpn_loc: 0.2146    time: 1.1977  last_time: 0.9809  data_time: 0.0020  last_data_time: 0.0022   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:46:11 d2.utils.events]: \u001B[0m eta: 0:02:42  iter: 1839  total_loss: 1.167  loss_cls: 0.1394  loss_box_reg: 0.1982  loss_mask: 0.3435  loss_rpn_cls: 0.2164  loss_rpn_loc: 0.2919    time: 1.2037  last_time: 1.4978  data_time: 0.0037  last_data_time: 0.0024   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:46:33 d2.utils.events]: \u001B[0m eta: 0:02:22  iter: 1859  total_loss: 1.195  loss_cls: 0.1631  loss_box_reg: 0.263  loss_mask: 0.3339  loss_rpn_cls: 0.1859  loss_rpn_loc: 0.2426    time: 1.2026  last_time: 0.3255  data_time: 0.0027  last_data_time: 0.0020   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:47:00 d2.utils.events]: \u001B[0m eta: 0:02:01  iter: 1879  total_loss: 1.163  loss_cls: 0.1462  loss_box_reg: 0.2296  loss_mask: 0.3434  loss_rpn_cls: 0.178  loss_rpn_loc: 0.2571    time: 1.2039  last_time: 0.2168  data_time: 0.0029  last_data_time: 0.0012   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:47:20 d2.utils.events]: \u001B[0m eta: 0:01:40  iter: 1899  total_loss: 1.137  loss_cls: 0.1392  loss_box_reg: 0.2703  loss_mask: 0.3342  loss_rpn_cls: 0.1556  loss_rpn_loc: 0.2192    time: 1.2017  last_time: 0.8680  data_time: 0.0025  last_data_time: 0.0018   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:47:45 d2.utils.events]: \u001B[0m eta: 0:01:19  iter: 1919  total_loss: 1.145  loss_cls: 0.1491  loss_box_reg: 0.2103  loss_mask: 0.3342  loss_rpn_cls: 0.1997  loss_rpn_loc: 0.2777    time: 1.2025  last_time: 0.2318  data_time: 0.0027  last_data_time: 0.0011   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:48:10 d2.utils.events]: \u001B[0m eta: 0:00:59  iter: 1939  total_loss: 1.17  loss_cls: 0.1518  loss_box_reg: 0.2545  loss_mask: 0.3458  loss_rpn_cls: 0.1875  loss_rpn_loc: 0.2635    time: 1.2027  last_time: 0.3134  data_time: 0.0029  last_data_time: 0.0011   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:48:31 d2.utils.events]: \u001B[0m eta: 0:00:39  iter: 1959  total_loss: 1.156  loss_cls: 0.1508  loss_box_reg: 0.238  loss_mask: 0.3353  loss_rpn_cls: 0.1704  loss_rpn_loc: 0.2411    time: 1.2013  last_time: 1.1381  data_time: 0.0026  last_data_time: 0.0028   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:48:50 d2.utils.events]: \u001B[0m eta: 0:00:19  iter: 1979  total_loss: 1.134  loss_cls: 0.1505  loss_box_reg: 0.3075  loss_mask: 0.3385  loss_rpn_cls: 0.1574  loss_rpn_loc: 0.204    time: 1.1988  last_time: 0.2117  data_time: 0.0025  last_data_time: 0.0015   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:49:19 d2.utils.events]: \u001B[0m eta: 0:00:00  iter: 1999  total_loss: 1.164  loss_cls: 0.1515  loss_box_reg: 0.2355  loss_mask: 0.3494  loss_rpn_cls: 0.1714  loss_rpn_loc: 0.2806    time: 1.2007  last_time: 0.2152  data_time: 0.0035  last_data_time: 0.0012   lr: 0.00025  max_mem: 7370M\n",
      "\u001B[32m[01/29 01:49:19 d2.engine.hooks]: \u001B[0mOverall training speed: 1998 iterations in 0:39:59 (1.2007 s / it)\n",
      "\u001B[32m[01/29 01:49:19 d2.engine.hooks]: \u001B[0mTotal training time: 0:40:01 (0:00:02 on hooks)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T23:52:36.531538Z",
     "start_time": "2025-01-28T23:52:36.322556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# plot the training loss\n",
    "metrics_df = pd.read_json(\"./output/metrics.json\", orient=\"records\", lines=True)\n",
    "mdf = metrics_df.sort_values(\"iteration\")\n",
    "mdf.head(10).T\n",
    "fig, ax = plt.subplots()\n",
    "mdf1 = mdf[~mdf[\"total_loss\"].isna()]\n",
    "ax.plot(mdf1[\"iteration\"], mdf1[\"total_loss\"], c=\"C0\", label=\"train\")\n",
    "# ax.set_ylim([0, 3])\n",
    "ax.legend()\n",
    "ax.set_title(\"Loss curve\")\n",
    "\n",
    "#Save the plot as an image file\n",
    "plt.savefig(\"loss_curve.png\")\n",
    "\n",
    "plt.show()"
   ],
   "id": "b58cff662d835e01",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAGzCAYAAABzfl4TAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAXpdJREFUeJzt3Qd4VGXWB/ATEhJ66E1C71WpIogICCKyyKprYVfQXVHEVT4XV1lXBV0FZe262EVFBHQBdRGR3kF67xASaqgplNT5nvMmd/LOnXtn7ty5NzNz5/97nnkgyWQyk5nMPfe855w3xuVyuQgAAADAAqWsuBEAAAAAhsACAAAALIPAAgAAACyDwAIAAAAsg8ACAAAALIPAAgAAACyDwAIAAAAsg8ACAAAALIPAAgAAACyDwAIAAAAsg8ACIMxNnTqVYmJiaOPGjaG+KwAAfiGwAAAAAMsgsACAiFBQUEBXr14N9d0AAD8QWAA4xJYtW2jgwIFUqVIlqlChAvXt25fWrVvncZ3c3FyaMGECNWvWjMqUKUPVqlWjnj170sKFC93XOXXqFD344INUr149SkhIoDp16tCQIUMoOTnZ733Yu3cv/eEPf6AaNWpQ2bJlqUWLFvTcc8+5vz5ixAhq2LCh1/eNHz9eLPfI+OPHH3+cvvnmG2rTpo24Lz/99BNVrVpV3D+1jIwM8ZjGjh3r/lx2dja9+OKL1LRpU/H9SUlJ9Pe//118HgDsEWfT7QJACdq1axfdeOONIqjgA2fp0qXpo48+ot69e9Py5cupW7du7gP4xIkT6S9/+Qt17dpVHIy5dmPz5s10yy23iOvceeed4vb++te/iiAgLS1NBB4pKSmaQYFi+/bt4j7wzx45cqS47qFDh0Qw8Morr5h6XEuWLKFZs2aJAKN69eoiIBo6dCjNnj1bPL74+Hj3defOnSsChnvvvded4fjd735Hq1atEvenVatWtGPHDnrrrbdo//794voAYAMXAIS1L774wsV/qhs2bNC9zh133OGKj493HTp0yP25EydOuCpWrOjq1auX+3MdOnRwDRo0SPd2Lly4IH7W5MmTA76f/HP45x09etTj8wUFBe7/Dx8+3NWgQQOv733xxRfFz5Xxx6VKlXLt2rXL4/MLFiwQX/vpp588Pn/bbbe5Gjdu7P7466+/Ft+/cuVKj+t9+OGH4vtXr14d8GMEAP+wFAIQ4fLz8+nXX3+lO+64gxo3buz+PC9h3H///eKMnTMTrHLlyiIbceDAAc3b4uULzgIsW7aMLly4YPg+nDlzhlasWEEPPfQQ1a9f3+Nr6iWOQNx0003UunVrj8/16dNHZC9mzpzp/hzfV86q3HPPPe7PfffddyJL0bJlSzp79qz7wt/Pli5davp+AYA+BBYAEY4P6pcvXxb1DGp8YOUlgdTUVPHxSy+9RBcvXqTmzZtTu3bt6OmnnxZLGAquQ3jttddo/vz5VKtWLerVqxe9/vrrou7Cl8OHD4t/27Zta+lja9Sokdfn4uLixHLNDz/84K6V4KURrh+RAwsOnjiI4noP+cKPnfESDwBYD4EFQBThQIHrHj7//HMRBHz66afUsWNH8a9izJgxogaBazG4GPL5558XAQoXhwZLL3vBWRe9DIoWrqPIzMwUARDjOgzOTHTo0MF9HQ6oOHjiTIbW5bHHHgv68QCANwQWABGOz8LLlStH+/bt0+zSKFWqlOiGUChdFd9++63IZLRv314UdcqaNGlCf/vb38QSy86dOyknJ4feeOMN3fugLMHwdX2pUqWKyJioHT16lAINkHiph5dDeHmDizzlbIXyGM6fPy+6Y/r16+d10crwAEDwEFgARLjY2Fjq37+/WBqQW0JPnz5N06dPF+2k3C3Czp075/G93JbKrZjKkgIvqahnRfABumLFij5bNDm44YM9Z0K4e0RWWIdZfFvp6ekeyy8nT56kOXPmBPSYOVi66667RMfJ119/TXl5eV6BBbe9Hj9+nD755BOv779y5QpdunQpoJ8JAMbEcAWnwesCQIhGenOGYdSoUVS3bl2vrz/55JPiYM4tpVycySl+rkPgdkw+sMrtplw3wS2onTp1EpkLbjX9+OOPRTvnu+++S1u3bhVn+HxQ5qJJvh0+6PPSwffffy9qG/Rs27ZNBDFcp8HtnVwfwYHOvHnzxO0qgU2DBg3E/XjiiSdEIDNlyhQRmHDLq/x2xMsmo0ePpvfff1/z561evVr8PA56uLVVDlaUpZDBgweL5RIOOnr06CGWXDiLw0snCxYsoM6dO5t+XgBAh4HOEQAIg3ZTvUtqaqq43ubNm10DBgxwVahQwVWuXDnXzTff7FqzZo3Hbf3rX/9yde3a1VW5cmVX2bJlXS1btnS98sorrpycHPH1s2fPukaPHi0+X758eVdiYqKrW7durlmzZhm6rzt37nQNHTpU3H6ZMmVcLVq0cD3//PMe1/n1119dbdu2Fe2x/PVp06bptpvyfdHDbaxJSUnievy4tPDjeu2111xt2rRxJSQkuKpUqeLq1KmTa8KECa709HRDjwkAAoOMBQAAAFgGNRYAAABgGQQWAAAAYBkEFgAAAGAZBBYAAABgGQQWAAAAYBkEFgAAAGCZOCphPLTmxIkTYqhNMLseAgAAQMnh6RS8Rw8P6uPpt2ETWHBQIe9bAAAAAJGD9xiqV69e+AQWnKlQ7piyfwEAAACEt4yMDJEYUI7jYRNYKMsfHFQgsAAAAIgs/soYULwJAAAAlkFgAQAAAJZBYAEAAACWKfEaCwAAALvaIfPy8ig/Pz/UdyUixcbGUlxcXNCjIBBYAABAxMvJyaGTJ0/S5cuXQ31XIlq5cuWoTp06FB8fb/o2EFgAAEBE48GLR44cEWfcPLyJD4oYwBh4toeDszNnzojfZbNmzXwOwfIFgQUAAEQ0PiBycMEzFviMG8wpW7YslS5dmo4ePSp+p2XKlDF1OyjeBAAARzB7hg3W/g7xLAAAAIBlEFgAAACAZRBYAAAAOEDDhg3p7bffDvXdQPEmAABAqPTu3ZuuvfZaSwKCDRs2UPny5SnUHJOxyLiaSx8tP0Sp59HDDAAAzhr6ZUSNGjXCoivGMYHF+B930cT5e2nw+6tCfVcAACAMDsiXc/JK/OJyuQzfxxEjRtDy5cvpnXfeEXM3+DJ16lTx7/z586lTp06UkJBAq1atokOHDtGQIUOoVq1aVKFCBerSpQstWrTI51II386nn35KQ4cOFQEHz6b48ccfyW6OWQpZd+ic+Pfi5dxQ3xUAAAixK7n51PqFBSX+c3e/NIDKxRs7tHJAsX//fmrbti299NJL4nO7du0S/z777LP073//mxo3bkxVqlSh1NRUuu222+iVV14RwcZXX31FgwcPpn379lH9+vV1f8aECRPo9ddfp8mTJ9N7771Hw4YNE3MqqlatSnZxTMYiNhZT1gAAIHIkJiaKKaGcTahdu7a48PRQxoHGLbfcQk2aNBFBQIcOHeiRRx4RQQhnHl5++WXxNX8ZCM6K3HfffdS0aVN69dVXKSsri3777TdbH5djMhalMRgFAACKlC0dK7IHofi5VujcubPHxxwQjB8/nubNmyf2ROG6iytXrlBKSorP22nfvr37/1zYWalSJUpLSyM7OSawiC2FjAUAABTXFxhdkghH5VXdHWPHjqWFCxeK5RHOPvD47bvuukuM3vaFR3Srfy88/txOkftbV4mLRcYCAAAiS3x8vKFt3levXi2WNbgQU8lgJCcnUzhyzNF4z8mMUN8FAACAgHAnx/r160WQcPbsWd1sAtdVzJ49m7Zu3Urbtm2j+++/3/bMQ4kEFhxVPf/889SoUSORhuHCES4gCaS9BgAAAIqXOLhgs3Xr1mIOhV7NxJtvvim6Q2644QbRDTJgwADq2LEjhaOAlkJee+01mjJlCn355ZfUpk0b2rhxIz344IOisvWJJ56w714CAAA4UPPmzWnt2rUen+MlD63MxpIlSzw+N3r0aI+P1UsjWif9Fy9epLAKLNasWSMGdAwaNMj9QL/99lvbW1cAAAAgMgS0FMIpmMWLF4uBHozXeXgi2MCBA3W/Jzs7mzIyMjwuAAAA4EwBZSx4EhgHBi1bthRrQlxzwVPAeJKXnokTJ4rJXwAAAOB8AWUsZs2aRd988w1Nnz6dNm/eLGotuKeW/9Uzbtw4Sk9Pd194LCkAAAA4U0AZi6efflpkLe69917xcbt27cTMcc5KDB8+XPN7eKY5XwAAAOyEDsXw+B0GlLG4fPkylVKNzuYlkXDtpQUAAOdTpkvyMQqCo/wO1RM7bctYcO8s11TwTmrcbrplyxbRW/vQQw+ZvgMAAADB4BPcypUru/fA4E29eHQ1BLjN/OXL4nfIv0tlMzTbAwvecpUHZD322GPih9etW1fstvbCCy+YvgMAAADB4p1Bmd0bbDld5cqV3b9Ls2JcJbwoxV0lPFCLCzl5lzWrNHx2nvv/yZMK52wAAEB04W7F3NzcUN+NiMTLH74yFUaP347ZhAwAAIAPjMGk8SF4jtmEDAAAAEIPgQUAAABYxpGBRUEBepkBAABCwZGBRR4CCwAAgJBwaGCBgV0AAACh4NDAAhkLAACAUHBmYJGPwAIAACAUnBlYYCkEAAAgJJwZWCBjAQAAEBKODCzyUWMBAAAQEo4MLHLzsRQCAAAQCo4MLJCxAAAACA1HBha5qLEAAAAICUcGFugKAQAACA2HBhbIWAAAAISCMwMLLIUAAACEhDMDCyyFAAAAhIQzAwtkLAAAAELCkYEF2k0BAABCw5GBBQZkAQAAhIYjAwtkLAAAAELDkYFFLgILAACAkHBkYJGPrhAAAICQcGRggZHeAAAAoeHIwAI1FgAAAKHhyMAiD10hAAAAIeHMwAIZCwAAgJBwZmCBGgsAAICQcGZggYwFAABASDgzsECNBQAAQEg4M7BAxgIAACAkHBpYIGMBAAAQCg4NLJCxAAAACAVnBhboCgEAAAgJRwYWmLwJAAAQGo4MLHLRFQIAABD+gUXDhg0pJibG6zJ69GgKJ8hYAAAAhEZcIFfesGED5efnuz/euXMn3XLLLXT33XdTOMHupgAAABEQWNSoUcPj40mTJlGTJk3opptuonCSj3ZTAACA8A8sZDk5OTRt2jR66qmnxHKInuzsbHFRZGRkkN1ysRQCAAAQWcWbc+fOpYsXL9KIESN8Xm/ixImUmJjoviQlJZHdMNIbAAAgwgKLzz77jAYOHEh169b1eb1x48ZRenq6+5Kamkp2Q/EmAABABC2FHD16lBYtWkSzZ8/2e92EhARxKUko3gQAAIigjMUXX3xBNWvWpEGDBlE4QsYCAAAgQgKLgoICEVgMHz6c4uJM137aCgOyAAAAIiSw4CWQlJQUeuihhyhcIWMBAAAQGgGnHPr3708uV3gfuNFuCgAAEBqO3CsEA7IAAABCw5GBBbZNBwAACA1nBhZYCgEAAAgJZwYW6AoBAAAICWcGFshYAAAAhIQzAwvUWAAAAISEMwMLZCwAAABCwqGBBWosAAAAQsGRgUU+lkIAAABCwpGBRS4yFgAAACHhyMACe4UAAACEhiMDi9x8V9jvZwIAAOBEjgwsGJIWAAAAJc+xgcVXa5Op4bPzaP3hc6G+KwAAAFHDsYHFhJ92i39HT98S6rsCAAAQNRwbWCiy8/JDfRcAAACihuMDCwAAACg5CCwAAADAMo4PLDKv5oX6LgAAAEQNxwcWAAAAUHKiKrDIys6jnDyM+wYAALBLHEWJyzl51PbFBeL/yZMGhfruAAAAOFLUZCwOpmWF+i4AAAA4XtQEFhcu54b6LgAAADhe1AQWR89dCvVdAAAAcLyoCCwKClziouV0xtUSvz8AAABOFRWBRb7Lpbnb6e3vraRury6mp7/bFoq7BQAA4DjREVhwxsLlHVnsPJ4h/p295XgI7hUAAIDzREVgkacTWAAAAIC1oiZjkY+5WAAAALaLmsACGQsAAAD7RU1gAQAAAPaLmsDChYwFAACA7aIisMgrKNBsNwUAAABrRUVgUVBAqLEAAAAoAVGTsUBcAQAAEIaBxfHjx+mPf/wjVatWjcqWLUvt2rWjjRs3UiTVWKDeAgAAwB5xgVz5woUL1KNHD7r55ptp/vz5VKNGDTpw4ABVqVKFwn2ktxxKcFwRExPCOwQAAOBQAQUWr732GiUlJdEXX3zh/lyjRo0onMSWiqHRNzeldxcfcH8uLx9zLAAAAMJuKeTHH3+kzp0709133001a9ak6667jj755BOf35OdnU0ZGRkeFztpLXMUDsiSrmPrPQAAAIheAQUWhw8fpilTplCzZs1owYIFNGrUKHriiSfoyy+/1P2eiRMnUmJiovvCGQ87cdAQo7UUIgcWyF4AAACEPrAoKCigjh070quvviqyFSNHjqSHH36YPvzwQ93vGTduHKWnp7svqampZCetmMGreNPWewAAABC9Agos6tSpQ61bt/b4XKtWrSglJUX3exISEqhSpUoel5KmrrFAwgIAACAMAgvuCNm3b5/H5/bv308NGjSgcKLu+OCgApM3AQAAwiyw+L//+z9at26dWAo5ePAgTZ8+nT7++GMaPXo0hbM8sRRS/LFn8ykAAACEJLDo0qULzZkzh7799ltq27Ytvfzyy/T222/TsGHDKJzl8+RNKZjAUggAAEAYzLFgt99+u7iEsxhVX0h+AYIJAACAkhAVe4VwxgLFmwAAAPaLisCCaywweRMAAMB+jgsseKS3uiukcI5F8cco3gQAALCH4wKLlrUren1OBBbSx0heAAAA2MNxgYXYuVSz3RSTNwEAAOzmuMBCq5aigGssCoo/xl4hAAAA9nBcYFGmdKzX51C8CQAAUDIcE1i8dU8Haly9PP377vbaxZvSxwgxAAAAwmRAVrgael09cSl0yndXCCILAAAAWzgmY+GLett0pCwAAADs4cjAIka1FiK6QqSPMccCAADAHo4MLNQKt01HMAEAAGC3qAgs8vI5sCj+GDEGAACAPaIisMh3YUAWAABASYiOwKKgQNUVgtACAADADo4MLNRzLAqLN5GxAAAAsJsjAwutkd7ccgoAAAD2iorAonCkd/HHWAkBAACwhyMDixjV/qacreCshQJzLAAAAOzhyMBCTQQWmLwJAABguygKLIo/RlwBAABgj6jpCsHkTQAAAPs5MrBQK1AFFogxAAAA7OHIwEKVsBAZC7ndFMWbAAAA9nBkYOG3xgJxBQAAgC2iJrDAXiEAAAD2i5riTSOTNzn4aPjsPHEBAACAwDkysNDahMxzKUQ7yDh89pL7//JALQAAADAmOgILFxnqCkHtBQAAQHCiZKQ3ZywQNQAAANjNkYGFWl4+7xVS/DFiDAAAAHtERfEmZyuQsQAAALCfIwMLNfVIbwzIAgAAsEdUBBYYkAUAAFAyoiew8BjpDQAAAHaInsDCo90UoQUAAEDIA4vx48dTTEyMx6Vly5YU7sTkTQQTAAAAtosL9BvatGlDixYtKr6BuIBvwnYc8Hhtmy63m5b8XQIAAIgKAUcFHEjUrl2bIkmeehMyRBYAAADhUWNx4MABqlu3LjVu3JiGDRtGKSkpPq+fnZ1NGRkZHhe7xWjUWHguhSCyAAAACHlg0a1bN5o6dSr98ssvNGXKFDpy5AjdeOONlJmZqfs9EydOpMTERPclKSmJShraTQEAAMIwsBg4cCDdfffd1L59exowYAD9/PPPdPHiRZo1a5bu94wbN47S09Pdl9TUVArJgKwgdivNzZcKNAAAAEBXUJWXlStXpubNm9PBgwd1r5OQkCAuoRzpzZuQyQIJMUZP30zztp+k4d0b0IQhba25gwAAAA4V1ByLrKwsOnToENWpU4fCWTBLIRxUsC/XHrXhngEAAERxYDF27Fhavnw5JScn05o1a2jo0KEUGxtL9913H0XW5E0UWQAAAIR8KeTYsWMiiDh37hzVqFGDevbsSevWrRP/DydeXSGqFAWKNwEAAMIgsJgxYwZFIs5YRMfwcgAAgNCKom3Tiz9GxgIAAMAejgws1CO9OZAQWQvlY9RYAAAA2MKRgYUWj8ACcQUAAIAtHBlYqOdYWG1b6kXaeTzd3h8CAAAQgcJva9IwdzU3n4Z8sFr8/+ArAyku1pGxGQAAgClReVQMZinkwuUc9/+v5OZbc4cAAAAcwpGBhb+VEBRvAgAA2MORgYU/KN4EAACwR3QGFqG+AwAAAA7lzMDC7rYQAAAAiKLAwg8X1kIAAABsEaXFmwAAAGAHRwYW/iBhAQAAYI+oDCwAAADAHqWis3YTKQsAAAA7ODKw8AdLIQAAAPaIzsAi1HcAAADAoRwZWMT46QtBxgIAAMAejgwsAAAAIDSisngTA7IAAADs4cjAwh+EFQAAAPaIzsACkQUAAIAtonSkNyILAAAAOzgysAAAAIDQiM7AAgkLAAAAW0RnV0hJ3REAAIAo48jAwh8UbwIAANgjOgML5CwAAABsEZUjvQEAAMAejgwsQrEUUlCALAgAAIAzA4sSLt78ddcpaj/hV1q4+7TFtwwAABBZnBlYUMnuFbIh+TxlZefRmkNnLb1dAACASBOdgYVNt5t1Nc+mWwYAAIgMjgwsQlW6eSkHgQUAAEQ3RwYWoUpZZCJjAQAAUS4qAwu75lhcykZgAQAA0c2RgUWMn5nedk3evJSdb88NAwAARENgMWnSJHEQHzNmDEUSuwIL7gwBAACIZqYDiw0bNtBHH31E7du3p3ATquJNBBYAABDtTAUWWVlZNGzYMPrkk0+oSpUqFGlsazfNzrN8RgYAAIDjA4vRo0fToEGDqF+/fn6vm52dTRkZGR6XULPr4J9f4KLsvAJbbhsAACASxAX6DTNmzKDNmzeLpRAjJk6cSBMmTKCS5Kd209a9TbnltEzpWBt/AgAAgEMyFqmpqfTkk0/SN998Q2XKlDH0PePGjaP09HT3hW8j1OxcrVBaTj9ZcZg+XH7Ivh8EAAAQ6RmLTZs2UVpaGnXs2NH9ufz8fFqxYgW9//77YtkjNtbzbD0hIUFcogXXWVzNzadXft4jPv7j9Q2oQkLAiSEAAICIFNARr2/fvrRjxw6Pzz344IPUsmVLeuaZZ7yCilDxtxRi52KIEljIGQwEFgAAEC0COuJVrFiR2rZt6/G58uXLU7Vq1bw+H85y8u0LLDB9EwAAopkzJ2/6mWTxxLdbbPvZmGUBAADRLOgc/bJly6y5Jw6BwAIAAKKZIzMWoZSFHU4BACCKOTKw8F+8SZRj0yAr1FgAAEA0c2RgEcoAIAs7nAIAQBSL2sDCrlqIrOxcW24XAAAgEkRtYHEpx57A4hIyFgAAEMWiN7CwKWORiRoLAACIYlEbWNhVC4HiTQAAiGaODCxiDLSF2NUWisACAACimSMDi5AuhWCOBQAARDFHBhYxIewKsasoFAAAIBI4MrAI6RyLq3nksm+PMwAAgLAWtYFFlk2ZhbwCF+Xk2zPVEwAAINxF7UhvO4ssUWcBAADRypGBRag3C0NnCAAARKvoDSxsnJCJwAIAAKKVIwOLGAN9IbYuhSCwAACAKOXIwCLUbaHIWAAAQLSK2uJNu+ZY2H3bAAAA4cyRgUWoswoILAAAIFpFbWBhZ1eInbcNAAAQzqJ2pPelHHSFAAAAWM2RgYWTW1kBAADCGQILG2Rl53p9buneNGr47Dz6ecfJkNwnAACAkhC1XSF2SIgr/HVe0shYPDh1g/j3sW82l/j9AgAAKCmODCxCpWKZOPEvBmQBAEC0cmhgEZqURfmEwsACxZsAABCtHBpYhEb5eAQWAAAQ3RBYWKhC0VII5lgAAEC0cmRgEarizQpFSyFZNu5DAgAAEM4cGVhYFWhczc03FVi4XOZ+HgAAQKSLisAirlTgkcX031KozYsLTBVvAgAARCtHBhbqMCLWRGCx6egFyi8ILPVQPj424J8DAADgJI4MLNRiTayFmOns4ACmHIILAACIYtERWJjIWFw2uUkZlkMAACCaOTKwiFFlKOJiA3+YWSZnUVREYAEAAFHMkYGFWikTSyGXTbaMImMBAADRLKDAYsqUKdS+fXuqVKmSuHTv3p3mz59P4SbGgq4QrY3EAmk5NeLVn/fQs//dburnAAAARHxgUa9ePZo0aRJt2rSJNm7cSH369KEhQ4bQrl27yHk1FvZmLPLyC+jjFYdpxoZUOpeVbepnAQAAhJuA8vaDBw/2+PiVV14RWYx169ZRmzZtyEmBxSWTxZsVEox1hcidrJlX86hahQRTPw8AACCcmC4IyM/Pp++++44uXboklkT0ZGdni4siIyOD7KYuqTCzFJKTVxDUfiEAAADRKODizR07dlCFChUoISGBHn30UZozZw61bt1a9/oTJ06kxMRE9yUpKYkiIWNhFoo3AQAgmgUcWLRo0YK2bt1K69evp1GjRtHw4cNp9+7dutcfN24cpaenuy+pqank5MAC7aYAABDNAj4KxsfHU9OmTcX/O3XqRBs2bKB33nmHPvroI83rc2aDLyVJvRSiFViULR1LVwLcZMwIZCwAACCaBT3HoqCgwKOGIhxp1VjYFQAE0m4KAADgNAEdBXlZY+DAgVS/fn3KzMyk6dOn07Jly2jBgsB2AbVbUpVyHh+X0ggsuHvjbJb1PxuBBQAARLOAjoJpaWn0wAMP0MmTJ0UhJg/L4qDilltuoXDStGaFkGUsgr3dI2cvUaPq5S27PwAAACUpoKPgZ599RpG4V0hsSS6FBNFuOnr6Zpq3/SS1rF2RfhnTy9L7BQAAUBIcv1dIfFwpzcDCzJJFxtVcW5dCOKhge09lmr4NAACAUHJ8YJEgAotSlmQsDp+5VOI1Fm8t3E//nLvD0tsEAACwi+MDC70aCzMBwKE0/9WeVi6x8H4l7yw+QNPWpdBZ7CcCAAARIGq3TTe6p4fs0JmsEs1YpJy/7P5/gUvaXAQAACBMRUVg0bVRFUsyCwd1MhZnMrPd/3I9h0YcY0ry2eLAAgAAIBJERWAxslcT+u+o7sEvhehkLOZuPSH+nb3leOFtx1uTtUg577+mAwAAIJxERWDBSseWCjpjcfTcZcrLd5XYDqf884x46afdNPKrjVQg78UOAAAQAlETWKiZCSzyClwedQ9W3rYWrZ/FwcPszccoO694n5Ppvx2lX3efpuRzyHAAAEBoRW1gYaR4s1x8bEgLOLUChRFTN9BTs7ZR2xeLx6grdZ3nL+VY8nMBAADMiuLAorTf61SrEG+q5VQOLMx2c+TmF9CJi1e9Pr8x+XzR171v92wWAgsAAAitqA0syhvIWFQr773d+8EAMxZTlh0yce+Ijl+4QvkB1kwgYwEAAKEWtYGFkeWK6poZi0sB1Vh8tfaoiXtHdNRALYfa+UsYogUAAKHl+MAiJogCS62MxakM7+UJK4ZvqaWYKMQ85yNj8dSsrfS791fR1dziok8AAACrOTawuL9bffHvPwe1Np2xUNdYaEwGt63dNNlgq6nsXFGNBS+hrD10TowEVyzcdZq2H0svkQ3Olu1Lo1d/3mP7zwEAgPDj2MDi1aHtKHnSIPpDlyTdzckUerUM1St4ZiySqpYz9LPV2ZC8/AKya4aFVo3FD1uP032frKM3ft3vdZ3ks/a3pI74YgN9vOIwrT541vafBQAA4cWxgYUvb9zdgWL8zN3mLyeW9ewcaVKjgqHbr6gKLE6m+18+sWLqprIUomxYtiXlgm4L65WcfHr2v9sp1UQth1GHDRS6AgCAs0RlYHFnp3penzuqqmkoHx/nNceiSY3yXt+Xk1fgN2OReiHwg7eRQVz+ijcPpGWRS9XuqmQsRk/fTDM2pNKNry/VvT2uxxj73TYECAAAYFjUBBbqZQ2195Yc9PiYg4oyXoGFd8aCz/zVypT2/D4zWYGruQViQ7NAl0LkQCLzap57gzR17caBNP+1Fn+btY2+33SM+ryxPKD7AQAA0cu6Pb7DXN3KZemRmxpT3cSyml+fs+U4DWxb2yPrUFYVIDSp6RlYXLycS3Gx3gf/MqU947XU81dM3edrKpelYxcuk9FxFjw0K+NqccGmkrWoWamM+2NfY78bPjtP/LvvX7dSQlysoSmjAAAAUZmxYOMGtqLhNzTU/BoXcL4rZS04Y+EVWKgyFryccFkjY1E+PvilENagmrFiUV9Dsg6czvQKhi5e9j1Ia+neNLIb73ViZ30HAACERlQFFv5sS73o/n/5+Dgqq1oKqVo+nuKlXVK5fXNrSvH36LWbmj2A1jfYheKrzkJrUqi/VtaS2CS1xT9/EfUdO4+nG/4eDv6e+X67x/MEAADhBYFFkb4ta3qN/FZnLFhjVQEnt1X6m5GRYnIppGE172JRo7MsFAdOZ/ktVA2lVQG0pH64/BDN3JhKQz5Ybet9AgAA8xBYFBnTr7nHx+W4xkJjd1N1ncU+1VIDq1jGs01Vaf8MVH0TSyHq6ZtadRJHgphlwTM5srLzPIpXR3610Wfmgbd656FZwe5lIm8Ad9rABFQAACh5CCyIRPdFu3qJ1KlBFffnymvUWBidZRFgM4etNRa846n6c2aGbyke+Pw36v7qYkq/nCs+fm7ODvp192m6/b1Vut+z4sAZMTRr/I+7fN72rhPpYldXI3afzAjwngMAQElAYCEZ06+Z+//l4uO82kbVsyxKa3SEGNnIzM4aC/VSCDuo2urdbMaCA5Q1h85RZnYeHbt42W+Xifx9SoeKnpkbUmjQu6uo2XPzPe731+u0N3FLQ8YCACAsIbCQtKmb6FEnoTVHQs5Y/K7DNVTRz74g9aoEHhywmhUTRHBjxQ6n6sDCbI3FpqPekzwD4Wv5YolGJ0q/N5fT83N30oJdpzRuCzu5AgCEIwQWOsrp7FAq7xdSs1IC3aUxxTPYrIPZZRC9HU7Vw7AuXM51L2UEYuPR8xQMzlxwm2mgdmnUb6DGAgAgPCGw0FFeJ1sgJzF4I7Ox/Vv4vJ2kqtoDufypXzXwjhD1UohyX9UZC6YepGXExuTgMhYszaJMQ7hmLLhIleebBFuoCgAQqaI6sOC5FOyGJtX87vehhadT+rteksZSiHr/Di0NTWYs5AOaki2RA4talXyPNve1b8iOY8ZnTuhJy7Qm0+DrdrTGrJeUdxYfoHnbT9KK/WcoHPBrLZBZIQAAwYqakd5aNjzXT5xh9lHNsFC6QvyJl7Ze16O11Tq3qDauXsHyVtPi/UIK/9+0ZgUxDEveXbVBtfKmzvZ3HE+nHBPbv6udSrcqY6EdWKw7fI7u/Xid+H/ypEFUkritdt+pTPcwL/ng7m83Xbu0n/Cr2DPm3i5JNOnO9iG5DwAQXaI6Y8HFmX1b1dJ80+c5Fv7wUog/9ap4L4Us3HXa7/dxAGAGH/wvFc2ZqFS2NNWomGBJJmRDcnD1FVbXRvDmavLBW/HjthMUKrwjrXrEe8bVXOo1eSmNm73D4/Na992f619dLLa6DwQHFWzhbv+vOQAAK0R1YOGLVRkLblnlDg/Zwj0GAguTRZ/srLQc0kw10KthdXMByyYL6iusDCz4uHzO5OAxu+zRmK2xJeWi2IROXhrp9fpSavKPn2nuluOGb3vNobN0KuOq2OoeACCcIbDQYaTV00jGQms5hPcY8XeArVzOc3qnEUp77PksH4GFyUzIxiBbTe3o5gi3As49Rcsg/vaJ4cwGm7om2XDdTcaVwLt4gsGDynhpBwAgUAgsdPBeIUaKN43Qajn1l5o2syZfpVy8VwEn11lY0caafiVXTCJVCl7N4rNuqxgNUnj+xtuL9otx5Hqe/m6b2Db+ZLq5fV30MhbHLvi/Pd5tttG4n93b1oca/55ueXM5/X7KmlDfFQCIQAgsJAXSWaOlGQutOgsb1ryrFR30z0lDsprWrOhxnfLxcV51F0ZdV78yxQU5rzyYdlP5+WGnM6+KgzFf1NvDy17/ZS+9vegALdun36nx3aZj4t+3Fu7Xvc4/5uwQPytFZyS6VmCResH/+PTFe+zfpl7BWQjld6aH55xw0e/W1IuiRgQAIBAILHTaFNU7lAYTWNTTyFisO3KOrKZkE+SMRbNa3t0njUwuh3SW9lIJJmNhpN1WS75LfynEV+3B1bwCj/HjnObnQsiv1xYvRShyiq6rtRwwfX2K+Pe1BXvFvxcu5YgDdPvxC8QBWCs7cUxjKSSUth4LbMv5U1JHEQCAEQgsJPJupkaChoTSRjMWnoFF4+rl3S2hVqpatC8Jn3HKWQx1vYbZ5ZDODasGeQ9JdE3Iu6MGQr3mH+h+IUptw2erjogA5/kf9DdF4x1pO728kB7/drNXIKQEH98XZTl42JjSZmpmKcQsni2yLfViQIFaoEGd3KoMAGB5YDFx4kTq0qULVaxYkWrWrEl33HEH7du3j5yieoUEeuSmxvTswJZUSpXy18pgxMcarLFQHchvaV2L7FBdo/6BazWs6AzhXwcvhYSygFPdonnaZGBhpJvkwOksETD8vOMULdJZqnBR8f3Zq7EMwm2/WiPWjeClsubPzfeZMZi8YB8N+WA1zd95yh00cAblpslLySonL+oHRv83c6vYywUAwHRgsXz5cho9ejStW7eOFi5cSLm5udS/f3+6dMncplbhaNzAVvToTU3cH88d3UNkL/476gbTGYvalcpYFlio6wxkVctr1040taAzpGXtSlSxTOCdKlYOycpX11gEWK+hBBaBevXnPR5LJFp2n8y0NFvx8FcbxUySMTO36F6HsxVMCT7WHymcNXJUpwbEDL2MBWd05mw5LnafNbrVPQBEh4Amb/7yyy8eH0+dOlVkLjZt2kS9evXS/J7s7GxxUWRkeJ/ZhbNrkyrTvn8N1PxafKyxwEK9S+p19auI5YmLJjYCu5pb4HcpRE1dwGlmKaRLw+DrK4LNWHgthQQ4HpwP9GZaKHmbeb3t2313hAR/gPe15wgXWMr8BT9m6HXJZEl7zXAmqbSx5B0ARIGgaizS0wv3IKhatarP5ZPExET3JSkpiSKZfFwymrHQnPjZMrjlEK2JnkpXiJoVSyFW1FcE23KqzlicleZ1GMEH3rRMc9mSdxcf8Pl1pcbimsplfc6wsAovs3DWwAov/LBTLKEoxalaGYuftp0Q11lz8GxAtz32u230zPeBTQsFgCgNLAoKCmjMmDHUo0cPatu2re71xo0bJwIQ5ZKaGtmTA+WzQqNzLLSYWQ45Lq13c9bDaGAhL4XkFRQY6nhR62xhxiLQokutGguj2aJgl0Ma1yhPLWtXFHM8fLmSmy+WzBpJQVuqjYWbVi53fLW2MBvz8v92e31NWWb567eFSzIjpm7wOf9i/+lMd4Fo5tVcUeA6c2Oqe8y8lg+XHxJzRkoC3zdf80wAIISBBdda7Ny5k2bMmOHzegkJCVSpUiWPSySTD8pmDtCKns2qu/9fzsD4cLZR2q9Da+R4NZ2lkDqJZYKu8q+TaG77dyszFnJ9idlZHIEGFrExMfTPQa0NXbd5rYoey15WLIXoSTlvfV2TXIyq93rxtdwy/bcU6v/WCvp05RF3sKXILvo+rseY8VuK+3b430nzC+eMlMTMDB5E1vS5+XQ5x1xnEgDYFFg8/vjj9L///Y+WLl1K9erVo2hrSf1lzI208P96GdorRPd2pEVpo7fzW1Fxnv59i6MyGssz8hRPI5tfPTdnBw16dyXt1WmhDJZcdBlI96N8381u/25meYKDwL4aO+CqtarjWcvCe4TYRV1fYRduDebMgxHJZwvv0xerj+i+zga8vYKenb2D+r65THwsF34qG6Yt3Zsmll1+2Fq8lwrXxnB7rVW2pgQ2zwNCg7NLh85kUbjgWiqeSitnj8FbqUDTiBxUzJkzh5YsWUKNGjWiaMQdEs1qeR5EguUv1c42GtgIrJpOZ0ggeA7GrhPFxYi9W9QgKySWLe1VvHkgzX/wohyjCqST5VqqThujzNY9jLutlVc3hlqrOpV0p25a/UZ0tGjYV0kIdEjWifSrtEqnFuPwmUt+g66Hvixcbnlyxlb354ZOWSOyIelFBc/8++zz72W060RhnZfe+9X8HSd9dq3w7bR9cYEIZsLlQMpLUgfTQnMw5aFvm46eNz3EzpcxM7bQvO0nA/qeifP3Ut83ltOSveGxO+/Ad1bSgbQsuuejtaG+K84JLHj5Y9q0aTR9+nQxy+LUqVPicuUKordgyWdnWvgNdZ+PsdWKYPfyYH/u2cijXqNMELUkMiXLIBdQrtY5AMlvbNuPp3sVb5oNLMy2nMp1KnoFoBxwKjitr5yBK6x8s7ayxsJIoBComRu8C0GN0vo1cTDHz93HKw+Jj/mN/fDZSzTo3VW6t/PotE006pvN1PJ5z2422ahpm0RW5sGpG+jTlYctzYoY7brhA7ni37/uFwPc+r25XPd7zmRmi4zO5KIJsIG8x3AmUqkx4feUV+bt9vgb5GLbO6esFePcA8HFy746mH7ddYrmbj1Bo6dvNnUi4Gscv/pvbO2hcyKI4efTLqEaHFdQ4PLb3r3zeLrYDTliAospU6aIAszevXtTnTp13JeZM2dSNHv+9sI1+PGDC/8tLRUWGjko8xvpt7+l+t1IS/abVG9hpM7CiCpFEzrv7ZJEdaXuBqtwXQSvyshpcl4W0WoB5RZPxZWi9XD5+2qaXAoxG1gY0VrKWGidkVuZtSjJwOJU+pWAa1p4wNe5ALt2jPhidbLohjHSsrzu8Hm/y38dpSLof83bI86OZ28+5vE9fJDlA/n7S4o7g5T9VuQpshyUGFlqlD32zWZxID9YlLnj4lc1Lmxt88Iv7tt+7ZfCgOKDpYVBllGcAeJM5Ccrj4gg4P5P14n/vyntj7OtaOQ7By9G8XvTwHdW0JMz9GeuaBUyrzxwRhQFGxlY5y/Q4d/9rI2pIqNw3yfrRBDzwdKDFCizU4FLwppDZ+nG15eK5URfr7Pb31tF93+yXmxuGDFLIVqXESNGUDTjM/zkSYNoRI/CpaHyCXF0Y7PqdH3jqpRoYPtzPiPXmoPgK5BQUsp2ZCyCDVD0xJYqJaabqu3WeOwrD5z1WbxZq6K5jAVnG3zNAjGrbmIZj+daa/MxPpOwQnZePp0IYhfWQJ24eNWj28VI5iU33yUGaFmNR8JPWaZ9QFUO9oEc3OW2bc6ocfD31KxtYmdXpcD02f9ud2cT1JYULaHsOJYullQ6TPiV/vTZerGZHR84fXXDMCX42paq/9rgwtZLOfmiOFa9p5EeDtZf+mm35lLRzhPpdN/H69zLncrj5OXYQFu42dQ1yWK5MtDA+b3FB0Ub8/L9/rMR/P6ol01asf8M9XxtCf39++2iLkwpoFa/DtQnMO8sOuCRKf54xSFqN35BwMsuvLwjL6Vdzc2nL9ckexQ6rzpwltYdNrc/lFLgPOzT9eJ3zO/9St0TB2UceJ7Q+N2Hsg4Ee4XY5Os/d6MZI7sbuu63GvMD1DZoZCi0zir0Wk590fqDtaJWQ6GsF/MbgHoKKdNaj+c3Zd/Fm+YCC7u6NVqq6iu0pm5uP2ZNYMHZEDv2mvFVY9FQGqom70WjRQke+QzSDoXTPvV/AWYCuDuurUvLxt5Mz9zaUhyYeOlFCQ55Aqo/O46nU16BS5zxclD8zuID9KfPfhNnmEpdiK+hbgcNFCheLFpq0Jq+yweeXq8vdZ/9f7rqMH2++ojmUhEfCHlZVb1RsZwllJf07v5wjceywuEzWWLmCafk+T3ol50nNX/G/Z+s0818cHCqLO3y7035++YdhLVeN/x8cyCk7M7Lty3vTMwBEb+38HYM3z3q/b777W8pImhQCuC5RumtRfs96nh+2HpC/F3JRev8fPpaHuPXGi/v8EUJuK+fuJhe/HEX3fHBavExdyD98bP1dO/H69zLULwExY9DyT4xDrDUtT5cuHrnlDWiJVvrb/7LtUdF4MnBXThBYBEGFu3xHyFrpdYX7CrcI8LIWG9fZ2prNSJpKzMWszYWbtal182hrrPgCJ3XSe3oCrFrOUTdEaLsalqpTJzHwSfSCjfZyYyrVEbqYjpy1vdB8LZ2tUULtZnJsv40r1XB74RRVxAdX6N6N9Fs5TaqU4Mq9PIdbUWgUjo2Riw5KAHKN+uPUtdXFmtuWR9IseZi1cGHD2h84OTX9Z6i0fK8140vPMjthaIlXDlgUOOTgQ3JF9wb7il1GBwA8N8tBwFaQd6MDSm05tA5+t/2E5o//0xWtlfBOi8DccDy8k+7NbNivByiPHa+bYUSaPFzx9sxVC4qEpdxQMFZn6X70txZOBkvG6gzpxwQ3PT6UneAoOXzVUfcmbTi28oV/yq3JwfiSts1L0ExJfvGP4vH+D8ybZPISCr3+fZ3V4n3DZ7U/J9hHb1+/qGi142RLFZJQmARBjhi5x1P/alZMcGjTfXnHSdNBwRSB6pmRbyZzIceeUKkVqaB/4CUPzi2OeWCeBNQk8/UaprIWChDtexoA1V3hGQWpcDrSTvb8tmNFQWcJVlfobURmd4ynIKXAge1q2PqZ/mbJvrULc0pnPHfzZ+ub0Bv33ud1wH3x63aB1n5AGGEOrDi17ORrjLZzEeupwaq9xytjIU6QOGMyJaiegfepE9rWqtM7i7zdbvyiQP/7Whl/DiwkGejWBmUcz2O+k9z/+kssYmgXtDHg/5+0gmcAsW/e35e+ZJX9LpZti9NPN6211SiX57sRQPa1Pb6vuQSPskwCoFFmLi3q/9R510aVvUICHjNTl34ZCYg4HVi9QGvmkYthBXtnVqBBQcVcnGq1jIIk6vOOROgNbPDl3pVyxpObRsh34zcESJLKvqZyplLoOuepeQnPEQZC3W7qZE3MyOvZy1axYvqv4FezX23P/P681drkwM+2NpFeUxxsd7PpeLo+cum93oJNBPG2Qo54PUVMKqXaHjZUnmrWLY3ze/rWS+w8Pc8a9WcbU31325vNijXqn/QyuAEsiRn1clC14bVqLY05FDB79klfZJhFAKLEjKofeEZHBd1qnHK9M6O9QLeCIwD/AW7TgddvMlnB+qo3KqlEKW4TaGusahftfANTm7N1CrcZHJhGQ/90gpSfCUEkjTeTIMhL6nIxY2+fqaR9X95yad13UqaB6GSxGeQ8qZjWme2Wt0WXNDqC0/gVD9d+w0MZRvb33fWYtq6o/TCD7soXCiv5yY1iluW1YE8P+dmzz63H7/osazqr7OB32+0cPuu2kFVZmG51PY5u6g4lzdq1HPgdKY7ta/OBviiLOmoMzPng9wfhw/EWllDrfZMX5k5fr6+MVAbZ5SRvymt98Nw7WJBYFFCPri/I236Zz9R1KnWv3VtQxmCLo28NwKbryqcMlt0qQ4AqltUvKm+XXWbaI+m1Q2dgWm9OWl1hshtaeo3ECWIscr5S9m6O9gyTjao23aNnF3KwUe7axK9vq6cpfDSmJ34/lcsqhGR+/aPFE3Y9P29MfSHLt5Zi7s6FQfQPIGT50jI9htYEmhfT/9AVnj/wis9rNQLyUP15OmzgdRZaLVmy68XLuK77qVfRUFjIPh21bUzXGgo/y75OlodHPd3q+9zmVdr2YMDDl/0uuS2BVkAzQdi9bwNLjDVCnT8vY74dpShf1pqBVAHZiYLWdKZy0AgsChB6uBByXLf11X/D1NRMSFOM93ORUzywBS9rdMDDQDkjIXWHhJ65DcMLmhSF4aqU3o9mlbzug2OB3jjL62ZBDKtWRY8OVBvBLrVgYU/HPiox7XvOO67rZitls6e4jQCFqWrpYHUqWEFrWxP3aI9YuT9XZLPXtLsTFCTs3DKWbL8uuLPqbNT/g44RpxUFeaFGv/u+Ay3jPRa0DpwGgksuJBWxsEzt7rKzKTn+XbVbdickZOXDXlZg2sOZLws1bCa7/owdcsr32eeXunLnlOevx8lcA90cJeRcfh6baBGRomrgyo58GuncVKge58MBOte3xOmyyAMgUWI8B/KX/s0o+HdG9ANTbwPrmodG1TxOivmgUz8hiWfxHBFO++yGaiNRy94VDbLSyrqCZJ6/v79NjG8Rf7DVK8bq7MMvDQiT7VUqJeMFmt0zvhrOVX6/hXXVCnrUaNiN7m+IpClkDUHffe784GDA5ZgWm61yAW06kBQ7pPngjKtM241+TUUV8rzNfnwjY1ozmM9PIIj3vBN68xRTvdeyvZfvKcUzoYTdSCx22RgoS7y5IM/F1EquCti2djeAd+/I1r1FaqftXy/d5H3H31kKxQ7VcE0Zwj81b9wVk5+3nmDP6uyUeoN/OQOEzlA8Lc0xe+193T2zMrJ39O0pvFtH8wsgyFjAboV7hOGtKVSGmel/uorlLY+rRR0oAWcTWqUFwGKfGCR2wt9TVCUz464rVQOcrQKt7htSn0W31NjOeTGZsUFenxyvHhPWsCpxvk7TnmkPbkrRGuOhl3U9RWcffA19phxz7zWzBI1zr5oFXaaIRdDqie8KjvjqoMOK6rR216TSD/9taf7Yz6QaB1wNkiZJ60lsUigbp82HViozqK1ltYaVi8v/s4CcVijhVidVdAaq93HwOZ86oyFOnjkrjStJZ59UtbCVx1HoNTZASVjIb9vamVw1O7unOReKtR6PuIMvK8zHqKmt01AJC35yRBYRAiuhle7TaelL9DlEH9vDuekWgI1+Q+pa6OqNPuxG0TVuV5gUVh06bvOgjMufFvyPgRa1ef+ztg5jfv9Js9hO0kluBwizwqRz7p82Xz0gmbmQE0eWBWsayoX/x7VY5DrFC2F2PWmJo+811sG0ZqzEmnU6fY9Gn8bfHD3t8RkJLAwQ6tQUc6OcMDHbeAyXq6Mk7Yv8FWIKQcO6o6Q+TtPUe9/L6NPVHt77JYKOPlnmcnEGpljw69ljgHk9xx/HSFsxA0NDXfB+GK2syNcO0IYAosw0qLowCMHutc3riaGAl1b3ztib1yjglctQiBDshQ3+wksjI75nTnyeo+9FxjP3eiqCorUWYNujT2/zn/gcsZEL7Vd08BYb96DRS7i9NcZYuVAy3qqIEZvzVWuX5DrK3xp4Gdd2yyutZHPMJWMRUmcLel1CpgdhRxOuN5HDhqOnLskhiLJ+Az5uMb8BtmhNM/fu7q+wiytjhA5Y8HFuxwbcHZTIXe5+MJLZ/x4i283U/Ngz5MvZXulrA636gZSs+CLVraNb1vOPvib1aJkhtTMPB/JJrJ//FIK1xkWDIFFGPnvYzeIKHjDc/3cn5v25260YEwvSig6s3u8T1Px761Fw1IGtvXOWlQPcCmEsyFcHBoszkaocXFmgmrehHq4VaUynmnbXtIyiC/+lkIqJMSJA6A8SttfAafWkotZ6iCmXT3tN8a50p4aq/3UVyisLtyU/Ufa3EpdbKuki20JLDQOODxS2qo9VkKJg2P5bFY9OtroaG91xsKq341yhq6c1HAQoVW82LuF/6UPLfJjVweQPABq4u/b+a1LsWo5JEXjTP96VZ2b3uu7Q9Hf8O+vu8bra/yc8j4sgdILEJQBiFrTSy9czjFc+xYKCCzCCB8Ix/+ujUf3CNdfyAfsx3o3pSMTb6MP/9RJfDyovXedRaCzLHg31hube9c5WEErG6JV56AsnzC9+6KuxfA3fXOoxh9//WplfU7l5HV+I9XgeuSzUvVSiNYZFw9zks8MtxftLqm8gZVkxuJ3Hep6bXhXV1omkc/S7AgstJZCuL4iwA1DI2c5RDpwKpkhXyshmRpr8Vy4qa5ZChTXrShLjcrgLN7OXS7mVtzkZziZmjLSfrd0wFU/z+VKx4nOuEmq4IIDL/m518ramsGdLcomXoobmni+t+i9B7Qp+hvW+vvj+TJmDvbJOn9LSteHVv1FOGcrGAKLCCQHGlx5zAdQXj5QDthK7YGS5TDiZo0zEV892r7I2/Vq3a5WpkHuoFCWhNQHZfXcBg7EfNHqr9fLWHRIKj6Q86Y+ZsmbLqmXEVrwmrSqoIsLTGX8RsrDtvxtW9/AhloRXnJTMmGK2qoaC2UQWKDbgxuhlX7W2jMm0ihdT+oz9d3SWbxWZ5Sa3rq/epx8oPgAxgENLwUo7cBahaQ86VauQzBCGfAmF3lzMKQ190XG9RQc2MiTe60s4JTrLPhvUl0cb2QpRM1svUuyRgaFx4Vb3Z5akhBYOMBb91xLsx7p7v5j/X3Ha0Q73597ehcXKW8MNVQzNbRSnB01zhCU6FmZZ69F3udD6wCpVXQpBzFaSyp9W/lOwWq9T/Eb7nWqx2Bk+ianHv2NHNYjvxGqC9u4bkRdwDl7i/cgI3/tx/w8c+usv83cZEbHRY++uXCpjfHBhoM3eZmMgyWriui0himpDzhmCzf1pkuGwvWqGiKtjIWReoVDOge7dtcEF1gorw3er0j5rSlZNHkTve6Nq3nUPhnRpm6iqaU85e9E2QFVndUMllz4yAFLufg4j1qXE+mB7ydkdlkqWSNjobXBZKS0mjIEFg7ESynPDWrt0UedPGmQWEJR/oCm/LGT2N56+l8KJ4HWqJgg6js48FDS3ZPv7iCyId9rbEM85IPV9Pai/T7vh1YbKTPT8tmvVS2fX+fdAmdvPkZXVe2I90vDx3iZgh+nL3xc4wMqb6lshtbmaXrLIZx+1hr8xV0yyu1w+yenpeV9SfgNlpev1Onsj1Yc1n3DyvSz/bP7/tVLFGvesjrScggHff4GImkxOmRNfcDRass0gme8lIRTBg5AHODKB2glO8epfiXzYyRjobf8ZFVRIxeDqztC5GmhgS6DKNlHrbbL5n5mPKh3C1Zee1YNuZOXEtSBPB+05SUpZVt3f5TCzTIB7mGktdQxT2ODSa0sR6A/q6SE570CW8iZAM4abPxnP7pBOvhzfQdnPpSDFgcenA3prNHqamTJQGtct/KzA9VGY88MtadmbfPaqvv29oV1A2xTygXNbIhsTL/mYohWsFt+6/Wwt5VqJ5RlkyrSzAH+2XxmyNtVs7lbT1D3iUto9PTNPs/2Pi3ahlnBEwrvnLLG43NvLjQWLHEdj5HlEH/knSiNVsurl8H4Db6x1IlgVAcL0+a+YqKZGzzbmbXw4K+ujYoPXhyYKal+pbaBH6P6pak120FvHogV5B2WlQmb8nKemcJNrv/QCpqa1fIdSOkt7wS7HKJk3+SlEHXhprIMIv9d+ps/w5TCzbY6WRr26+5TtGi397A/eddq3uFXPTVYLzAyE+SXBAQWYMrjNzfVHNolq5AQa1lg4S8g4JS9Vqq0bHzxfcgoGr7kK03OdQZKEWMw9OZltNc4CPxeGn3NAVQVVfGtOkhRv5nwJnLvLfEM8u77eJ3X+GWeE7Ax2f8OkerAoY7q+dJqs/NXyDrDwAFYfYYst1wHqoOf/USCbcWUlyeM1JvIyyH8fKrbxHmJQV3sq2xP7u/AbWQ+ihGNNAI4eaaK0efdyHKI1vNcEoFF/aKg/LRUw6BukVcyQ3IR/aT5e/zeNhduchF4c9Vzy4Gl4v9mbqO/fLXR63vlk4Vfd532W7CsbCtvZ3dYMBBYQEBWP9tHLJ+MHdCCvnv0Bnrj7g5+06QPdC+s9VAO/Hywl1PD/rT30yHB7umSRCv/frPmGG1fB30+k162L402FB1w+Vj4ZN9m7q/729Mg0FZYLuCUcSrz1rbFBZM9VNXpHOjs+9dAerBHcb2M+s3k89VHvKYEcrZAvb04P7aJ8/cG/FjkpRD1ma1RP2w9LiYM+sOPV40zOIHS2hXWDCP3mbcS90cOjji1rnXgbKqqs5i33Xc6nPHtqJfFzGpc3fPnczxrdkfgbUVBES/RaWUbtZ5nWSuNfZFYoMWjakpQLtccqetGlFHi8uucpwpvNDARl/++41XPRznpBIszaVrZNPlkwd8yCFOCWbvm2QQLgQUEhIMDefnkzk71RP3Glw911f2eW1rXEvUdHJQo+I+LC/X8dT+wV4d697hr4dZceRS4Wv+ijgd52uPg91fRiC82uD/mAIPXmtVnj2oTftrltWW9TK/qXf0mxl0Y5aSsivy7lW9LHjes9WbCZ8F/6dnI/TEX8H42vLP7Y87SmB1nru5u0Tqz9YffB3/a5t2Pr9bcgowF/y6sGt3+1dqjfq8zc0NKQDUfPNNBK/BRLxnwzsXq5RA5ZW5F4aasYfVyXgG4mTV83hRR2b+EB66pAwt+PftbTkssV1ozA1m8TBsfVMZC+bWqf5++Xuf/nLtT7PgazLLUd490px9G9xDF9bIG0u/e6EZrfPLi6/6HEgILsM0AqXVRvZTxyQOdac2zfdyBxfCirIZcXMnByLYX+we0hvxA9wZe66OHX72N1o7r4259lQs8+Y9TPntUtkK/41rvGRiyL1YnkxV4GUSetuhveUnOWMg1DH++sZFHhoIzSfKZLA8he+2u9qbuo7rGwuy67reqTeG0AgL1bfPB1l/BrRq/psy2SsuyrubRRyuKh4XpWbj7NJ3L8r3Xg7wfEK/Xa2YsVIEFT7vckuq5dKWuN7GqcLNuYhmPzgjWzEBBqRZ5giYvpaiDKH79GmmF15oqHKyq5eINDwNsImVw+P2Ei205c+GL2eejkep1b6SmLFyzFQyBBVhO6UDxNcCKz9zlWgs+U+fvkaeOcjAiHyDUo7+18Nby/PO3vNDf401d3vNCnuy5/h/9aP6TN3rdjr8+e96V1lfngTod6qvAVR6qo35z16JUxvMBTfFEn+LlG72aFF6u0poRYuSgIzN7trjtWLrH7AY1PotVD3syswzCGRYjG/v5M3VNsqEiXp7RMEeanmrkQKl10NQqcpy33bPtUN2W2u6aypZ3hLh/lonAgjMsHy73DMYqqibr+usIsWo+hxb+s5CzA77INSXjBrYy9D1mA4sGqiBBbx8oX8FIOEFgAbbwV2xp5nvu6VKfPh/RmbaPLw4alFTtMAPbNyt8LXMMNlC4yUs7vCvtHdd5X3dkr8bi33/e3lr827+1fpssnzn5C2BiiiYLyPuiqJdTeHBYeYNnYY/2Lrx/bL3BGRHqsd5m2v6Ulj5f9QhayyDd/cz00GLVvAMjwYKyROWrwFMhB8l8sFX/DpvWqKg71lkvsPDXXWGU1tJEswC2/VYs3HNac7iWvJzmr77CzsCCNaha3tBrSF4GuqtTPerUoIrfjFvz2uaeD/Xvf6BUd6XHaIAUCggsIKL0aVnLY2+RvS8PFBkKrTMuPQ/2aCRGZr9z77Xuz/FtbHuhP/UtmpfRv00tvwfJ1nW8z07+cVsrcVvKAYCzNpyJ4c+ptfGxPq68sTw9oIX4t1JZ/cBBvReLL3KAcs/H6+jRrzf53SWRD4LqKafqDgEegcxFpEwrK8Ejm/2NrNY6SHYzUaynLjYNhno5gAegjZmxxf3xHdddY3qdW53x4roCbvFWlsT4dy5vUMea1CzvccCzrHBTo27GyGwNDy6i/yzTXjqSU/v+OkK0ZlkYbb01wkgnhfr3wRmwf93R1v3xGo3NAjkwDmTasRxwytvcc8Bp5P0sXFtNGQILiDqcJfjh8Z40RFVHwW/scoscZ0Y4KFDseelW+uqhriIwYT2bVaeXh7TRXErxlYkZ27+5+Pdfd+gXpfIAMw5G+hVlPDr6OVtiWlMRlQOVklqVD0qcLPll1ylaUzQ229d27eoCTrli/q4P11DfN5a7P15eNINDnXnwl+XQyljILX9GGSkI9kUpPFTmmsj4cfJsETn1fXt7/2lrLdp1FoW/Vz5A9dOYNssBq97gOaszFoEGFjwbgrtBtCaztpZaTo22x8rLA0csHGFtKLDQ+H3Iz9fGoxcsWwZpWD3wZRC9wELeh8VXEG83BBYAOjgzIgcF3CarbuH8U/eGAadsH+/TTAQNyhu33BXiK9Ow9YVb6MArA6X7F+cxBEwp/PR4A/xnP1o6tje9XHS2VbV88YF6/pO96MZm1Q0Ne1IvhzSU3px3Hs/QXNKRAx0+q7+3a5LPx2gkRa4ESrJ/L9gnunQUdVXFpnrLHGmZvvdj4DoZdUo6J7/AY1Ijn8nKjyuQTaj8dYYMkoa7yQFAoGfF3LXywg87vT4vZwHUSywcSPrbi0dNmVD5h87ez7O83bq6+0SP/Jrae8rcBFazRY9Gh8DpDb8LBP8tydM95fZzowESF3K//steGvjOSo9BW6ES/F7ZAGBJ94zWGaqscjnPosnt4weI1Lwyl4ODIK0lF/lNkv/PLa6cUueee87APPzVJlq05zSNu62l37oFZVjXtdJQoXEDW9LQjtfQE99uESPKuQZFCcy4ZoXnkXENCK9Tv/nrfo83UW6D5YCI5wr4Su1OGdaR0q/keg0PY+8vPaiZdueW29mbj2vWXHy36Rj9d/Mxd9thrkaq/Ym+Tb2KQKc+2EUUwTYa97P7gCkvaQSyt4mc6lfmKiizLDie5aCPD+7KXAUW6F4d7Jn/7vD4WHm9nCia+qmV5Ql4GUQKBrjO6Ot1nm26Z7OKh7WZWS7g575kl0KMPX6XRYWbeVIbq3pHYS01VHVV32/y3a1S0hBYAIQYH7y0AoJgJnz68uGfOrn/z8HIp9K8C19DzngEtTKVlA88nGnhtPfDNzYWj2HGyO5iXxO5A+e9+67zyLrwni+8/KJ0f/DP5zHyyv8ZH8vVx/mBqvQwZxLm7yzsmOA9bjibxBMOeZia0o2k1JPw2OxX5u322BSOMx/yGR0Po/rgfs+f2aJoSBOvtytjnpWx1nyfeRMxZaokBy/KeG6j5ICHb5/nddzato7IpnC7MwcRHKQpRaRKLQfX5vgbosQHuZUHCusAejStJu7nx0V7ySjZCbm2Rp1xMhtYDG5fx9RrsiTVqli4kZ6vpT9+zo2M8Za7hsy2xzYyUYSpZAx5w0S5e4u3ZRj59SYKNQQWAOBB66yY0/bvSkECn0n/d9QNIoMhn9XLQYWWFwa3ppqVEujeLvV1a1CmPtiVHvj8N3r//uKfp1WDknk116uVUT3tU96kTvbzkz3pSk4+3TR5GZnBEyDlKZBVy8cHHFjIj5snVCpLTlz/I6+3K4EFZ5nYqJuaUKmYGBrkYy1eHhD2zV+uF/8qgYWRzbWUjpBKAc4DebR3Ewp3/Hrleh+9qbocdPBympHAwiUVMhhtMbdiHoWS3ZN3vF341E2Gu8PsFh73AgDChrJ04q/Y0kw7IKfcXxpSXF2vhetYjGRwfAUVjLMryo6vj/RqLOoj8vJdIkhSshk8nv7+T9d7jHFXa1C1nDtjocdX17CvllCuk+FiUXm/GJlcA6MUPXJA8uhN2gfwQMZ3aKXub2peU+xD0at54c99qEcjmjR/Lz3h4/fDv0/unuGZLDxHRgu3RFu5fJGdWyCGkpkp7i28vfK6gQW//q2Yg5KWeVVMIbVjHoXWvi3hElSw8LknABA2zC7NhJNxt7Wix25u6nMKJw9m8/dYOVPz5Iyt9PdbC1t/tTxza0sRoMgb2PFyyeaUC9SpgX7LLNfJGM0eyVkeNa714LPXEdKeMnqUOhkex385J08EE4on+zUTtSVKNoWXrPz9fjh7xWfLvnDnDE8xHXqddgCl56fHe9LrC/bS5Ls6uCdg8rJNZnYe9Z68jB7v09Rj3w8Z16b8/j+rRW3SvlPF3RL+6iyUVtNAi1fVGx/O2niMFu1J81k7xYElt5oGWkMSrpuPKRBYAIBjBTPam5c3lMzI5yO6+LyuVoCiXi4xa8GYXqIrwtdtLf5bb4+PH+rZSBSoypvy9W1ZkxbvTfNYruCuJrPD7eJ87BKsdZv/+6vvtmz11FXWrl4iff3nbu6PuX5m5sjrafxPu0Q3ktamelzYqBS9bk7x3HejYlEnldzVpODlJTljxwWcHLD5KuTU6oZ6+MbGYpmN6x+4aNXXGHD+WWaGCYbzDAuGwAIAQMKbua0/ct7vpMVA8dID326guHtHvSuuP7xMpQ50PvMTHBnFWZkft52gp27xnPGhDsq4RuGP3Qr37vGlQ1Lhkgx3ED01a5vf33vnhlXpx9E9RVfP5AX7KC2zsAhXOT5zILj86d60/3SWyASkX8kR//IwMWWybn2NAzN3LfFt3d0pSTdgUwcUctChLJ9ULR8viij/OagVrT50jn7YcpwW7Dolilq5C0qrvkIOLpQAZ8bI6+nej9eJzq3CzxfeNmdojLTD6i1LlYQYl1x9UgIyMjIoMTGR0tPTqVKl0D1wAICSxHMjPlt1hIZcW9fnPjpOwVt7+xpZzzUS3N3CwYfZmgbe1p7raHg8/et3tTdcCMmttj1eWyK6g+T9ifzhfVC45uSD+zvSoAAGo+XmF4jh/Epn0ldrk+mFH3bRS0PaiI4r1vDZeeJfX0tPR85eovyCAmpaVFzb941l7gLOkli+NHr8RmABAABRZ/6OkyID0M3ERnfBcrlcYn8ZLtwMplCUMzHcSj22f4sSCVYRWAAAAECJH78DbrxdsWIFDR48mOrWrSvWhebOnRvsfQUAAACHCDiwuHTpEnXo0IE++OADe+4RAAAARKyAu0IGDhwoLgAAAAAl3m6anZ0tLvIaDQAAADiT7dumT5w4URR7KJekJN9bJwMAAEDksj2wGDdunKggVS6pqal2/0gAAABw6lJIQkKCuAAAAIDz2Z6xAAAAgOgRcMYiKyuLDh486P74yJEjtHXrVqpatSrVr6+/+x4AAAA4X8CBxcaNG+nmm292f/zUU0+Jf4cPH05Tp0619t4BAACAswOL3r17iznnAAAAAGqosQAAAADLILAAAACAyGk3VVOWUTCBEwAAIHIox21/5RAlHlhkZmaKfzGBEwAAIPLwcZwnaeuJcZVwJWZBQQGdOHGCKlasKLZdtzKS4mCFJ3v62ic+kjn9MeLxRT6nP0Y8vsjn9MeYYePj43CBg4q6detSqVKlwidjwXemXr16tt0+/yKd+GKJpseIxxf5nP4Y8fgin9MfYyWbHp+vTIUCxZsAAABgGQQWAAAAYBnHBBa80dmLL77o6A3PnP4Y8fgin9MfIx5f5HP6Y0wIg8dX4sWbAAAA4FyOyVgAAABA6CGwAAAAAMsgsAAAAADLILAAAAAAyyCwAAAAAMs4JrD44IMPqGHDhlSmTBnq1q0b/fbbbxTuJk6cSF26dBHjzWvWrEl33HEH7du3z+M6vXv3FqPP5cujjz7qcZ2UlBQaNGgQlStXTtzO008/TXl5eRQOxo8f73X/W7Zs6f761atXafTo0VStWjWqUKEC3XnnnXT69OmIeXz8mlM/Pr7wY4rU52/FihU0ePBgMbaX7+/cuXM9vs6NZC+88ALVqVOHypYtS/369aMDBw54XOf8+fM0bNgwMfmvcuXK9Oc//5mysrI8rrN9+3a68cYbxd8sjyB+/fXXQ/74cnNz6ZlnnqF27dpR+fLlxXUeeOABsQ2Bv+d90qRJYf/42IgRI7zu+6233hoxz5+Rx6j1N8mXyZMnR8RzaOTYYNV757Jly6hjx46iPbVp06Y0derU4B+AywFmzJjhio+Pd33++eeuXbt2uR5++GFX5cqVXadPn3aFswEDBri++OIL186dO11bt2513Xbbba769eu7srKy3Ne56aabxOM5efKk+5Kenu7+el5enqtt27aufv36ubZs2eL6+eefXdWrV3eNGzfOFQ5efPFFV5s2bTzu/5kzZ9xff/TRR11JSUmuxYsXuzZu3Oi6/vrrXTfccEPEPL60tDSPx7Zw4UJu33YtXbo0Yp8/vg/PPfeca/bs2eKxzJkzx+PrkyZNciUmJrrmzp3r2rZtm+t3v/udq1GjRq4rV664r3Prrbe6OnTo4Fq3bp1r5cqVrqZNm7ruu+8+99f5d1CrVi3XsGHDxOv/22+/dZUtW9b10UcfhfTxXbx4UTwXM2fOdO3du9e1du1aV9euXV2dOnXyuI0GDRq4XnrpJY/nVf67DdfHx4YPHy6eH/m+nz9/3uM64fz8GXmM8mPjCx8bYmJiXIcOHYqI53CAgWODFe+dhw8fdpUrV8711FNPuXbv3u167733XLGxsa5ffvklqPvviMCC//BHjx7t/jg/P99Vt25d18SJE12RhA9S/EeyfPly9+f4wPTkk0/qfg+/WEqVKuU6deqU+3NTpkxxVapUyZWdne0Kh8CC36C08Jt46dKlXd999537c3v27BG/A35Dj4THp8bPVZMmTVwFBQWOeP7Ub9r8uGrXru2aPHmyx/OYkJAg3ngZv0Hx923YsMF9nfnz54s39uPHj4uP//Of/7iqVKni8RifeeYZV4sWLVwlSeugpPbbb7+J6x09etTjoPTWW2/pfk84Pz4OLIYMGaL7PZH0/Bl9Dvnx9unTx+NzkfIcah0brHrv/Pvf/y5O/GT33HOPCGyCEfFLITk5ObRp0yaRjpU3OuOP165dS5EkPT1d/Fu1alWPz3/zzTdUvXp1atu2LY0bN44uX77s/ho/Rk7b1qpVy/25AQMGiB3udu3aReGA0+ScsmzcuLFIr3J6jvHzxqln+bnjZZL69eu7n7tIeHzya3HatGn00EMPeezcG+nPn+zIkSN06tQpj+eMNyXi5Uf5OeP0eefOnd3X4evz3+X69evd1+nVqxfFx8d7PG5O9164cIHC7e+Sn09+TDJOm3Ma+rrrrhMpdjnFHO6Pj9PfnBpv0aIFjRo1is6dO+f+mtOeP14emDdvnljOUYuU5zBddWyw6r2TryPfhnKdYI+dJb67qdXOnj1L+fn5Hr88xh/v3buXIgVvJz9mzBjq0aOHOAAp7r//fmrQoIE4MPN6H6//8gt79uzZ4uv8Jq/12JWvhRofcHjNjt/ATp48SRMmTBBrljt37hT3j/9o1W/YfP+V+x7uj0/G67wXL14Ua9hOef7UlPukdZ/l54wPWrK4uDjxpihfp1GjRl63oXytSpUqFA54HZufs/vuu89jp8gnnnhCrEvzY1qzZo0IGPn1/eabb4b94+N6it///vfi/h06dIj+8Y9/0MCBA8XBJDY21lHPH/vyyy9FrQI/ZlmkPIcFGscGq9479a7DwceVK1dEDVVUBhZOwUU4fLBdtWqVx+dHjhzp/j9Hn1ww17dvX/GG0KRJEwp3/IalaN++vQg0+EA7a9Ys0y/acPXZZ5+Jx8tBhFOev2jGZ4R/+MMfRLHqlClTPL721FNPebyu+U3+kUceEUV34b4Hxb333uvxmuT7z69FzmLwa9NpPv/8c5Ep5QLMSHwOR+scG8JZxC+FcIqZo2x1NSx/XLt2bYoEjz/+OP3vf/+jpUuXUr169Xxelw/M7ODBg+Jffoxaj135WrjhCLt58+bi/vP94+UDPsvXe+4i5fEdPXqUFi1aRH/5y18c/fwp98nX3xv/m5aW5vF1TjFzp0GkPK9KUMHP68KFCz2yFXrPKz/G5OTkiHh8Ml6i5PdR+TUZ6c+fYuXKlSJD6O/vMlyfw8d1jg1WvXfqXYdf78Gc+EV8YMFRZqdOnWjx4sUeqSP+uHv37hTO+EyIXzhz5syhJUuWeKXdtGzdulX8y2e+jB/jjh07PN4IlDfC1q1bU7jhljU+W+f7z89b6dKlPZ47fhPgGgzluYuUx/fFF1+I9DG3djn5+ePXKL8Zyc8Zp0157V1+zvgNj9eBFfz65r9LJbDi63DLIB/A5cfNS2ahTqMrQQXXBnGwyGvw/vDzyjUIyhJCOD8+tWPHjokaC/k1GcnPnzqLyO8zHTp0iKjn0OXn2GDVeydfR74N5TpBHztdDmk35ar0qVOniormkSNHinZTuRo2HI0aNUq07S1btsyj5eny5cvi6wcPHhTtUNxKdOTIEdcPP/zgaty4satXr15eLUX9+/cXbUncJlSjRo2wacf829/+Jh4f3//Vq1eL1idueeIqZ6VlituolixZIh5n9+7dxSVSHp/ShcSPgSvGZZH6/GVmZor2NL7wW8Sbb74p/q90RXC7Kf998ePZvn27qLjXaje97rrrXOvXr3etWrXK1axZM492Ra5q51a+P/3pT6Kljv+Gue2tJFr5fD2+nJwc0T5br1498XzIf5dKJf2aNWtENwF/ndsXp02bJp6zBx54IOwfH39t7NixonOAX5OLFi1ydezYUTw/V69ejYjnz99jlNtF+T5xJ4RauD+Ho/wcG6x671TaTZ9++mnRVfLBBx+g3VTG/bf8S+Z5Ftx+yv3X4Y7/ILQu3L/MUlJSxEGoatWqInDiXnJ+AchzEFhycrJr4MCBoseaD9p8MM/NzXWFA25dqlOnjnherrnmGvExH3AVfDB67LHHRFsXv8CHDh0q/oAi5fGxBQsWiOdt3759Hp+P1OePZ3BovS65TVFpOX3++efFmy4/rr59+3o99nPnzokDUYUKFUR724MPPigOBjKegdGzZ09xG/za4IAl1I+PD7Z6f5fKbJJNmza5unXrJt74y5Qp42rVqpXr1Vdf9Tgwh+vj4wMTH2j4AMPtitxyyXNW1Cdh4fz8+XuMCg4A+G+KAwS1cH8Oyc+xwcr3Tv5dXnvtteI9mk985J9hVkzRgwAAAAAIWsTXWAAAAED4QGABAAAAlkFgAQAAAJZBYAEAAACWQWABAAAAlkFgAQAAAJZBYAEAAACWQWABAAAAlkFgAQAAAJZBYAEAAACWQWABAAAAZJX/B/lHSNeQt5LfAAAAAElFTkSuQmCC"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T00:01:51.064651Z",
     "start_time": "2025-01-29T00:01:34.098341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load trained model\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.WEIGHTS = \"output/model_final.pth\"\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # Only barnacle class\n",
    "cfg.TEST.DETECTIONS_PER_IMAGE = 5000\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TEST = 5000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 5000\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.75  # Set the testing threshold for this model\n",
    "cfg.INPUT.MIN_SIZE_TEST = 250 # min size yields best predictions with 0 for zoomed out images and 250 for zoomed in images\n",
    "cfg.INPUT.MAX_SIZE_TEST = 9999\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# Predict on a new ROI\n",
    "roi = cv2.imread(\"barnacle_dataset/test/roi_unseen_img2.png\")\n",
    "if roi is None:\n",
    "    raise FileNotFoundError(\"The test image was not found or could not be read.\")\n",
    "\n",
    "# Resize the image\n",
    "new_width = 1800  # Set the desired width\n",
    "new_height = 1800  # Set the desired height\n",
    "roi = cv2.resize(roi, (new_width, new_height))\n",
    "\n",
    "outputs = predictor(roi)\n",
    "\n",
    "# Visualize results\n",
    "v = Visualizer(roi[:, :, ::-1], scale=0.5)\n",
    "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "\n",
    "# Save the output image\n",
    "output_image = out.get_image()[:, :, ::-1]\n",
    "# cv2.imwrite(\"output/images/result.png\", output_image)\n",
    "\n",
    "# Optionally, display the image\n",
    "cv2.imshow(\"Result\", output_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# count barnacles\n",
    "num_barnacles = len(outputs[\"instances\"])\n",
    "print(f\"Number of barnacles detected: {num_barnacles}\")"
   ],
   "id": "8d7d8d50ce89d6de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[01/29 02:01:34 d2.checkpoint.detection_checkpoint]: \u001B[0m[DetectionCheckpointer] Loading from output/model_final.pth ...\n",
      "Number of barnacles detected: 148\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "58005e27a1125de5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
