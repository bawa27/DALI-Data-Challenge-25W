{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-28T17:55:34.849512Z",
     "start_time": "2025-01-28T17:55:28.805943Z"
    }
   },
   "source": [
    "import torch\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import warnings\n",
    "# These warnings are not impactful on the output\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\".*incompatible shapes.*\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T17:55:38.145774Z",
     "start_time": "2025-01-28T17:55:38.141747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # this block is used when changing the registered dataset\n",
    "#\n",
    "# from detectron2.data import MetadataCatalog\n",
    "# # remove metadata of dataset from registry\n",
    "# MetadataCatalog.remove(\"barnacle_train\")"
   ],
   "id": "3c224e1a0f1dc78d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T17:55:40.002526Z",
     "start_time": "2025-01-28T17:55:39.997694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Register dataset\n",
    "register_coco_instances(\n",
    "    \"barnacle_train\",\n",
    "    {},\n",
    "    \"barnacle_dataset/annotations/train.json\",  # COCO-style annotations (see below)\n",
    "    \"barnacle_dataset/train/images\"  # Path to image directory\n",
    ")"
   ],
   "id": "6be6f8dfdc2f5efc",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T17:55:40.459288Z",
     "start_time": "2025-01-28T17:55:40.445424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create config\n",
    "cfg = get_cfg()\n",
    "\n",
    "# load base from model zoo\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "\n",
    "# dataset config\n",
    "cfg.DATASETS.TRAIN = (\"barnacle_train\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 1\n",
    "\n",
    "# model config\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1 # Only barnacle class\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256\n",
    "\n",
    "# memory optimization\n",
    "cfg.TEST.DETECTIONS_PER_IMAGE = 3000  # Increased to handle dense clusters\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TRAIN = 5000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TRAIN = 5000\n",
    "cfg.SOLVER.AMP.ENABLED = True  # Automatic Mixed Precision\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "# Training Configuration\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00005\n",
    "cfg.SOLVER.MAX_ITER = 4000\n",
    "cfg.SOLVER.STEPS = [2500, 3500]\n",
    "cfg.SOLVER.GAMMA = 0.1\n",
    "\n",
    "# Warmup Configuration\n",
    "cfg.SOLVER.WARMUP_FACTOR = 1.0 / 1000\n",
    "cfg.SOLVER.WARMUP_ITERS = 100\n",
    "cfg.SOLVER.WARMUP_METHOD = \"linear\"\n",
    "\n",
    "# Gradient Clipping\n",
    "cfg.SOLVER.CLIP_GRADIENTS.ENABLED = True\n",
    "cfg.SOLVER.CLIP_GRADIENTS.CLIP_TYPE = \"norm\"\n",
    "cfg.SOLVER.CLIP_GRADIENTS.CLIP_VALUE = 1.0"
   ],
   "id": "6168ad10b0a56de",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T16:59:25.951202Z",
     "start_time": "2025-01-28T16:25:44.390759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Start training\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ],
   "id": "fac15c05f4505017",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[01/28 18:25:44 d2.engine.defaults]: \u001B[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001B[32m[01/28 18:25:46 d2.data.datasets.coco]: \u001B[0mLoading barnacle_dataset/annotations/train.json takes 1.07 seconds.\n",
      "\u001B[32m[01/28 18:25:46 d2.data.datasets.coco]: \u001B[0mLoaded 100 images in COCO format from barnacle_dataset/annotations/train.json\n",
      "\u001B[5m\u001B[31mWARNING\u001B[0m \u001B[32m[01/28 18:25:46 d2.data.datasets.coco]: \u001B[0mFiltered out 4660 instances without valid segmentation. There might be issues in your dataset generation process.  Please check https://detectron2.readthedocs.io/en/latest/tutorials/datasets.html carefully\n",
      "\u001B[32m[01/28 18:25:46 d2.data.build]: \u001B[0mRemoved 0 images with no usable annotations. 100 images left.\n",
      "\u001B[32m[01/28 18:25:46 d2.data.build]: \u001B[0mDistribution of instances among all 1 categories:\n",
      "\u001B[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|  barnacle  | 64890        |\n",
      "|            |              |\u001B[0m\n",
      "\u001B[32m[01/28 18:25:46 d2.data.dataset_mapper]: \u001B[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001B[32m[01/28 18:25:46 d2.data.build]: \u001B[0mUsing training sampler TrainingSampler\n",
      "\u001B[32m[01/28 18:25:46 d2.data.common]: \u001B[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001B[32m[01/28 18:25:46 d2.data.common]: \u001B[0mSerializing 100 elements to byte tensors and concatenating them all ...\n",
      "\u001B[32m[01/28 18:25:46 d2.data.common]: \u001B[0mSerialized dataset takes 19.38 MiB\n",
      "\u001B[32m[01/28 18:25:46 d2.data.build]: \u001B[0mMaking batched data loader with batch_size=1\n",
      "\u001B[32m[01/28 18:25:46 d2.checkpoint.detection_checkpoint]: \u001B[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001B[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001B[0m\n",
      "\u001B[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001B[0m\n",
      "\u001B[34mroi_heads.mask_head.predictor.{bias, weight}\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[01/28 18:25:46 d2.engine.train_loop]: \u001B[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aryan Bawa\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torch\\functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3596.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "C:\\Users\\Aryan Bawa\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[01/28 18:26:17 d2.utils.events]: \u001B[0m eta: 0:25:03  iter: 19  total_loss: 5.12  loss_cls: 0.6837  loss_box_reg: 0.3386  loss_mask: 0.694  loss_rpn_cls: 2.732  loss_rpn_loc: 0.4536    time: 1.2659  last_time: 2.5167  data_time: 0.2450  last_data_time: 0.0039   lr: 1.9131e-05  max_mem: 7199M\n",
      "\u001B[32m[01/28 18:26:37 d2.utils.events]: \u001B[0m eta: 0:23:02  iter: 39  total_loss: 2.491  loss_cls: 0.579  loss_box_reg: 0.4084  loss_mask: 0.6802  loss_rpn_cls: 0.4574  loss_rpn_loc: 0.3764    time: 1.1148  last_time: 0.2212  data_time: 0.0020  last_data_time: 0.0008   lr: 3.9111e-05  max_mem: 7199M\n",
      "\u001B[32m[01/28 18:27:01 d2.utils.events]: \u001B[0m eta: 0:24:39  iter: 59  total_loss: 2.257  loss_cls: 0.5165  loss_box_reg: 0.357  loss_mask: 0.6454  loss_rpn_cls: 0.4012  loss_rpn_loc: 0.3637    time: 1.1492  last_time: 1.1366  data_time: 0.0020  last_data_time: 0.0013   lr: 5.9091e-05  max_mem: 7360M\n",
      "\u001B[32m[01/28 18:27:27 d2.utils.events]: \u001B[0m eta: 0:25:07  iter: 79  total_loss: 2.088  loss_cls: 0.4686  loss_box_reg: 0.3721  loss_mask: 0.6055  loss_rpn_cls: 0.3554  loss_rpn_loc: 0.3214    time: 1.1821  last_time: 2.2857  data_time: 0.0022  last_data_time: 0.0034   lr: 7.9071e-05  max_mem: 7360M\n",
      "\u001B[32m[01/28 18:27:43 d2.utils.events]: \u001B[0m eta: 0:23:32  iter: 99  total_loss: 2.121  loss_cls: 0.4186  loss_box_reg: 0.4199  loss_mask: 0.5655  loss_rpn_cls: 0.3379  loss_rpn_loc: 0.3284    time: 1.1049  last_time: 2.1965  data_time: 0.0017  last_data_time: 0.0036   lr: 9.9051e-05  max_mem: 7360M\n",
      "\u001B[32m[01/28 18:28:11 d2.utils.events]: \u001B[0m eta: 0:24:36  iter: 119  total_loss: 1.958  loss_cls: 0.4072  loss_box_reg: 0.304  loss_mask: 0.5755  loss_rpn_cls: 0.3419  loss_rpn_loc: 0.3426    time: 1.1533  last_time: 0.8314  data_time: 0.0028  last_data_time: 0.0014   lr: 0.00011903  max_mem: 7360M\n",
      "\u001B[32m[01/28 18:28:31 d2.utils.events]: \u001B[0m eta: 0:23:08  iter: 139  total_loss: 1.884  loss_cls: 0.3404  loss_box_reg: 0.3625  loss_mask: 0.5202  loss_rpn_cls: 0.3378  loss_rpn_loc: 0.3208    time: 1.1346  last_time: 0.2035  data_time: 0.0074  last_data_time: 0.0013   lr: 0.00013901  max_mem: 7360M\n",
      "\u001B[32m[01/28 18:28:48 d2.utils.events]: \u001B[0m eta: 0:22:41  iter: 159  total_loss: 1.869  loss_cls: 0.3112  loss_box_reg: 0.387  loss_mask: 0.4994  loss_rpn_cls: 0.3213  loss_rpn_loc: 0.312    time: 1.0999  last_time: 1.1064  data_time: 0.0018  last_data_time: 0.0012   lr: 0.00015  max_mem: 7360M\n",
      "\u001B[32m[01/28 18:29:08 d2.utils.events]: \u001B[0m eta: 0:21:57  iter: 179  total_loss: 1.776  loss_cls: 0.2807  loss_box_reg: 0.4053  loss_mask: 0.4675  loss_rpn_cls: 0.2949  loss_rpn_loc: 0.3272    time: 1.0837  last_time: 0.2120  data_time: 0.0018  last_data_time: 0.0012   lr: 0.00015  max_mem: 7360M\n",
      "\u001B[32m[01/28 18:29:25 d2.utils.events]: \u001B[0m eta: 0:21:26  iter: 199  total_loss: 1.695  loss_cls: 0.2311  loss_box_reg: 0.3712  loss_mask: 0.4382  loss_rpn_cls: 0.2879  loss_rpn_loc: 0.3028    time: 1.0617  last_time: 0.7048  data_time: 0.0016  last_data_time: 0.0027   lr: 0.00015  max_mem: 7360M\n",
      "\u001B[32m[01/28 18:29:44 d2.utils.events]: \u001B[0m eta: 0:21:04  iter: 219  total_loss: 1.62  loss_cls: 0.2284  loss_box_reg: 0.3942  loss_mask: 0.4174  loss_rpn_cls: 0.2766  loss_rpn_loc: 0.2974    time: 1.0526  last_time: 0.2235  data_time: 0.0019  last_data_time: 0.0008   lr: 0.00015  max_mem: 7360M\n",
      "\u001B[32m[01/28 18:30:09 d2.utils.events]: \u001B[0m eta: 0:21:13  iter: 239  total_loss: 1.627  loss_cls: 0.2673  loss_box_reg: 0.3627  loss_mask: 0.4114  loss_rpn_cls: 0.3003  loss_rpn_loc: 0.3225    time: 1.0703  last_time: 0.7642  data_time: 0.0021  last_data_time: 0.0012   lr: 0.00015  max_mem: 7360M\n",
      "\u001B[32m[01/28 18:30:33 d2.utils.events]: \u001B[0m eta: 0:21:29  iter: 259  total_loss: 1.607  loss_cls: 0.2339  loss_box_reg: 0.3628  loss_mask: 0.4009  loss_rpn_cls: 0.2707  loss_rpn_loc: 0.2811    time: 1.0797  last_time: 1.1913  data_time: 0.0022  last_data_time: 0.0014   lr: 0.00015  max_mem: 7360M\n",
      "\u001B[32m[01/28 18:30:51 d2.utils.events]: \u001B[0m eta: 0:21:22  iter: 279  total_loss: 1.566  loss_cls: 0.2342  loss_box_reg: 0.3932  loss_mask: 0.3935  loss_rpn_cls: 0.2487  loss_rpn_loc: 0.31    time: 1.0660  last_time: 0.2200  data_time: 0.0015  last_data_time: 0.0009   lr: 0.00015  max_mem: 7360M\n",
      "\u001B[32m[01/28 18:31:13 d2.utils.events]: \u001B[0m eta: 0:21:07  iter: 299  total_loss: 1.551  loss_cls: 0.2236  loss_box_reg: 0.3485  loss_mask: 0.3955  loss_rpn_cls: 0.2674  loss_rpn_loc: 0.306    time: 1.0687  last_time: 0.2038  data_time: 0.0020  last_data_time: 0.0011   lr: 0.00015  max_mem: 7360M\n",
      "\u001B[32m[01/28 18:31:35 d2.utils.events]: \u001B[0m eta: 0:20:52  iter: 319  total_loss: 1.543  loss_cls: 0.2294  loss_box_reg: 0.4047  loss_mask: 0.3855  loss_rpn_cls: 0.2458  loss_rpn_loc: 0.2982    time: 1.0708  last_time: 0.2100  data_time: 0.0022  last_data_time: 0.0006   lr: 0.00015  max_mem: 7363M\n",
      "\u001B[32m[01/28 18:31:57 d2.utils.events]: \u001B[0m eta: 0:20:37  iter: 339  total_loss: 1.532  loss_cls: 0.2247  loss_box_reg: 0.3375  loss_mask: 0.3933  loss_rpn_cls: 0.2753  loss_rpn_loc: 0.3137    time: 1.0729  last_time: 2.1316  data_time: 0.0028  last_data_time: 0.0033   lr: 0.00015  max_mem: 7363M\n",
      "\u001B[32m[01/28 18:32:21 d2.utils.events]: \u001B[0m eta: 0:20:22  iter: 359  total_loss: 1.524  loss_cls: 0.2172  loss_box_reg: 0.3538  loss_mask: 0.3883  loss_rpn_cls: 0.2411  loss_rpn_loc: 0.2989    time: 1.0774  last_time: 2.4612  data_time: 0.0024  last_data_time: 0.0040   lr: 0.00015  max_mem: 7363M\n",
      "\u001B[32m[01/28 18:32:39 d2.utils.events]: \u001B[0m eta: 0:20:07  iter: 379  total_loss: 1.528  loss_cls: 0.199  loss_box_reg: 0.3651  loss_mask: 0.4036  loss_rpn_cls: 0.2587  loss_rpn_loc: 0.2904    time: 1.0703  last_time: 0.2119  data_time: 0.0024  last_data_time: 0.0014   lr: 0.00015  max_mem: 7363M\n",
      "\u001B[32m[01/28 18:32:59 d2.utils.events]: \u001B[0m eta: 0:19:49  iter: 399  total_loss: 1.475  loss_cls: 0.1874  loss_box_reg: 0.3776  loss_mask: 0.3935  loss_rpn_cls: 0.2432  loss_rpn_loc: 0.2988    time: 1.0649  last_time: 0.2475  data_time: 0.0021  last_data_time: 0.0016   lr: 0.00015  max_mem: 7363M\n",
      "\u001B[32m[01/28 18:33:24 d2.utils.events]: \u001B[0m eta: 0:19:34  iter: 419  total_loss: 1.468  loss_cls: 0.2151  loss_box_reg: 0.3594  loss_mask: 0.3902  loss_rpn_cls: 0.2215  loss_rpn_loc: 0.3197    time: 1.0756  last_time: 0.6960  data_time: 0.0033  last_data_time: 0.0017   lr: 0.00015  max_mem: 7363M\n",
      "\u001B[32m[01/28 18:33:42 d2.utils.events]: \u001B[0m eta: 0:19:13  iter: 439  total_loss: 1.492  loss_cls: 0.1862  loss_box_reg: 0.3588  loss_mask: 0.3694  loss_rpn_cls: 0.2274  loss_rpn_loc: 0.2956    time: 1.0664  last_time: 0.2462  data_time: 0.0029  last_data_time: 0.0015   lr: 0.00015  max_mem: 7363M\n",
      "\u001B[32m[01/28 18:34:04 d2.utils.events]: \u001B[0m eta: 0:19:01  iter: 459  total_loss: 1.459  loss_cls: 0.2034  loss_box_reg: 0.3347  loss_mask: 0.3727  loss_rpn_cls: 0.2563  loss_rpn_loc: 0.2653    time: 1.0677  last_time: 0.6801  data_time: 0.0074  last_data_time: 0.0035   lr: 0.00015  max_mem: 7363M\n",
      "\u001B[32m[01/28 18:34:24 d2.utils.events]: \u001B[0m eta: 0:18:50  iter: 479  total_loss: 1.433  loss_cls: 0.1834  loss_box_reg: 0.3706  loss_mask: 0.385  loss_rpn_cls: 0.2302  loss_rpn_loc: 0.2996    time: 1.0645  last_time: 1.8564  data_time: 0.0031  last_data_time: 0.0062   lr: 0.00015  max_mem: 7363M\n",
      "\u001B[32m[01/28 18:34:41 d2.utils.events]: \u001B[0m eta: 0:18:24  iter: 499  total_loss: 1.417  loss_cls: 0.1928  loss_box_reg: 0.3803  loss_mask: 0.3789  loss_rpn_cls: 0.2509  loss_rpn_loc: 0.2845    time: 1.0569  last_time: 2.3232  data_time: 0.0033  last_data_time: 0.0086   lr: 0.00015  max_mem: 7363M\n",
      "\u001B[32m[01/28 18:35:04 d2.utils.events]: \u001B[0m eta: 0:18:17  iter: 519  total_loss: 1.448  loss_cls: 0.2021  loss_box_reg: 0.3444  loss_mask: 0.3838  loss_rpn_cls: 0.2328  loss_rpn_loc: 0.2911    time: 1.0600  last_time: 0.6468  data_time: 0.0031  last_data_time: 0.0018   lr: 0.00015  max_mem: 7363M\n",
      "\u001B[32m[01/28 18:35:24 d2.utils.events]: \u001B[0m eta: 0:18:05  iter: 539  total_loss: 1.39  loss_cls: 0.1856  loss_box_reg: 0.3569  loss_mask: 0.3487  loss_rpn_cls: 0.2245  loss_rpn_loc: 0.2699    time: 1.0585  last_time: 2.0033  data_time: 0.0052  last_data_time: 0.0050   lr: 0.00015  max_mem: 7363M\n",
      "\u001B[32m[01/28 18:35:40 d2.utils.events]: \u001B[0m eta: 0:17:36  iter: 559  total_loss: 1.375  loss_cls: 0.1697  loss_box_reg: 0.3636  loss_mask: 0.3685  loss_rpn_cls: 0.2236  loss_rpn_loc: 0.2704    time: 1.0487  last_time: 0.6229  data_time: 0.0029  last_data_time: 0.0020   lr: 0.00015  max_mem: 7363M\n",
      "\u001B[32m[01/28 18:35:58 d2.utils.events]: \u001B[0m eta: 0:17:18  iter: 579  total_loss: 1.418  loss_cls: 0.1811  loss_box_reg: 0.371  loss_mask: 0.3766  loss_rpn_cls: 0.2203  loss_rpn_loc: 0.2973    time: 1.0432  last_time: 1.0475  data_time: 0.0031  last_data_time: 0.0022   lr: 0.00015  max_mem: 7363M\n",
      "\u001B[32m[01/28 18:36:21 d2.utils.events]: \u001B[0m eta: 0:17:10  iter: 599  total_loss: 1.435  loss_cls: 0.1853  loss_box_reg: 0.3289  loss_mask: 0.3827  loss_rpn_cls: 0.2462  loss_rpn_loc: 0.3187    time: 1.0475  last_time: 2.0096  data_time: 0.0030  last_data_time: 0.0058   lr: 0.00015  max_mem: 7363M\n",
      "\u001B[32m[01/28 18:36:42 d2.utils.events]: \u001B[0m eta: 0:16:52  iter: 619  total_loss: 1.402  loss_cls: 0.1944  loss_box_reg: 0.3626  loss_mask: 0.3665  loss_rpn_cls: 0.2156  loss_rpn_loc: 0.2685    time: 1.0465  last_time: 0.2357  data_time: 0.0030  last_data_time: 0.0012   lr: 0.00015  max_mem: 7363M\n",
      "\u001B[32m[01/28 18:36:58 d2.utils.events]: \u001B[0m eta: 0:16:31  iter: 639  total_loss: 1.372  loss_cls: 0.1808  loss_box_reg: 0.4156  loss_mask: 0.3662  loss_rpn_cls: 0.2305  loss_rpn_loc: 0.2681    time: 1.0389  last_time: 0.2862  data_time: 0.0039  last_data_time: 0.0321   lr: 0.00015  max_mem: 7363M\n",
      "\u001B[32m[01/28 18:37:23 d2.utils.events]: \u001B[0m eta: 0:16:22  iter: 659  total_loss: 1.351  loss_cls: 0.1665  loss_box_reg: 0.3222  loss_mask: 0.3673  loss_rpn_cls: 0.2372  loss_rpn_loc: 0.2894    time: 1.0463  last_time: 0.7342  data_time: 0.0033  last_data_time: 0.0019   lr: 0.00015  max_mem: 7363M\n",
      "\u001B[32m[01/28 18:37:39 d2.utils.events]: \u001B[0m eta: 0:16:02  iter: 679  total_loss: 1.39  loss_cls: 0.1663  loss_box_reg: 0.352  loss_mask: 0.3574  loss_rpn_cls: 0.2233  loss_rpn_loc: 0.2793    time: 1.0384  last_time: 0.2289  data_time: 0.0027  last_data_time: 0.0018   lr: 0.00015  max_mem: 7363M\n",
      "\u001B[32m[01/28 18:37:58 d2.utils.events]: \u001B[0m eta: 0:15:44  iter: 699  total_loss: 1.42  loss_cls: 0.1682  loss_box_reg: 0.3398  loss_mask: 0.3794  loss_rpn_cls: 0.2427  loss_rpn_loc: 0.2987    time: 1.0357  last_time: 0.2511  data_time: 0.0025  last_data_time: 0.0022   lr: 0.00015  max_mem: 7363M\n",
      "\u001B[32m[01/28 18:38:16 d2.utils.events]: \u001B[0m eta: 0:15:30  iter: 719  total_loss: 1.382  loss_cls: 0.1881  loss_box_reg: 0.3389  loss_mask: 0.381  loss_rpn_cls: 0.219  loss_rpn_loc: 0.3073    time: 1.0325  last_time: 0.2262  data_time: 0.0026  last_data_time: 0.0013   lr: 0.00015  max_mem: 7363M\n",
      "\u001B[32m[01/28 18:38:38 d2.utils.events]: \u001B[0m eta: 0:15:11  iter: 739  total_loss: 1.374  loss_cls: 0.1648  loss_box_reg: 0.3224  loss_mask: 0.37  loss_rpn_cls: 0.239  loss_rpn_loc: 0.307    time: 1.0337  last_time: 0.7055  data_time: 0.0036  last_data_time: 0.0022   lr: 0.00015  max_mem: 7363M\n",
      "\u001B[32m[01/28 18:38:54 d2.utils.events]: \u001B[0m eta: 0:14:54  iter: 759  total_loss: 1.338  loss_cls: 0.166  loss_box_reg: 0.3664  loss_mask: 0.3545  loss_rpn_cls: 0.1975  loss_rpn_loc: 0.2781    time: 1.0273  last_time: 0.2165  data_time: 0.0080  last_data_time: 0.0012   lr: 0.00015  max_mem: 7363M\n",
      "\u001B[32m[01/28 18:39:12 d2.utils.events]: \u001B[0m eta: 0:14:31  iter: 779  total_loss: 1.297  loss_cls: 0.1718  loss_box_reg: 0.3767  loss_mask: 0.3491  loss_rpn_cls: 0.2064  loss_rpn_loc: 0.2486    time: 1.0249  last_time: 0.2218  data_time: 0.0033  last_data_time: 0.0010   lr: 0.00015  max_mem: 7363M\n",
      "\u001B[32m[01/28 18:39:33 d2.utils.events]: \u001B[0m eta: 0:14:17  iter: 799  total_loss: 1.392  loss_cls: 0.1789  loss_box_reg: 0.3597  loss_mask: 0.3737  loss_rpn_cls: 0.2055  loss_rpn_loc: 0.3103    time: 1.0255  last_time: 2.4306  data_time: 0.0026  last_data_time: 0.0042   lr: 0.00015  max_mem: 7363M\n",
      "\u001B[32m[01/28 18:39:51 d2.utils.events]: \u001B[0m eta: 0:14:02  iter: 819  total_loss: 1.37  loss_cls: 0.1686  loss_box_reg: 0.3718  loss_mask: 0.3657  loss_rpn_cls: 0.209  loss_rpn_loc: 0.2996    time: 1.0217  last_time: 0.2076  data_time: 0.0028  last_data_time: 0.0011   lr: 0.00015  max_mem: 7363M\n",
      "\u001B[32m[01/28 18:40:08 d2.utils.events]: \u001B[0m eta: 0:13:48  iter: 839  total_loss: 1.335  loss_cls: 0.1708  loss_box_reg: 0.3631  loss_mask: 0.3648  loss_rpn_cls: 0.1917  loss_rpn_loc: 0.2812    time: 1.0183  last_time: 0.7603  data_time: 0.0025  last_data_time: 0.0024   lr: 0.00015  max_mem: 7363M\n",
      "\u001B[32m[01/28 18:40:27 d2.utils.events]: \u001B[0m eta: 0:13:31  iter: 859  total_loss: 1.317  loss_cls: 0.1643  loss_box_reg: 0.3512  loss_mask: 0.3464  loss_rpn_cls: 0.2145  loss_rpn_loc: 0.2744    time: 1.0166  last_time: 0.2400  data_time: 0.0030  last_data_time: 0.0014   lr: 0.00015  max_mem: 7363M\n",
      "\u001B[32m[01/28 18:40:51 d2.utils.events]: \u001B[0m eta: 0:13:19  iter: 879  total_loss: 1.344  loss_cls: 0.1741  loss_box_reg: 0.3164  loss_mask: 0.3582  loss_rpn_cls: 0.2324  loss_rpn_loc: 0.2865    time: 1.0202  last_time: 1.0382  data_time: 0.0030  last_data_time: 0.0022   lr: 0.00015  max_mem: 7363M\n",
      "\u001B[32m[01/28 18:41:11 d2.utils.events]: \u001B[0m eta: 0:13:03  iter: 899  total_loss: 1.351  loss_cls: 0.1608  loss_box_reg: 0.3496  loss_mask: 0.351  loss_rpn_cls: 0.2221  loss_rpn_loc: 0.2704    time: 1.0198  last_time: 0.6163  data_time: 0.0026  last_data_time: 0.0022   lr: 0.00015  max_mem: 7365M\n",
      "\u001B[32m[01/28 18:41:36 d2.utils.events]: \u001B[0m eta: 0:12:52  iter: 919  total_loss: 1.303  loss_cls: 0.1498  loss_box_reg: 0.2863  loss_mask: 0.3581  loss_rpn_cls: 0.2402  loss_rpn_loc: 0.2901    time: 1.0249  last_time: 0.2419  data_time: 0.0034  last_data_time: 0.0016   lr: 0.00015  max_mem: 7365M\n",
      "\u001B[32m[01/28 18:41:52 d2.utils.events]: \u001B[0m eta: 0:12:37  iter: 939  total_loss: 1.317  loss_cls: 0.1578  loss_box_reg: 0.3461  loss_mask: 0.3579  loss_rpn_cls: 0.2084  loss_rpn_loc: 0.2704    time: 1.0206  last_time: 0.7036  data_time: 0.0036  last_data_time: 0.0026   lr: 0.00015  max_mem: 7365M\n",
      "\u001B[32m[01/28 18:42:12 d2.utils.events]: \u001B[0m eta: 0:12:22  iter: 959  total_loss: 1.307  loss_cls: 0.1729  loss_box_reg: 0.348  loss_mask: 0.3618  loss_rpn_cls: 0.1748  loss_rpn_loc: 0.2726    time: 1.0195  last_time: 0.2265  data_time: 0.0026  last_data_time: 0.0015   lr: 0.00015  max_mem: 7365M\n",
      "\u001B[32m[01/28 18:42:31 d2.utils.events]: \u001B[0m eta: 0:12:07  iter: 979  total_loss: 1.292  loss_cls: 0.1412  loss_box_reg: 0.3313  loss_mask: 0.3511  loss_rpn_cls: 0.2382  loss_rpn_loc: 0.2801    time: 1.0178  last_time: 0.2391  data_time: 0.0026  last_data_time: 0.0014   lr: 0.00015  max_mem: 7365M\n",
      "\u001B[32m[01/28 18:42:48 d2.utils.events]: \u001B[0m eta: 0:11:53  iter: 999  total_loss: 1.287  loss_cls: 0.1495  loss_box_reg: 0.3231  loss_mask: 0.3648  loss_rpn_cls: 0.1856  loss_rpn_loc: 0.2813    time: 1.0147  last_time: 0.8327  data_time: 0.0023  last_data_time: 0.0015   lr: 0.00015  max_mem: 7365M\n",
      "\u001B[32m[01/28 18:43:01 d2.utils.events]: \u001B[0m eta: 0:11:33  iter: 1019  total_loss: 1.299  loss_cls: 0.1547  loss_box_reg: 0.3655  loss_mask: 0.3594  loss_rpn_cls: 0.2158  loss_rpn_loc: 0.2274    time: 1.0080  last_time: 2.2299  data_time: 0.0022  last_data_time: 0.0046   lr: 1.5e-05  max_mem: 7365M\n",
      "\u001B[32m[01/28 18:43:23 d2.utils.events]: \u001B[0m eta: 0:11:20  iter: 1039  total_loss: 1.263  loss_cls: 0.1535  loss_box_reg: 0.2731  loss_mask: 0.3557  loss_rpn_cls: 0.1853  loss_rpn_loc: 0.2803    time: 1.0094  last_time: 1.9649  data_time: 0.0026  last_data_time: 0.0038   lr: 1.5e-05  max_mem: 7365M\n",
      "\u001B[32m[01/28 18:43:47 d2.utils.events]: \u001B[0m eta: 0:11:04  iter: 1059  total_loss: 1.291  loss_cls: 0.1589  loss_box_reg: 0.3092  loss_mask: 0.3567  loss_rpn_cls: 0.2213  loss_rpn_loc: 0.2947    time: 1.0132  last_time: 0.5540  data_time: 0.0036  last_data_time: 0.0027   lr: 1.5e-05  max_mem: 7365M\n",
      "\u001B[32m[01/28 18:44:05 d2.utils.events]: \u001B[0m eta: 0:10:48  iter: 1079  total_loss: 1.303  loss_cls: 0.1641  loss_box_reg: 0.3302  loss_mask: 0.3669  loss_rpn_cls: 0.1882  loss_rpn_loc: 0.2737    time: 1.0109  last_time: 0.2271  data_time: 0.0024  last_data_time: 0.0018   lr: 1.5e-05  max_mem: 7365M\n",
      "\u001B[32m[01/28 18:44:24 d2.utils.events]: \u001B[0m eta: 0:10:35  iter: 1099  total_loss: 1.303  loss_cls: 0.1532  loss_box_reg: 0.3146  loss_mask: 0.3736  loss_rpn_cls: 0.2121  loss_rpn_loc: 0.2925    time: 1.0095  last_time: 1.7801  data_time: 0.0026  last_data_time: 0.0049   lr: 1.5e-05  max_mem: 7365M\n",
      "\u001B[32m[01/28 18:44:40 d2.utils.events]: \u001B[0m eta: 0:10:18  iter: 1119  total_loss: 1.267  loss_cls: 0.1437  loss_box_reg: 0.3474  loss_mask: 0.3578  loss_rpn_cls: 0.2055  loss_rpn_loc: 0.2535    time: 1.0059  last_time: 2.0513  data_time: 0.0023  last_data_time: 0.0031   lr: 1.5e-05  max_mem: 7365M\n",
      "\u001B[32m[01/28 18:45:00 d2.utils.events]: \u001B[0m eta: 0:10:04  iter: 1139  total_loss: 1.287  loss_cls: 0.1702  loss_box_reg: 0.3276  loss_mask: 0.3633  loss_rpn_cls: 0.2009  loss_rpn_loc: 0.2798    time: 1.0061  last_time: 0.2374  data_time: 0.0029  last_data_time: 0.0012   lr: 1.5e-05  max_mem: 7365M\n",
      "\u001B[32m[01/28 18:45:21 d2.utils.events]: \u001B[0m eta: 0:09:51  iter: 1159  total_loss: 1.238  loss_cls: 0.1414  loss_box_reg: 0.2922  loss_mask: 0.3618  loss_rpn_cls: 0.2025  loss_rpn_loc: 0.2462    time: 1.0065  last_time: 1.7713  data_time: 0.0030  last_data_time: 0.0064   lr: 1.5e-05  max_mem: 7365M\n",
      "\u001B[32m[01/28 18:45:41 d2.utils.events]: \u001B[0m eta: 0:09:38  iter: 1179  total_loss: 1.286  loss_cls: 0.1468  loss_box_reg: 0.3283  loss_mask: 0.3567  loss_rpn_cls: 0.1988  loss_rpn_loc: 0.2851    time: 1.0064  last_time: 2.0618  data_time: 0.0073  last_data_time: 0.0054   lr: 1.5e-05  max_mem: 7365M\n",
      "\u001B[32m[01/28 18:46:03 d2.utils.events]: \u001B[0m eta: 0:09:24  iter: 1199  total_loss: 1.256  loss_cls: 0.1491  loss_box_reg: 0.3162  loss_mask: 0.3518  loss_rpn_cls: 0.199  loss_rpn_loc: 0.2804    time: 1.0077  last_time: 2.6595  data_time: 0.0035  last_data_time: 0.0063   lr: 1.5e-05  max_mem: 7365M\n",
      "\u001B[32m[01/28 18:46:22 d2.utils.events]: \u001B[0m eta: 0:09:10  iter: 1219  total_loss: 1.277  loss_cls: 0.1545  loss_box_reg: 0.3579  loss_mask: 0.35  loss_rpn_cls: 0.2061  loss_rpn_loc: 0.2874    time: 1.0072  last_time: 0.6915  data_time: 0.0248  last_data_time: 0.0026   lr: 1.5e-05  max_mem: 7365M\n",
      "\u001B[32m[01/28 18:46:40 d2.utils.events]: \u001B[0m eta: 0:08:56  iter: 1239  total_loss: 1.287  loss_cls: 0.1509  loss_box_reg: 0.3197  loss_mask: 0.3596  loss_rpn_cls: 0.2102  loss_rpn_loc: 0.2724    time: 1.0057  last_time: 1.0087  data_time: 0.0040  last_data_time: 0.0160   lr: 1.5e-05  max_mem: 7365M\n",
      "\u001B[32m[01/28 18:47:04 d2.utils.events]: \u001B[0m eta: 0:08:40  iter: 1259  total_loss: 1.339  loss_cls: 0.1815  loss_box_reg: 0.3003  loss_mask: 0.3703  loss_rpn_cls: 0.1976  loss_rpn_loc: 0.3095    time: 1.0081  last_time: 0.2253  data_time: 0.0037  last_data_time: 0.0017   lr: 1.5e-05  max_mem: 7365M\n",
      "\u001B[32m[01/28 18:47:24 d2.utils.events]: \u001B[0m eta: 0:08:25  iter: 1279  total_loss: 1.273  loss_cls: 0.1535  loss_box_reg: 0.3508  loss_mask: 0.3571  loss_rpn_cls: 0.1915  loss_rpn_loc: 0.293    time: 1.0081  last_time: 0.1996  data_time: 0.0033  last_data_time: 0.0010   lr: 1.5e-05  max_mem: 7365M\n",
      "\u001B[32m[01/28 18:47:45 d2.utils.events]: \u001B[0m eta: 0:08:09  iter: 1299  total_loss: 1.274  loss_cls: 0.1479  loss_box_reg: 0.3042  loss_mask: 0.3557  loss_rpn_cls: 0.2313  loss_rpn_loc: 0.2662    time: 1.0091  last_time: 2.3234  data_time: 0.0032  last_data_time: 0.0064   lr: 1.5e-05  max_mem: 7365M\n",
      "\u001B[32m[01/28 18:48:04 d2.utils.events]: \u001B[0m eta: 0:07:55  iter: 1319  total_loss: 1.321  loss_cls: 0.1655  loss_box_reg: 0.3556  loss_mask: 0.3711  loss_rpn_cls: 0.1887  loss_rpn_loc: 0.2626    time: 1.0081  last_time: 0.6318  data_time: 0.0030  last_data_time: 0.0014   lr: 1.5e-05  max_mem: 7365M\n",
      "\u001B[32m[01/28 18:48:25 d2.utils.events]: \u001B[0m eta: 0:07:41  iter: 1339  total_loss: 1.229  loss_cls: 0.1252  loss_box_reg: 0.2958  loss_mask: 0.3551  loss_rpn_cls: 0.1965  loss_rpn_loc: 0.2978    time: 1.0088  last_time: 0.6957  data_time: 0.0030  last_data_time: 0.0019   lr: 1.5e-05  max_mem: 7366M\n",
      "\u001B[32m[01/28 18:48:45 d2.utils.events]: \u001B[0m eta: 0:07:25  iter: 1359  total_loss: 1.276  loss_cls: 0.143  loss_box_reg: 0.3026  loss_mask: 0.362  loss_rpn_cls: 0.196  loss_rpn_loc: 0.2775    time: 1.0087  last_time: 2.4138  data_time: 0.0030  last_data_time: 0.0049   lr: 1.5e-05  max_mem: 7366M\n",
      "\u001B[32m[01/28 18:49:11 d2.utils.events]: \u001B[0m eta: 0:07:12  iter: 1379  total_loss: 1.283  loss_cls: 0.1643  loss_box_reg: 0.295  loss_mask: 0.3585  loss_rpn_cls: 0.2264  loss_rpn_loc: 0.2818    time: 1.0128  last_time: 0.7054  data_time: 0.0040  last_data_time: 0.0021   lr: 1.5e-05  max_mem: 7366M\n",
      "\u001B[32m[01/28 18:49:25 d2.utils.events]: \u001B[0m eta: 0:06:58  iter: 1399  total_loss: 1.341  loss_cls: 0.143  loss_box_reg: 0.345  loss_mask: 0.3623  loss_rpn_cls: 0.2282  loss_rpn_loc: 0.2751    time: 1.0084  last_time: 0.2400  data_time: 0.0051  last_data_time: 0.0020   lr: 1.5e-05  max_mem: 7366M\n",
      "\u001B[32m[01/28 18:49:48 d2.utils.events]: \u001B[0m eta: 0:06:44  iter: 1419  total_loss: 1.304  loss_cls: 0.1521  loss_box_reg: 0.3124  loss_mask: 0.3647  loss_rpn_cls: 0.2198  loss_rpn_loc: 0.3047    time: 1.0105  last_time: 0.6348  data_time: 0.0033  last_data_time: 0.0017   lr: 1.5e-05  max_mem: 7366M\n",
      "\u001B[32m[01/28 18:50:08 d2.utils.events]: \u001B[0m eta: 0:06:30  iter: 1439  total_loss: 1.268  loss_cls: 0.1396  loss_box_reg: 0.329  loss_mask: 0.3527  loss_rpn_cls: 0.2054  loss_rpn_loc: 0.2493    time: 1.0097  last_time: 0.6490  data_time: 0.0028  last_data_time: 0.0020   lr: 1.5e-05  max_mem: 7366M\n",
      "\u001B[32m[01/28 18:50:25 d2.utils.events]: \u001B[0m eta: 0:06:15  iter: 1459  total_loss: 1.286  loss_cls: 0.1514  loss_box_reg: 0.3484  loss_mask: 0.3498  loss_rpn_cls: 0.2179  loss_rpn_loc: 0.2739    time: 1.0076  last_time: 0.6194  data_time: 0.0026  last_data_time: 0.0017   lr: 1.5e-05  max_mem: 7366M\n",
      "\u001B[32m[01/28 18:50:43 d2.utils.events]: \u001B[0m eta: 0:06:01  iter: 1479  total_loss: 1.324  loss_cls: 0.1603  loss_box_reg: 0.3887  loss_mask: 0.3709  loss_rpn_cls: 0.1891  loss_rpn_loc: 0.297    time: 1.0064  last_time: 0.2156  data_time: 0.0030  last_data_time: 0.0017   lr: 1.5e-05  max_mem: 7366M\n",
      "\u001B[32m[01/28 18:51:04 d2.utils.events]: \u001B[0m eta: 0:05:47  iter: 1499  total_loss: 1.277  loss_cls: 0.1595  loss_box_reg: 0.3155  loss_mask: 0.3447  loss_rpn_cls: 0.2073  loss_rpn_loc: 0.2988    time: 1.0069  last_time: 1.1448  data_time: 0.0029  last_data_time: 0.0023   lr: 1.5e-05  max_mem: 7366M\n",
      "\u001B[32m[01/28 18:51:21 d2.utils.events]: \u001B[0m eta: 0:05:33  iter: 1519  total_loss: 1.326  loss_cls: 0.1583  loss_box_reg: 0.3391  loss_mask: 0.3551  loss_rpn_cls: 0.2254  loss_rpn_loc: 0.2639    time: 1.0050  last_time: 1.3065  data_time: 0.0031  last_data_time: 0.0030   lr: 1.5e-06  max_mem: 7366M\n",
      "\u001B[32m[01/28 18:51:38 d2.utils.events]: \u001B[0m eta: 0:05:18  iter: 1539  total_loss: 1.274  loss_cls: 0.1632  loss_box_reg: 0.3637  loss_mask: 0.355  loss_rpn_cls: 0.1956  loss_rpn_loc: 0.2516    time: 1.0030  last_time: 0.2650  data_time: 0.0032  last_data_time: 0.0013   lr: 1.5e-06  max_mem: 7366M\n",
      "\u001B[32m[01/28 18:51:56 d2.utils.events]: \u001B[0m eta: 0:05:05  iter: 1559  total_loss: 1.264  loss_cls: 0.1554  loss_box_reg: 0.3318  loss_mask: 0.3416  loss_rpn_cls: 0.1834  loss_rpn_loc: 0.268    time: 1.0014  last_time: 1.9111  data_time: 0.0032  last_data_time: 0.0071   lr: 1.5e-06  max_mem: 7366M\n",
      "\u001B[32m[01/28 18:52:16 d2.utils.events]: \u001B[0m eta: 0:04:52  iter: 1579  total_loss: 1.269  loss_cls: 0.162  loss_box_reg: 0.3071  loss_mask: 0.3577  loss_rpn_cls: 0.1936  loss_rpn_loc: 0.248    time: 1.0016  last_time: 2.0224  data_time: 0.0031  last_data_time: 0.0053   lr: 1.5e-06  max_mem: 7366M\n",
      "\u001B[32m[01/28 18:52:46 d2.utils.events]: \u001B[0m eta: 0:04:39  iter: 1599  total_loss: 1.284  loss_cls: 0.1591  loss_box_reg: 0.2367  loss_mask: 0.3694  loss_rpn_cls: 0.2293  loss_rpn_loc: 0.2952    time: 1.0076  last_time: 2.2357  data_time: 0.0041  last_data_time: 0.0047   lr: 1.5e-06  max_mem: 7366M\n",
      "\u001B[32m[01/28 18:53:06 d2.utils.events]: \u001B[0m eta: 0:04:25  iter: 1619  total_loss: 1.325  loss_cls: 0.1594  loss_box_reg: 0.328  loss_mask: 0.3628  loss_rpn_cls: 0.2091  loss_rpn_loc: 0.2577    time: 1.0075  last_time: 0.2443  data_time: 0.0037  last_data_time: 0.0015   lr: 1.5e-06  max_mem: 7366M\n",
      "\u001B[32m[01/28 18:53:24 d2.utils.events]: \u001B[0m eta: 0:04:13  iter: 1639  total_loss: 1.27  loss_cls: 0.1481  loss_box_reg: 0.3209  loss_mask: 0.353  loss_rpn_cls: 0.1955  loss_rpn_loc: 0.2718    time: 1.0065  last_time: 0.2348  data_time: 0.0028  last_data_time: 0.0012   lr: 1.5e-06  max_mem: 7366M\n",
      "\u001B[32m[01/28 18:53:40 d2.utils.events]: \u001B[0m eta: 0:03:56  iter: 1659  total_loss: 1.266  loss_cls: 0.1614  loss_box_reg: 0.3578  loss_mask: 0.3516  loss_rpn_cls: 0.1714  loss_rpn_loc: 0.2596    time: 1.0038  last_time: 0.2463  data_time: 0.0024  last_data_time: 0.0015   lr: 1.5e-06  max_mem: 7366M\n",
      "\u001B[32m[01/28 18:54:00 d2.utils.events]: \u001B[0m eta: 0:03:43  iter: 1679  total_loss: 1.304  loss_cls: 0.1467  loss_box_reg: 0.3046  loss_mask: 0.371  loss_rpn_cls: 0.2013  loss_rpn_loc: 0.3046    time: 1.0036  last_time: 1.2468  data_time: 0.0025  last_data_time: 0.0023   lr: 1.5e-06  max_mem: 7366M\n",
      "\u001B[32m[01/28 18:54:22 d2.utils.events]: \u001B[0m eta: 0:03:30  iter: 1699  total_loss: 1.309  loss_cls: 0.1573  loss_box_reg: 0.3171  loss_mask: 0.3612  loss_rpn_cls: 0.1979  loss_rpn_loc: 0.2915    time: 1.0048  last_time: 0.7268  data_time: 0.0031  last_data_time: 0.0021   lr: 1.5e-06  max_mem: 7366M\n",
      "\u001B[32m[01/28 18:54:39 d2.utils.events]: \u001B[0m eta: 0:03:15  iter: 1719  total_loss: 1.28  loss_cls: 0.1651  loss_box_reg: 0.3386  loss_mask: 0.3456  loss_rpn_cls: 0.219  loss_rpn_loc: 0.276    time: 1.0030  last_time: 0.2094  data_time: 0.0027  last_data_time: 0.0009   lr: 1.5e-06  max_mem: 7366M\n",
      "\u001B[32m[01/28 18:54:55 d2.utils.events]: \u001B[0m eta: 0:03:01  iter: 1739  total_loss: 1.29  loss_cls: 0.1704  loss_box_reg: 0.3332  loss_mask: 0.3475  loss_rpn_cls: 0.1889  loss_rpn_loc: 0.2641    time: 1.0004  last_time: 0.6316  data_time: 0.0023  last_data_time: 0.0023   lr: 1.5e-06  max_mem: 7366M\n",
      "\u001B[32m[01/28 18:55:17 d2.utils.events]: \u001B[0m eta: 0:02:48  iter: 1759  total_loss: 1.245  loss_cls: 0.135  loss_box_reg: 0.309  loss_mask: 0.3497  loss_rpn_cls: 0.2127  loss_rpn_loc: 0.2711    time: 1.0019  last_time: 0.2386  data_time: 0.0030  last_data_time: 0.0013   lr: 1.5e-06  max_mem: 7366M\n",
      "\u001B[32m[01/28 18:55:44 d2.utils.events]: \u001B[0m eta: 0:02:34  iter: 1779  total_loss: 1.273  loss_cls: 0.1506  loss_box_reg: 0.2808  loss_mask: 0.3602  loss_rpn_cls: 0.2156  loss_rpn_loc: 0.2933    time: 1.0056  last_time: 2.0239  data_time: 0.0074  last_data_time: 0.0057   lr: 1.5e-06  max_mem: 7366M\n",
      "\u001B[32m[01/28 18:56:01 d2.utils.events]: \u001B[0m eta: 0:02:20  iter: 1799  total_loss: 1.288  loss_cls: 0.1471  loss_box_reg: 0.3272  loss_mask: 0.3602  loss_rpn_cls: 0.1994  loss_rpn_loc: 0.2831    time: 1.0041  last_time: 0.6760  data_time: 0.0029  last_data_time: 0.0021   lr: 1.5e-06  max_mem: 7366M\n",
      "\u001B[32m[01/28 18:56:17 d2.utils.events]: \u001B[0m eta: 0:02:06  iter: 1819  total_loss: 1.316  loss_cls: 0.1594  loss_box_reg: 0.3733  loss_mask: 0.3607  loss_rpn_cls: 0.1607  loss_rpn_loc: 0.2434    time: 1.0018  last_time: 2.4393  data_time: 0.0023  last_data_time: 0.0049   lr: 1.5e-06  max_mem: 7366M\n",
      "\u001B[32m[01/28 18:56:45 d2.utils.events]: \u001B[0m eta: 0:01:52  iter: 1839  total_loss: 1.315  loss_cls: 0.1668  loss_box_reg: 0.2645  loss_mask: 0.3719  loss_rpn_cls: 0.2311  loss_rpn_loc: 0.2965    time: 1.0058  last_time: 1.2206  data_time: 0.0034  last_data_time: 0.0027   lr: 1.5e-06  max_mem: 7366M\n",
      "\u001B[32m[01/28 18:57:04 d2.utils.events]: \u001B[0m eta: 0:01:38  iter: 1859  total_loss: 1.258  loss_cls: 0.1433  loss_box_reg: 0.3164  loss_mask: 0.3577  loss_rpn_cls: 0.2198  loss_rpn_loc: 0.2505    time: 1.0053  last_time: 0.2623  data_time: 0.0036  last_data_time: 0.0016   lr: 1.5e-06  max_mem: 7366M\n",
      "\u001B[32m[01/28 18:57:26 d2.utils.events]: \u001B[0m eta: 0:01:24  iter: 1879  total_loss: 1.301  loss_cls: 0.1575  loss_box_reg: 0.2906  loss_mask: 0.3629  loss_rpn_cls: 0.2215  loss_rpn_loc: 0.2956    time: 1.0064  last_time: 0.2168  data_time: 0.0035  last_data_time: 0.0016   lr: 1.5e-06  max_mem: 7366M\n",
      "\u001B[32m[01/28 18:57:42 d2.utils.events]: \u001B[0m eta: 0:01:10  iter: 1899  total_loss: 1.32  loss_cls: 0.1521  loss_box_reg: 0.3635  loss_mask: 0.3447  loss_rpn_cls: 0.1954  loss_rpn_loc: 0.2633    time: 1.0043  last_time: 0.3795  data_time: 0.0029  last_data_time: 0.0019   lr: 1.5e-06  max_mem: 7366M\n",
      "\u001B[32m[01/28 18:58:03 d2.utils.events]: \u001B[0m eta: 0:00:56  iter: 1919  total_loss: 1.296  loss_cls: 0.1559  loss_box_reg: 0.3324  loss_mask: 0.3557  loss_rpn_cls: 0.193  loss_rpn_loc: 0.2845    time: 1.0047  last_time: 0.1864  data_time: 0.0031  last_data_time: 0.0009   lr: 1.5e-06  max_mem: 7366M\n",
      "\u001B[32m[01/28 18:58:23 d2.utils.events]: \u001B[0m eta: 0:00:42  iter: 1939  total_loss: 1.238  loss_cls: 0.1519  loss_box_reg: 0.3157  loss_mask: 0.354  loss_rpn_cls: 0.1894  loss_rpn_loc: 0.2494    time: 1.0047  last_time: 0.2166  data_time: 0.0027  last_data_time: 0.0010   lr: 1.5e-06  max_mem: 7366M\n",
      "\u001B[32m[01/28 18:58:42 d2.utils.events]: \u001B[0m eta: 0:00:28  iter: 1959  total_loss: 1.26  loss_cls: 0.1438  loss_box_reg: 0.3103  loss_mask: 0.3473  loss_rpn_cls: 0.1924  loss_rpn_loc: 0.2719    time: 1.0039  last_time: 1.1491  data_time: 0.0025  last_data_time: 0.0019   lr: 1.5e-06  max_mem: 7366M\n",
      "\u001B[32m[01/28 18:59:02 d2.utils.events]: \u001B[0m eta: 0:00:14  iter: 1979  total_loss: 1.238  loss_cls: 0.1679  loss_box_reg: 0.3257  loss_mask: 0.345  loss_rpn_cls: 0.1885  loss_rpn_loc: 0.2443    time: 1.0041  last_time: 0.6079  data_time: 0.0054  last_data_time: 0.0022   lr: 1.5e-06  max_mem: 7366M\n",
      "\u001B[32m[01/28 18:59:25 d2.utils.events]: \u001B[0m eta: 0:00:00  iter: 1999  total_loss: 1.308  loss_cls: 0.1707  loss_box_reg: 0.3158  loss_mask: 0.3544  loss_rpn_cls: 0.1955  loss_rpn_loc: 0.2775    time: 1.0053  last_time: 0.2406  data_time: 0.0044  last_data_time: 0.0008   lr: 1.5e-06  max_mem: 7366M\n",
      "\u001B[32m[01/28 18:59:25 d2.engine.hooks]: \u001B[0mOverall training speed: 1998 iterations in 0:33:28 (1.0053 s / it)\n",
      "\u001B[32m[01/28 18:59:25 d2.engine.hooks]: \u001B[0mTotal training time: 0:33:30 (0:00:02 on hooks)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T17:20:12.994824Z",
     "start_time": "2025-01-28T17:20:12.797466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# plot the training loss\n",
    "metrics_df = pd.read_json(\"./output/metrics.json\", orient=\"records\", lines=True)\n",
    "mdf = metrics_df.sort_values(\"iteration\")\n",
    "mdf.head(10).T\n",
    "fig, ax = plt.subplots()\n",
    "mdf1 = mdf[~mdf[\"total_loss\"].isna()]\n",
    "ax.plot(mdf1[\"iteration\"], mdf1[\"total_loss\"], c=\"C0\", label=\"train\")\n",
    "# ax.set_ylim([0, 3])\n",
    "ax.legend()\n",
    "ax.set_title(\"Loss curve\")\n",
    "\n",
    "# #Save the plot as an image file\n",
    "# plt.savefig(\"loss_curve.png\")\n",
    "\n",
    "plt.show()"
   ],
   "id": "b58cff662d835e01",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T18:27:13.633214Z",
     "start_time": "2025-01-28T18:26:20.708012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load trained model\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.WEIGHTS = \"output/model_final.pth\"\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # Only barnacle class\n",
    "cfg.TEST.DETECTIONS_PER_IMAGE = 5000\n",
    "cfg.MODEL.RPN.PRE_NMS_TOPK_TEST = 5000\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 5000\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.75  # Set the testing threshold for this model\n",
    "cfg.INPUT.MIN_SIZE_TEST = 250 # set to 0 for zoomed out images, set to 250 for zoomed in ones\n",
    "cfg.INPUT.MAX_SIZE_TEST = 9999\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# Predict on a new ROI\n",
    "roi = cv2.imread(\"barnacle_dataset/test/roi_unseen_img2.png\")\n",
    "if roi is None:\n",
    "    raise FileNotFoundError(\"The image 'barnacle_dataset/test/roi_unseen_img1.png' was not found or could not be read.\")\n",
    "\n",
    "# Resize the image\n",
    "new_width = 1800  # Set the desired width\n",
    "new_height = 1800  # Set the desired height\n",
    "roi = cv2.resize(roi, (new_width, new_height))\n",
    "\n",
    "outputs = predictor(roi)\n",
    "\n",
    "# Visualize results\n",
    "v = Visualizer(roi[:, :, ::-1], scale=0.5)\n",
    "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "\n",
    "# Save the output image\n",
    "output_image = out.get_image()[:, :, ::-1]\n",
    "cv2.imwrite(\"output/images/result.png\", output_image)\n",
    "\n",
    "# Optionally, display the image\n",
    "cv2.imshow(\"Result\", output_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# count barnacles\n",
    "num_barnacles = len(outputs[\"instances\"])\n",
    "print(f\"Number of barnacles detected: {num_barnacles}\")"
   ],
   "id": "8d7d8d50ce89d6de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of barnacles detected: 129\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "58005e27a1125de5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
